<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="default">
<head><meta name="generator" content="Hexo 3.8.0">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hongyan's Notes, NexT">





  <link rel="alternate" href="/atom.xml" title="Hongyan's Notes" type="application/atom+xml">






<meta name="description" content="Generative Model Conlusion categories: VAE-based, GAN-based, autogressive model based, flow-based.  advantage and disadvantage: vae-based (ad: model each training samples, ideal vae-based model withou">
<meta name="keywords" content="Coding &amp;&amp; Learning">
<meta property="og:type" content="article">
<meta property="og:title" content="Image Generation">
<meta property="og:url" content="https://www.yanhong.website/2021/04/12/Generation/index.html">
<meta property="og:site_name" content="Hongyan&#39;s Notes">
<meta property="og:description" content="Generative Model Conlusion categories: VAE-based, GAN-based, autogressive model based, flow-based.  advantage and disadvantage: vae-based (ad: model each training samples, ideal vae-based model withou">
<meta property="og:locale" content="default">
<meta property="og:updated_time" content="2021-04-26T06:58:42.274Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Image Generation">
<meta name="twitter:description" content="Generative Model Conlusion categories: VAE-based, GAN-based, autogressive model based, flow-based.  advantage and disadvantage: vae-based (ad: model each training samples, ideal vae-based model withou">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://www.yanhong.website/2021/04/12/Generation/">





  <title>Image Generation | Hongyan's Notes</title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  








</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Hongyan's Notes</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">Cheatsheet</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            About
          </a>
        </li>
      
        
        <li class="menu-item menu-item-guestbook">
          <a href="/guestbook" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br>
            
            Guestbook
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>
            
            Search
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="Searching..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://www.yanhong.website/2021/04/12/Generation/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Hongyan">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hongyan's Notes">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Image Generation</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2021-04-12T19:59:19+08:00">
                2021-04-12
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/Generative-Model/" itemprop="url" rel="index">
                    <span itemprop="name">Generative Model</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  
                </span>
              

              

              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h2 id="Generative-Model-Conlusion"><a href="#Generative-Model-Conlusion" class="headerlink" title="Generative Model Conlusion"></a>Generative Model Conlusion</h2><ul>
<li><p>categories: VAE-based, GAN-based, autogressive model based, flow-based.</p>
</li>
<li><p>advantage and disadvantage: vae-based (ad: model each training samples, ideal vae-based model without mode collapse; disad: suffer from posterior collapse); gan-based (ad: clear and realistic images; disad: suffering from mode collapse); autogressive model based: ad: effective probability estimation; disad: sampling speed is slow.</p>
</li>
<li><p>improvement methods: combinations, CVAE-GAN (VAE, GAN), VQ-VAE (AE, autogressive model), VQ-GAN (AE, autogressive model by combinating cnn with transformer)</p>
</li>
</ul>
<h3 id="Taming-Transformers-for-High-Resolution-Image-Synthesis"><a href="#Taming-Transformers-for-High-Resolution-Image-Synthesis" class="headerlink" title="Taming Transformers for High-Resolution Image Synthesis"></a>Taming Transformers for High-Resolution Image Synthesis</h3><ul>
<li><p><a href="https://arxiv.org/pdf/2012.09841.pdf" target="_blank" rel="noopener">CVPR 2021 PAPER</a></p>
</li>
<li><p><a href="https://blog.csdn.net/qq_40723205/article/details/113181463" target="_blank" rel="noopener">blog</a></p>
</li>
<li><p>target: demonstrate how combining the effectiveness of the inductive bias of CNNs with the expressivity of transformers enables them to model and thereby synthesize high-resolution images.</p>
</li>
<li><p>core idea: use CNNs to learn a contextrich vocabulary of image constituents by a learning a codebook; utilize transformers to efficiently model their composition within high-resolution images.</p>
</li>
<li><p>method: using VQGAN to learn a codebook, different from VQ-VAE.</p>
</li>
<li><p><font color="red"> difference from VQ-VAE</font>: using transforer to deal with higher resolution image (VQ-VAE:256 <em> 256 images, dimension reduction 32 </em> 32 in discrete codebook space, VQGAN: 1280 <em> 460 images, dimension reduction 16 </em> 16 in discrete codebook space). VQ procedure: using adversarial loss to replace reconstruction loss. autogressive precedure: using transformer  to replace pixelCNN.</p>
</li>
<li><p><font color="red"> similar idea with VQ-VAE</font> : Using discrete representation can discraite natual modality better (introducing VQ, or other discrete methods). Using autogressive model can conduct effective probability estimation, but which should be implemented in low-dimensiton space rather than large pixel space (introducing autogressive models, such as pixelCNN, transformer).</p>
</li>
</ul>
<h4 id="Related-paper-NIPS-2017-Neural-Discrete-Representation-Learning"><a href="#Related-paper-NIPS-2017-Neural-Discrete-Representation-Learning" class="headerlink" title="Related paper NIPS 2017: Neural Discrete Representation Learning"></a><a href="https://arxiv.org/pdf/1711.00937.pdf" target="_blank" rel="noopener">Related paper NIPS 2017: Neural Discrete Representation Learning</a></h4><ul>
<li><p>based on VAE, but different from VAE: the encoder network outputs discrete, rather than continuous, codes; and the prior is learnt rather than static.</p>
</li>
<li><p>the reason of VQ: discrete representations which are potentially a more natural fit for many of the modalities we are interested in. Furthermore, discrete representations are a natural fit for complex reasoning, planning and predictive learning.</p>
</li>
<li><p>learning discrete representation: vector quantization. </p>
</li>
<li><p>methods: testing by removing encoder and using autogressive model pixelCNN to build relation aming the dimension of sampling Z. </p>
</li>
<li><p><a href="https://kexue.fm/archives/6760" target="_blank" rel="noopener">blog</a></p>
</li>
<li><p>my understanding: discrete representations are more natural fit for many of modalities (langauge is discrete, images can be desscibed by discrete language). VAE has <font color="blue"> posterior  collapse </font>  which ignores the learnt latent code, as the powerful decoder, which can generate/reconstruct image with noise generated from <font color="blue">reparameterize </font>.  Inspired from pixelCNN with autogressive model by discribe a image with discrete pixel, VQ-VAE face two problems: recursive order designs, speeding up sampling (because sampling in autogressive model is slow). The shortcoming of autogressive model in pixel space is ignoring the relationship among continous pixels. VQ-VAE is designed to dimenstion reduction in latent code space, and then using autogressive model to model discrete code. In detail, using <font color="blue">neighbor reconstruction</font> to generate m * m matrix to achieve discrete coding, using <font color="blue">straight-thought estimator</font> to optimize the function without gradient. </p>
<ul>
<li><p>related concepts: AE: x-z-x, using compressed latent code to describe a image, VAE: x - z’ -&gt; x, enforce the latent code z’ to obey normal distribution and the sampling new latent code from the normal distribution. VAE: advantage is that ideal VAE can model each training samples without mode collapse, disadvantage is that VAE suffer from posterior collapse which ignores the latent code due to the powerful decoder, which can generate/reconstruct image with the noise introduced from reparamerization.</p>
</li>
<li><p>related concepts: autogressive model, such as pixelCNN using conditional probability distribution to generte image in pixel space. the advantage is the effective probability estimation, the disacvantage is the slow sampling speed.</p>
</li>
</ul>
</li>
</ul>
<h4 id="Related-paper-NIPS-2019-Generating-Diverse-High-Fidelity-Images-with-VQ-VAE-2"><a href="#Related-paper-NIPS-2019-Generating-Diverse-High-Fidelity-Images-with-VQ-VAE-2" class="headerlink" title="Related paper NIPS 2019: Generating Diverse High-Fidelity Images with VQ-VAE-2"></a><a href="https://arxiv.org/pdf/1906.00446.pdf" target="_blank" rel="noopener">Related paper NIPS 2019: Generating Diverse High-Fidelity Images with VQ-VAE-2</a></h4><ul>
<li><p>improvement: scaling and enhancing the autoregressive priors used in VQ-VAE to generate synthetic samples of much higher coherence and fidelity than possible before.</p>
</li>
<li><p>using hierarchical VQ-VAE: top latent code (32 <em> 32) to model global information, while bottom latent code (64 </em> 64) conditioned on top latent code to represent local detail.</p>
</li>
</ul>
<h4 id="Related-paper-CVPR-2020-Learning-Representations-by-Predicting-Bags-of-Visual-Words"><a href="#Related-paper-CVPR-2020-Learning-Representations-by-Predicting-Bags-of-Visual-Words" class="headerlink" title="Related paper CVPR 2020: Learning Representations by Predicting Bags of Visual Words"></a><a href="https://openaccess.thecvf.com/content_CVPR_2020/papers/Gidaris_Learning_Representations_by_Predicting_Bags_of_Visual_Words_CVPR_2020_paper.pdf" target="_blank" rel="noopener">Related paper CVPR 2020: Learning Representations by Predicting Bags of Visual Words</a></h4><h4 id="Related-paper-ICML-2020-Predictive-Sampling-with-Forecasting-Autoregressive-Models"><a href="#Related-paper-ICML-2020-Predictive-Sampling-with-Forecasting-Autoregressive-Models" class="headerlink" title="Related paper ICML 2020:Predictive Sampling with Forecasting Autoregressive Models"></a><a href="http://proceedings.mlr.press/v119/wiggers20a/wiggers20a.pdf" target="_blank" rel="noopener">Related paper ICML 2020:Predictive Sampling with Forecasting Autoregressive Models</a></h4><h4 id="Related-paper-ICML-2020-Latent-Bernoulli-Autoencoder"><a href="#Related-paper-ICML-2020-Latent-Bernoulli-Autoencoder" class="headerlink" title="Related paper ICML 2020:Latent Bernoulli Autoencoder"></a><a href="http://proceedings.mlr.press/v119/fajtl20a/fajtl20a.pdf" target="_blank" rel="noopener">Related paper ICML 2020:Latent Bernoulli Autoencoder</a></h4><h4 id="Related-paper-2021-Multimodal-Controller-for-Generative-Models"><a href="#Related-paper-2021-Multimodal-Controller-for-Generative-Models" class="headerlink" title="Related paper 2021:Multimodal Controller for Generative Models"></a><a href="https://arxiv.org/pdf/2002.02572.pdf" target="_blank" rel="noopener">Related paper 2021:Multimodal Controller for Generative Models</a></h4><h3 id="Generating-Diverse-Structure-for-Image-Inpainting-With-Hierarchical-VQ-VAE"><a href="#Generating-Diverse-Structure-for-Image-Inpainting-With-Hierarchical-VQ-VAE" class="headerlink" title="Generating Diverse Structure for Image Inpainting With Hierarchical VQ-VAE"></a>Generating Diverse Structure for Image Inpainting With Hierarchical VQ-VAE</h3><ul>
<li><p><a href="https://arxiv.org/pdf/2103.10022.pdf" target="_blank" rel="noopener">2021 PAPER</a></p>
</li>
<li><p>Application of VQ-VAE(VQ-VAE-2)</p>
</li>
<li><p>similar idea to VQ-VAE-2: using hirearchical VQ-VAE to genrate top(tructual) latent code and bottom(texture) latent code. using pixelCNN to generate structural top latent code, which can aviod mode collapse occured in GAN and ensure the diversity of structure.</p>
</li>
</ul>
<h2 id="Inspiration"><a href="#Inspiration" class="headerlink" title="Inspiration"></a>Inspiration</h2><ul>
<li><font color="red"> using idea of VQ-GAN to achieve specific application, such as high-resolution few-shot image generation. </font> 
</li>
<li><font color="red"> using idea of VQ-VAE (VQ-VAE-2: hirearchical VQ-vae) or VQ-GAN to achieve fuion-based few-shot image generation, which can also using top latent code to ensure the diversity of structures and using bottom latent code to model local detail. </font> 



</li>
</ul>
<h3 id="GIQA-Generated-Image-Quality-Assessment"><a href="#GIQA-Generated-Image-Quality-Assessment" class="headerlink" title="GIQA: Generated Image Quality Assessment"></a>GIQA: Generated Image Quality Assessment</h3><ul>
<li><a href="https://arxiv.org/pdf/2003.08932.pdf" target="_blank" rel="noopener">ECCV 2020 PAPER</a></li>
</ul>
<h3 id="Using-VQGAN"><a href="#Using-VQGAN" class="headerlink" title="Using VQGAN"></a>Using VQGAN</h3><ul>
<li><p>background knowledge</p>
<ul>
<li>word embedding<ul>
<li><a href="https://www.zhihu.com/question/32275069" target="_blank" rel="noopener">blog</a></li>
<li>procedure: creating a group of features for each word, for examples using 1024d vector to represent each indice in codebook, and then conducting distribution representation for the group of features.</li>
<li>how to learn the word embedding: using neural network with supervision.</li>
<li>effect: leart the context information among those words, for example the relation among the indices of codebook.</li>
</ul>
</li>
<li>transformer<ul>
<li>sequence2sequence + selfattention</li>
<li><a href="https://zhuanlan.zhihu.com/p/82391768" target="_blank" rel="noopener">blog1</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/48508221" target="_blank" rel="noopener">blog2</a></li>
<li><a href="https://www.zhihu.com/search?type=content&amp;q=transformer实现" target="_blank" rel="noopener">blog3</a></li>
</ul>
</li>
</ul>
</li>
<li><p>detailed implmentation</p>
<ul>
<li><p>VQ</p>
<ul>
<li>implementation：  x(b,w’,h’,c) -&gt; z(b, w, h, c<em>{z}) <font color="red"> lenght = w * h, which need to be inferred from the transformer, representing the numbers of indices of codebook.</font> -&gt; embedding f</em>{z}(1024, n_z), each dimension of c_z is embedded with a 1024d feature -&gt; mini-encoding(b <em> w </em> h, 1024), mini-encoding-indices(b <em> w </em> h, 1) used to search of quantized z in codebook.</li>
<li>understanding of VG: discrete representation, model much training samples in this discrete feature space, each local component (w * h) represents different meaning, combing them to reconstruct different image. The relationship among this component is potential and is to be excavated.</li>
</ul>
</li>
<li><p>transformer</p>
<ul>
<li>training phase: indices<em>{x}(b, w * h) is indices of codebook of input x, indices</em>{c}(b, w <em> h) is indices of codebook of condition c, cating (indicese<em>{c}, indices</em>{x}) to obtain indices_{cat}(b, w </em> h <em> 2), using transformer(indices<em>{cat}[b,-1]) to regress the indices</em>{cat}[-1], supervised by the real indices_{cat}(b, w </em> h * 2), in this way, the autogressive model is built.</li>
<li>tesing phase: giving indices<em>{c} (or indices</em>{c} + part indices<em>{x}) to predict the indices</em>{x} with needed steps.</li>
<li>understanding of transformer<ul>
<li>unconditional senario: using same depth image downsample to obtain indices and upsample to obtain reconstruction image, build complex relationship among discrete codebook of input image.</li>
<li>conditional: using different conditional image to obtain different discrete indices, build complex relationship among discrete codebook of input and discreate codebook of conditional image.</li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li><p>few-shot transforer</p>
<ul>
<li><p>transformation-based: given a input image from a category, selecting another image from the same category as conditional image, using VQGAN to learn same codebook of input image and conditional image. In transformer learning, using indices of conditional image as conditional information to learn relationship among those codebook (including input codebook and conditional codebook)</p>
<ul>
<li>problem: pairs are not unique, don’t like  input image and its corresponding depth image</li>
</ul>
</li>
<li><p>fusion-based: using the indices of several conditional images as conditional information, using transformer to learn the relationship. </p>
</li>
</ul>
</li>
</ul>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2021/04/10/few-shot-image-generation-methods/" rel="next" title="Few-shot Image Generation Methods and Applications">
                <i class="fa fa-chevron-left"></i> Few-shot Image Generation Methods and Applications
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Hongyan</p>
              <p class="site-description motion-element" itemprop="description">New Rhythm</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">55</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">21</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">35</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/hy-zpg" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="mailto:yanhong.sjtu@gmail.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#Generative-Model-Conlusion"><span class="nav-number">1.</span> <span class="nav-text">Generative Model Conlusion</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Taming-Transformers-for-High-Resolution-Image-Synthesis"><span class="nav-number">1.1.</span> <span class="nav-text">Taming Transformers for High-Resolution Image Synthesis</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#Related-paper-NIPS-2017-Neural-Discrete-Representation-Learning"><span class="nav-number">1.1.1.</span> <span class="nav-text">Related paper NIPS 2017: Neural Discrete Representation Learning</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Related-paper-NIPS-2019-Generating-Diverse-High-Fidelity-Images-with-VQ-VAE-2"><span class="nav-number">1.1.2.</span> <span class="nav-text">Related paper NIPS 2019: Generating Diverse High-Fidelity Images with VQ-VAE-2</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Related-paper-CVPR-2020-Learning-Representations-by-Predicting-Bags-of-Visual-Words"><span class="nav-number">1.1.3.</span> <span class="nav-text">Related paper CVPR 2020: Learning Representations by Predicting Bags of Visual Words</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Related-paper-ICML-2020-Predictive-Sampling-with-Forecasting-Autoregressive-Models"><span class="nav-number">1.1.4.</span> <span class="nav-text">Related paper ICML 2020:Predictive Sampling with Forecasting Autoregressive Models</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Related-paper-ICML-2020-Latent-Bernoulli-Autoencoder"><span class="nav-number">1.1.5.</span> <span class="nav-text">Related paper ICML 2020:Latent Bernoulli Autoencoder</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#Related-paper-2021-Multimodal-Controller-for-Generative-Models"><span class="nav-number">1.1.6.</span> <span class="nav-text">Related paper 2021:Multimodal Controller for Generative Models</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Generating-Diverse-Structure-for-Image-Inpainting-With-Hierarchical-VQ-VAE"><span class="nav-number">1.2.</span> <span class="nav-text">Generating Diverse Structure for Image Inpainting With Hierarchical VQ-VAE</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Inspiration"><span class="nav-number">2.</span> <span class="nav-text">Inspiration</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#GIQA-Generated-Image-Quality-Assessment"><span class="nav-number">2.1.</span> <span class="nav-text">GIQA: Generated Image Quality Assessment</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Using-VQGAN"><span class="nav-number">2.2.</span> <span class="nav-text">Using VQGAN</span></a></li></ol></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; 2018 &mdash; <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Hongyan</span>

  
</div>









        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === '') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config("");
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
  


  

  

</body>
</html>
