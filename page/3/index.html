<!DOCTYPE html>



  


<html class="theme-next pisces use-motion" lang="default">
<head><meta name="generator" content="Hexo 3.8.0">
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform">
<meta http-equiv="Cache-Control" content="no-siteapp">
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css">







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css">

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css">


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="Hongyan's Notes, NexT">





  <link rel="alternate" href="/atom.xml" title="Hongyan's Notes" type="application/atom+xml">






<meta name="description" content="New Rhythm">
<meta name="keywords" content="Coding &amp;&amp; Learning">
<meta property="og:type" content="website">
<meta property="og:title" content="Hongyan&#39;s Notes">
<meta property="og:url" content="https://www.yanhong.website/page/3/index.html">
<meta property="og:site_name" content="Hongyan&#39;s Notes">
<meta property="og:description" content="New Rhythm">
<meta property="og:locale" content="default">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Hongyan&#39;s Notes">
<meta name="twitter:description" content="New Rhythm">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Pisces',
    version: '5.1.4',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="https://www.yanhong.website/page/3/">





  <title>Hongyan's Notes</title><!-- hexo-inject:begin --><!-- hexo-inject:end -->
  








</head>

<body itemscope="" itemtype="http://schema.org/WebPage" lang="default">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left 
  page-home">
    <div class="headband"></div>

    <header id="header" class="header" itemscope="" itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Hongyan's Notes</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle">Cheatsheet</p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br>
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br>
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br>
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br>
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-about">
          <a href="/about/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-user"></i> <br>
            
            About
          </a>
        </li>
      
        
        <li class="menu-item menu-item-guestbook">
          <a href="/guestbook" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-question-circle"></i> <br>
            
            Guestbook
          </a>
        </li>
      

      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br>
            
            Search
          </a>
        </li>
      
    </ul>
  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off" placeholder="Searching..." spellcheck="false" type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            
  <section id="posts" class="posts-expand">
    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://www.yanhong.website/2019/09/05/Loss-for-VAE-GAN/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Hongyan">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hongyan's Notes">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/09/05/Loss-for-VAE-GAN/" itemprop="url">Loss for VAE-GAN</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-09-05T15:17:15+08:00">
                2019-09-05
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/Generative-Model/" itemprop="url" rel="index">
                    <span itemprop="name">Generative Model</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  
                </span>
              

              

              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h4 id="L1-loss-for-image-translation"><a href="#L1-loss-for-image-translation" class="headerlink" title="L1 loss for image translation"></a>L1 loss for image translation</h4><p>(Image-to-Image Translation with Conditional Adversarial Networks)[<a href="http://openaccess.thecvf.com/content_cvpr_2017/papers/Isola_Image-To-Image_Translation_With_CVPR_2017_paper.pdf" target="_blank" rel="noopener">http://openaccess.thecvf.com/content_cvpr_2017/papers/Isola_Image-To-Image_Translation_With_CVPR_2017_paper.pdf</a>]</p>
<p>\begin{aligned}<br>\mathcal{L}_{L<em>1}(G)=\mathbb{E}\</em>{x, y, z}\left[|y-G(x, z)|_{1}\right]<br>\end{aligned}</p>
<p>L1 term to force low-frequency correctness, L1 alone leads to reason- able but blurry results ($\lamda = 100$) </p>
<h4 id="Mean-feature-matching-for-image-generation-in-general-setting"><a href="#Mean-feature-matching-for-image-generation-in-general-setting" class="headerlink" title="Mean feature matching for image generation in general setting"></a>Mean feature matching for image generation in general setting</h4><p>(CVAE-GAN: Fine-Grained Image Generation through Asymmetric Training<br>)[<a href="http://openaccess.thecvf.com/content_ICCV_2017/papers/Bao_CVAE-GAN_Fine-Grained_Image_ICCV_2017_paper.pdf" target="_blank" rel="noopener">http://openaccess.thecvf.com/content_ICCV_2017/papers/Bao_CVAE-GAN_Fine-Grained_Image_ICCV_2017_paper.pdf</a>]</p>
<!-- \begin{aligned}
\mathcal{L}\_{G D}=\frac{1}{2}\left\|\mathbb{E}\_{\boldsymbol{x} \sim P_{r}} f_{D}(\boldsymbol{x})-\mathbb{E}\_{\boldsymbol{z} \sim P_{\boldsymbol{z}}} f_{D}(G(\boldsymbol{z}))\right\|\_{2}^{2}
\end{aligned} -->
<p>\begin{equation}<br>\mathcal{L}_{G D}=\frac{1}{2}\left|\mathbb{E}_{\boldsymbol{x} \sim P_{r}} f<em>{D}(\boldsymbol{x})-\mathbb{E}\</em>{\boldsymbol{z} \sim P_{\boldsymbol{z}}} f_{D}(G(\boldsymbol{z}))\right|_{2}^{2}<br>\end{equation}</p>
<p>to deal with the unstable gradient of G</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://www.yanhong.website/2019/08/16/Learning-without-Forgetting/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Hongyan">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hongyan's Notes">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/08/16/Learning-without-Forgetting/" itemprop="url">Learning without Forgetting</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-08-16T15:17:39+08:00">
                2019-08-16
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/Deep-learning/" itemprop="url" rel="index">
                    <span itemprop="name">Deep learning</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  
                </span>
              

              

              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h4 id="problem-definition"><a href="#problem-definition" class="headerlink" title="problem definition"></a>problem definition</h4><p>how to uing new data to train network while preserving the original capabilities</p>
<h4 id="comparable-methods"><a href="#comparable-methods" class="headerlink" title="comparable methods"></a>comparable methods</h4><ul>
<li><p>feature extraction: extracting feature from unchanged parameters trained on old tasks in training new branches for new tasks. however, the shared parameters fail to represent discriminative feature for new task.</p>
</li>
<li><p>fine-tuning FC: shared layers are fixed and finetuning the fc layers. however, the finetuned shared parameters degrade performance on previous tasks because there is not new guidance for original datasets.</p>
</li>
<li><p>joint training: upper bound of the lwf, need original datasets and new datasets.</p>
</li>
</ul>
<h4 id="learning-without-forgetting"><a href="#learning-without-forgetting" class="headerlink" title="learning without forgetting"></a>learning without forgetting</h4><ul>
<li>similar to joint training, don’t need original images and labels</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://www.yanhong.website/2019/07/23/MTL-related-Papers/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Hongyan">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hongyan's Notes">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/07/23/MTL-related-Papers/" itemprop="url">MTL related Papers</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-07-23T19:28:03+08:00">
                2019-07-23
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/Deep-learning/" itemprop="url" rel="index">
                    <span itemprop="name">Deep learning</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  
                </span>
              

              

              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h5 id="Learning-a-Deep-ConvNet-for-Multi-label-Classification-with-Partial-Labels"><a href="#Learning-a-Deep-ConvNet-for-Multi-label-Classification-with-Partial-Labels" class="headerlink" title="Learning a Deep ConvNet for Multi-label Classification with Partial Labels"></a><a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Durand_Learning_a_Deep_ConvNet_for_Multi-Label_Classification_With_Partial_Labels_CVPR_2019_paper.pdf" target="_blank" rel="noopener">Learning a Deep ConvNet for Multi-label Classification with Partial Labels</a></h5><ul>
<li><p>novel: labeling strategies+ new classification loss for leanring from partial labels + curriculum-based missing labels prediction methods</p>
</li>
<li><p>overview of method: from learning label correlations between observed and unobserved partial labels to learn a accurate model used to predict missing labels with a curriculum-based approch.</p>
</li>
<li><p>detail: using fully-connected graph to model correlations between all categories. GNN (message update function[MLP] + hidden state update function[GRU]) + MTL framework, alternative minimized</p>
<p>GNN: nodes represent categoriesthe input is feature extracted from the CNN, output is the predicted labels </p>
</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://www.yanhong.website/2019/07/15/Paper-related-Image-Generation/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Hongyan">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hongyan's Notes">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/07/15/Paper-related-Image-Generation/" itemprop="url">Papers related Few-shot Image Generation</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-07-15T13:38:29+08:00">
                2019-07-15
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/Few-shot-learning/" itemprop="url" rel="index">
                    <span itemprop="name">Few-shot learning</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  
                </span>
              

              

              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h4 id="∆-encoder-an-effective-sample-synthesis-method-for-few-shot-object-recognition"><a href="#∆-encoder-an-effective-sample-synthesis-method-for-few-shot-object-recognition" class="headerlink" title="∆-encoder: an effective sample synthesis method for few-shot object recognition"></a><a href="http://papers.nips.cc/paper/7549-delta-encoder-an-effective-sample-synthesis-method-for-few-shot-object-recognition.pdf" target="_blank" rel="noopener">∆-encoder: an effective sample synthesis method for few-shot object recognition</a></h4><ul>
<li><p>datasets: miniImageNet, CIFAR100, CUB, Caltech-256, APY, SUN and AWA2</p>
</li>
<li><p>how to generate images: learning to extract transferable intra-class deformations between same-class pairs of training examples and using this deformations to generate samples conditioned on few provided examples. </p>
</li>
<li><p>how to aid classification task: constructing feeding augmented images into a simple linear N-class classifier (one dense layer followed by softmax) over about 1024 samples of each category</p>
</li>
<li><p>how to evaluate the effectiveness of generated images: using trained generative model to generate thousands of images conditioned on provided few shots and using those generated images to train a simple classifier (training fc layer with convolutional layers of vgg16 or resnet18 pre-trained on Imagenet, another way is to pre-train those convulutional layers by samples from all training categories). Finally, comparing the results with the accuracy of other few-shot classifiers.</p>
</li>
</ul>
<h4 id="DADA-Deep-Adversarial-Data-Augmentation-for-Extremely-Low-Data-Regime-Classification"><a href="#DADA-Deep-Adversarial-Data-Augmentation-for-Extremely-Low-Data-Regime-Classification" class="headerlink" title="DADA: Deep Adversarial Data Augmentation for Extremely Low Data Regime Classification"></a><a href="https://arxiv.org/pdf/1809.00981.pdf" target="_blank" rel="noopener">DADA: Deep Adversarial Data Augmentation for Extremely Low Data Regime Classification</a></h4><ul>
<li><p>how to generate images: using a class-conditional GAN with a novel loss to generate diverse and category-specific images.</p>
</li>
<li><p>how to aid classification task: coupling the generation process and classification process.  Using 2k loss to distinguish fake data from real data, also to predict the category of fake data and real data. </p>
</li>
<li><p>how to evaluate the effectiveness of generated images: experiments are not conducted in few-shot setting, instead sampling 50-1000 samples of each category to simulate extremely low data regime. comparing the results with other GAN methods, such as Improved-GAN.</p>
</li>
</ul>
<h4 id="FEW-SHOT-AUTOREGRESSIVE-DENSITY-ESTIMATION-TOWARDS-LEARNING-TO-LEARN-DISTRIBUTIONS"><a href="#FEW-SHOT-AUTOREGRESSIVE-DENSITY-ESTIMATION-TOWARDS-LEARNING-TO-LEARN-DISTRIBUTIONS" class="headerlink" title="FEW-SHOT AUTOREGRESSIVE DENSITY ESTIMATION: TOWARDS LEARNING TO LEARN DISTRIBUTIONS"></a><a href="https://arxiv.org/pdf/1710.10304.pdf" target="_blank" rel="noopener">FEW-SHOT AUTOREGRESSIVE DENSITY ESTIMATION: TOWARDS LEARNING TO LEARN DISTRIBUTIONS</a></h4><ul>
<li><p>how to generate images: modified pixelCNN to achieve few-shot density estimation and extend the model to generate natural images.</p>
</li>
<li><p>how to aid classification task: None, only density extimation NLL</p>
</li>
<li><p>how to evaluate the effectiveness of generated images: visualization of the generated images, comparing the results with the NLL of other pixelCNN methods.</p>
</li>
</ul>
<h4 id="The-Variational-Homoencoder-Learning-to-learn-high-capacity-generative-models-from-few-examples"><a href="#The-Variational-Homoencoder-Learning-to-learn-high-capacity-generative-models-from-few-examples" class="headerlink" title="The Variational Homoencoder:Learning to learn high capacity generative models from few examples"></a><a href="https://arxiv.org/pdf/1807.08919.pdf" target="_blank" rel="noopener">The Variational Homoencoder:Learning to learn high capacity generative models from few examples</a></h4><ul>
<li><p>how to generate images: modified VAE to produces a hierarchical latent variable model which better utilises latent variables.</p>
</li>
<li><p>how to aid classification task: classifying an example x the estimation of the expected conditional likelihood under the variational posterior.</p>
</li>
<li><p>how to evaluate the effectiveness of generated images: one-shot generation, one-shot classification and the value of likelihood.</p>
</li>
</ul>
<h4 id="Distribution-Matching-in-Variational-Inference"><a href="#Distribution-Matching-in-Variational-Inference" class="headerlink" title="Distribution Matching in Variational Inference"></a><a href="https://arxiv.org/pdf/1802.06847" target="_blank" rel="noopener">Distribution Matching in Variational Inference</a></h4>
          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://www.yanhong.website/2019/07/09/Combination-between-GAN-and-VAE/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Hongyan">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hongyan's Notes">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/07/09/Combination-between-GAN-and-VAE/" itemprop="url">Combination between GAN and VAE</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-07-09T10:34:44+08:00">
                2019-07-09
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/Generative-Model/" itemprop="url" rel="index">
                    <span itemprop="name">Generative Model</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  
                </span>
              

              

              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="Reference-paper"><a href="#Reference-paper" class="headerlink" title="Reference paper"></a>Reference paper</h3><ul>
<li><p><a href="https://arxiv.org/abs/1703.10155" target="_blank" rel="noopener">CVAE-GAN: Fine-Grained Image Generation through Asymmetric Training</a></p>
</li>
<li><p><a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Zheng_Joint_Discriminative_and_Generative_Learning_for_Person_Re-Identification_CVPR_2019_paper.pdf" target="_blank" rel="noopener">Joint Discriminative and Generative Learning for Person Re-identification</a></p>
</li>
</ul>
<h4 id="the-detail-of-CVAE-GAN"><a href="#the-detail-of-CVAE-GAN" class="headerlink" title="the detail of CVAE-GAN"></a>the detail of CVAE-GAN</h4><ul>
<li><p>solved problem: synthesizing images in fine-grained categories(??)</p>
</li>
<li><p>method: modeling an image as a composition of label and latent attributesin a probabilistic model(??)</p>
</li>
<li><p>novalty: loss design for the discriminator and the generator, the classifier. an encoder network is used to learn the relationship between the latent space and image space.</p>
</li>
<li><p>new objective loss: minimizing the l2 distance of the mean feature and the real data, especially, for multi-class image generation, the generated image need to match the mean feature of real data of that category (<font color="red">similar to our recognition mudule</font>, which can reduce mode collapse??).</p>
</li>
<li><p>to keep the diversity of generated samples, combining the vae and gan, introducing encoder network to map real image to the latent vector. in this way, we explicitly set up the relationship between latent space and image sapce.</p>
</li>
<li><p>CVAE-GAN: the encoder network E(x-&gt;z), the generative network G(z-&gt;\tilt{x}), the discriminatove network D(distinguish x from \tilt{x}), the classifier network C(measure the class probability of the data), cascaded together and trained end-to-end.  </p>
</li>
<li><p>application: generation, inpainting, attribute morphing.</p>
</li>
<li><p>l2 loss and pari-wise feature matching enable the G to generate structure-preserving samples.</p>
</li>
</ul>
<h6 id="formulation"><a href="#formulation" class="headerlink" title="formulation"></a>formulation</h6><ul>
<li><p>mean feature matching in basic GAN (G+D): extracting feature from the discriminator to form mean feature matching to optimize the generator loss(L_GD). also can combining the feature form multi-layer.(<font color="red">can be applied in our dagan</font>)</p>
</li>
<li><p>mean feature mathcing in classifier(G+C): in the classifier, extracting feature from the classifier to form mean feature matching to optimize the generator loss(L_GC),also can combining the feature form multi-layer.(<font color="red">can be applied in our dagan</font>)</p>
</li>
<li><p>pair-wise feature matching: combining l2 loss and pair-wise feature matching loss</p>
</li>
</ul>
<h4 id="the-detail-of-Joint-Discriminative-and-Generative-Learning-for-Person-Re-identification"><a href="#the-detail-of-Joint-Discriminative-and-Generative-Learning-for-Person-Re-identification" class="headerlink" title="the detail of Joint Discriminative and Generative Learning for Person Re-identification"></a>the detail of Joint Discriminative and Generative Learning for Person Re-identification</h4><ul>
<li><p>solved problem: intra-class variations across different cameras.</p>
</li>
<li><p>method: improve learned reid embedding by better using agmented images with a joint framwork that couple the data generation and reid learning end-to-end. the generative module (appearance code and structure code) and the discrinative (sharing appearance code with the generative module). so appearance code plays a role of category-related embedding.</p>
</li>
<li><p>coupling the generative module for image generation and the discriminative module for reid learning.</p>
</li>
</ul>
<ul>
<li><p>reason: let the classification module can ‘see’ these variations (intr-class variations and inter-class variations) during training process.</p>
</li>
<li><p>generate images by swith the appearance code and structure code given the same identities or the different identities.</p>
</li>
</ul>
<h6 id="formulation-1"><a href="#formulation-1" class="headerlink" title="formulation"></a>formulation</h6><ul>
<li><p>generative module: self-identity generation, cross-identity generation.</p>
</li>
<li><p>discriminative module: primary feature learning, fine-grained feature mining, which is codesigned with the generative module.</p>
</li>
</ul>
<h5 id="my-thinking"><a href="#my-thinking" class="headerlink" title="my thinking"></a>my thinking</h5><ul>
<li><p>the generative module is resposible to generate images that contain significant intra-class variations (imagenet dataset including different background, FIGR-8 dataset including different style, omniglot dataset including different style, vggFace including different ages, skin colors). the generative module can be designed as two part including category-related code and category-unrelated code. the generative module is responsible to generate high-quality cross-category images. the category-related module can encode category related semantics, while the category-unrelated module can enclose geometry and posion related structure information</p>
</li>
<li><p>the discriminative module accept the cross-category images generated by the generative module to improve the discriminative module. additionaly, the classification module can be combined with the discriminative module, so the whole process can make contributions to the classification.</p>
</li>
<li><p>‘realism’: generated images should close domain gap between the genrated images ans the real ones. </p>
</li>
<li><p>‘diversity’: generated images should contain sufficient diversity cover ‘unseen’ intra-class variations.</p>
</li>
<li><p>the generative process should align with the classification task to enlarge the gain from the generated images.</p>
</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://www.yanhong.website/2019/07/01/CVAE-GAN/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Hongyan">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hongyan's Notes">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/07/01/CVAE-GAN/" itemprop="url">CVAE-GAN</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-07-01T11:30:07+08:00">
                2019-07-01
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/Generative-Model/" itemprop="url" rel="index">
                    <span itemprop="name">Generative Model</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  
                </span>
              

              

              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h4 id="Paper-Understanding"><a href="#Paper-Understanding" class="headerlink" title="Paper Understanding"></a>Paper Understanding</h4><ul>
<li><a href="https://arxiv.org/abs/1703.10155" target="_blank" rel="noopener">paper links</a></li>
</ul>
<h5 id="problem-method-effect"><a href="#problem-method-effect" class="headerlink" title="problem,method,effect"></a>problem,method,effect</h5><ul>
<li><p>problem: synthesizing images in fine-grained categories.</p>
</li>
<li><p>method: gan+vae<br>gan: asymmetric loss(G_loss[mean discrepancy] + D_loss[cross entropy])<br>vae: encoder(relatio between latent space and real images) -&gt; pairwise feature matching -&gt; keep structure of real images</p>
</li>
<li><p>effect: generating realistic and diverse samples with fine-grained category labels.</p>
</li>
</ul>
<h5 id="detail-explanation"><a href="#detail-explanation" class="headerlink" title="detail explanation"></a>detail explanation</h5><ul>
<li><p>the loss of generator (mean feature matching): minimizing the distance of mean feature to the real images, reduce mode collapse. using an intermediate layer of the discriminator to extract feature for real images and generated fake images. before the last fc layer of the discriminator.</p>
</li>
<li><p>conditional image generation: using mean feature matching.</p>
</li>
<li><p>pairwise feature matching</p>
</li>
</ul>
<h6 id="network-design"><a href="#network-design" class="headerlink" title="network design"></a>network design</h6><p>classification both used in the generator and the discriminator</p>
<p>KL loss is used in the generator</p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://www.yanhong.website/2019/06/19/Simialr-to-DAGAN/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Hongyan">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hongyan's Notes">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/06/19/Simialr-to-DAGAN/" itemprop="url">Paper Reading Related GAN</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-06-19T09:03:25+08:00">
                2019-06-19
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/Generative-Model/" itemprop="url" rel="index">
                    <span itemprop="name">Generative Model</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  
                </span>
              

              

              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="Similar-to-DAGAN"><a href="#Similar-to-DAGAN" class="headerlink" title="Similar to DAGAN"></a>Similar to DAGAN</h3><h4 id="DAGAN"><a href="#DAGAN" class="headerlink" title="DAGAN"></a><a href="https://arxiv.org/pdf/1711.04340.pdf" target="_blank" rel="noopener">DAGAN</a></h4><p>detailed understanding <a href="https://pan.baidu.com/s/1jwQoUsxwjv6Mv7axS5bRRw" target="_blank" rel="noopener">ppt</a></p>
<h4 id="Class-Distinct-and-Class-Mutual-Image-Generation-with-GANs"><a href="#Class-Distinct-and-Class-Mutual-Image-Generation-with-GANs" class="headerlink" title="Class-Distinct and Class-Mutual Image Generation with GANs"></a><a href="https://arxiv.org/pdf/1811.11163.pdf" target="_blank" rel="noopener">Class-Distinct and Class-Mutual Image Generation with GANs</a></h4><ul>
<li><p>problem definition: typically in class-conditional image generation, it is assume that there are no intersections between classes, gan model are optimized to fit discrete class labels. Actually, there are data with ambiguous bundaries in real world in class-overlapping settings.</p>
</li>
<li><p>aims: class-distinct and class-mutual image generation is desigend to selectively generate class-distinct and class-mutual images in a controllable manner.</p>
</li>
<li><p>effects: propose novel families of GANs called class-mixture GAN and class-posterior GAN, mainly redisgining the generator prior and the objective function with auxiliary classifier.</p>
</li>
<li><p>destail: weak supervision(binary class labels), focusing on class specificity, different from typical class-wise interpolation.</p>
<ol>
<li>based on AC-GAN(class-conditional GAN): loss_gan + loss_classification</li>
<li>class label $y_g = r_0y_0 + r_1y_1 + … + r_iy_i$, interpolation in label space ($r_i$ is from Dirichlet distribution)</li>
<li>posterior: r_i = C(y|x_r)</li>
<li>visualization: vary y continuously between classes to generate images</li>
</ol>
</li>
<li><p>conclusion: latent space is effective, simple version in y space, we selected in image space</p>
</li>
</ul>
<h4 id="Attention-based-Fusion-for-Multi-source-Human-Image-Generation"><a href="#Attention-based-Fusion-for-Multi-source-Human-Image-Generation" class="headerlink" title="Attention-based Fusion for Multi-source Human Image Generation"></a><a href="https://arxiv.org/pdf/1905.02655v1.pdf" target="_blank" rel="noopener">Attention-based Fusion for Multi-source Human Image Generation</a></h4><ul>
<li><p>problem: conditioned on a target pose and a set X of source appearance images</p>
</li>
<li><p>effect: complementary images of the same person which usually available at training and at testing time. (similar idea)</p>
</li>
<li><p>novelty: attention-mechanism which selects relevant information from different source image regions. (similar)</p>
</li>
<li><p>U-Net: attention are integrated into U-Net, attention module which is spatial-attention nodule(channel independent), using Enconder-Decoder construction.</p>
</li>
<li><p>dataset: market1501(source appearance) + DeepFashion(pose)</p>
</li>
</ul>
<h3 id="GAN-applied-in-other-leanring-tasks"><a href="#GAN-applied-in-other-leanring-tasks" class="headerlink" title="GAN applied in other leanring tasks"></a>GAN applied in other leanring tasks</h3><h4 id="Progressive-Pose-Attention-Transfer-for-Person-Image-Generation"><a href="#Progressive-Pose-Attention-Transfer-for-Person-Image-Generation" class="headerlink" title="Progressive Pose Attention Transfer for Person Image Generation"></a><a href="https://arxiv.org/pdf/1904.03349.pdf" target="_blank" rel="noopener">Progressive Pose Attention Transfer for Person Image Generation</a></h4><h4 id="Attention-based-Fusion-for-Multi-source-Human-Image-Generation-1"><a href="#Attention-based-Fusion-for-Multi-source-Human-Image-Generation-1" class="headerlink" title="[Attention-based Fusion for Multi-source Human Image Generation"></a>[Attention-based Fusion for Multi-source Human Image Generation</h4><p>](<a href="https://arxiv.org/pdf/1905.02655v1.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1905.02655v1.pdf</a>)</p>
<h4 id="Joint-Discriminative-and-Generative-Learning-for-Person-Re-identification"><a href="#Joint-Discriminative-and-Generative-Learning-for-Person-Re-identification" class="headerlink" title="Joint Discriminative and Generative Learning for Person Re-identification"></a><a href="http://openaccess.thecvf.com/content_CVPR_2019/papers/Zheng_Joint_Discriminative_and_Generative_Learning_for_Person_Re-Identification_CVPR_2019_paper.pdf" target="_blank" rel="noopener">Joint Discriminative and Generative Learning for Person Re-identification</a></h4><ul>
<li><p>problem: significant intra-class variations across different cameras.</p>
</li>
<li><p>motivation: augamenting data to enhance the invariance to input changes, improving learned re-id embeddings by better leveraging the generated data, which achieved by jointly coupling re-id learning and data augmentation end-to-end.</p>
</li>
<li><p>important methods: generative module including appearance code and structure code + discriminative module sharing appearance encoder with generative module. switching the appearance codes or appearance codes to generate high-quality cross-id images which are on line fed back to the appeance encoder and used to improve the discriminative module.</p>
</li>
</ul>
<p>— my understanding: analyzing the essence of problem (for example, intra-class invariance in reid, maybe intra-class invariance is important for all classification tasks), generating corresponding images to improve the performance (generate cross-id images by appearance code and structure code, maybe using two code focused on different content(appeance and structure two codes for reid problem),also it can be beneficial to generate cross-class images).</p>
<ul>
<li>method: </li>
</ul>
<p>for generative module: leveraging latent code (appeance and structure)</p>
<p> $ self-identity: encouraging the appeance encoder to pull appeance code by generating images with seeing cross-images in the same identity, so that intra-class feature variance are reduced, similar to 1-way-1-shot</p>
<p> $ cross-identity: reconstruct appeance and structure codes, soft label, adversarial training, similar to 2-way-1-shot</p>
<p> for discriminative module: (images and generated images are fed into discriminative part)</p>
<p> $ primary feature learning: teacher-student type supervision based on soft label</p>
<p> $ fine-grained feature mining: multi-task learning style</p>
<h4 id="RelGAN-Multi-Domain-Image-to-Image-Translation-via-Relative-Attributes"><a href="#RelGAN-Multi-Domain-Image-to-Image-Translation-via-Relative-Attributes" class="headerlink" title="RelGAN: Multi-Domain Image-to-Image Translation via Relative Attributes"></a><a href="http://openaccess.thecvf.com/content_ICCV_2019/papers/Wu_RelGAN_Multi-Domain_Image-to-Image_Translation_via_Relative_Attributes_ICCV_2019_paper.pdf" target="_blank" rel="noopener">RelGAN: Multi-Domain Image-to-Image Translation via Relative Attributes</a></h4><ul>
<li>matching: discriminator</li>
<li>interpolation: discriminator</li>
</ul>
<h4 id="Guided-Image-to-Image-Translation-with-Bi-Directional-Feature-Transformation"><a href="#Guided-Image-to-Image-Translation-with-Bi-Directional-Feature-Transformation" class="headerlink" title="[Guided Image-to-Image Translation with Bi-Directional Feature Transformation"></a>[Guided Image-to-Image Translation with Bi-Directional Feature Transformation</h4><p>](<a href="http://openaccess.thecvf.com/content_ICCV_2019/papers/AlBahar_Guided_Image-to-Image_Translation_With_Bi-Directional_Feature_Transformation_ICCV_2019_paper.pdf" target="_blank" rel="noopener">http://openaccess.thecvf.com/content_ICCV_2019/papers/AlBahar_Guided_Image-to-Image_Translation_With_Bi-Directional_Feature_Transformation_ICCV_2019_paper.pdf</a>)</p>
<ul>
<li>bidirectional feature extraction</li>
<li>pixel-to-pixel adain</li>
</ul>
<h4 id="AttentionGAN-Unpaired-Image-to-Image-Translation-using-Attention-Guided-Generative-Adversarial-Networks"><a href="#AttentionGAN-Unpaired-Image-to-Image-Translation-using-Attention-Guided-Generative-Adversarial-Networks" class="headerlink" title="[AttentionGAN: Unpaired Image-to-Image Translation using Attention-Guided Generative Adversarial Networks"></a>[AttentionGAN: Unpaired Image-to-Image Translation using Attention-Guided Generative Adversarial Networks</h4><p>](<a href="https://arxiv.org/pdf/1911.11897.pdf" target="_blank" rel="noopener">https://arxiv.org/pdf/1911.11897.pdf</a>)</p>
<ul>
<li><p>abstract: problem(limited in transforming high-level semantics of input images) -&gt; reson(perceive the most discriminative semantic parts between the source and target domains) -&gt; method(identify the most discriminative semantic objects and minimize changes of unwanted parts for semantic manipulation problems without using extra data and models)</p>
</li>
<li><p>introduction: problem(change unwanted parts in the translation, and can also be easily affected by background changes) -&gt; other solutions(ContrastGAN uses object-mask annotations, mask-guided generation train an extra model to detect the object masks and then employ them for image generation) -&gt; Attention GAN (only focus on the foreground of the target do- main and preserve the background of the source domain effectively. the proposed generator learns both foreground and background attentions. It uses the foreground attention to select from the generated out- put for the foreground regions, while uses the background attention to maintain the background informa- tion from the input image)</p>
</li>
<li><p>attention: detail</p>
</li>
</ul>
<h4 id="ELEGANT-Exchanging-Latent-Encodings-with-GAN-for-Transferring-Multiple-Face-Attributes"><a href="#ELEGANT-Exchanging-Latent-Encodings-with-GAN-for-Transferring-Multiple-Face-Attributes" class="headerlink" title="ELEGANT: Exchanging Latent Encodings with GAN for Transferring Multiple Face Attributes"></a><a href="https://arxiv.org/pdf/1803.10562.pdf" target="_blank" rel="noopener">ELEGANT: Exchanging Latent Encodings with GAN for Transferring Multiple Face Attributes</a></h4><ul>
<li>abstract: problem(transfer multiple face attributes simultaneously, low quality of generated images) -&gt; method(receives two images of opposite attributes as inputs, All the attributes are encoded in a disentangled manner in the latent space, which enables us to manipulate several attributes simultaneously, multi-scale discrimina- tors for adversarial training, it can even generate high-quality images with finer details and less artifacts)</li>
</ul>
<h4 id="StarGAN-Unified-Generative-Adversarial-Networks-for-Multi-Domain-Image-to-Image-Translation"><a href="#StarGAN-Unified-Generative-Adversarial-Networks-for-Multi-Domain-Image-to-Image-Translation" class="headerlink" title="StarGAN: Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation"></a><a href="https://arxiv.org/pdf/1711.09020.pdf" target="_blank" rel="noopener">StarGAN: Unified Generative Adversarial Networks for Multi-Domain Image-to-Image Translation</a></h4><ul>
<li>abstract: problem(limited scalability and robustness in handling more than two domains) -&gt; reson -&gt; method(simultaneous training of multiple datasets with different domains within a single network)</li>
</ul>
<h4 id="StarGAN-v2-Diverse-Image-Synthesis-for-Multiple-Domains"><a href="#StarGAN-v2-Diverse-Image-Synthesis-for-Multiple-Domains" class="headerlink" title="StarGAN v2: Diverse Image Synthesis for Multiple Domains"></a><a href="https://arxiv.org/pdf/1912.01865.pdf" target="_blank" rel="noopener">StarGAN v2: Diverse Image Synthesis for Multiple Domains</a></h4><ul>
<li>abstract: problem(diversity of generated images, scalability over multiple domains) -&gt; method(we start from StarGAN and replace its domain label with our proposed domain- specific style code that can represent diverse styles of a specific domain. we introduce two mod- ules, a mapping network and a style encoder. The mapping network learns to transform random Gaussian noise into a style code, while the encoder learns to extract the style code from a given reference image. Considering multiple domains, both modules have multiple output branches, each of which provides style codes for a specific domain.)</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://www.yanhong.website/2019/06/14/Pedestrain-Datasets/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Hongyan">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hongyan's Notes">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/06/14/Pedestrain-Datasets/" itemprop="url">Pedestrain Datasets</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-06-14T09:38:51+08:00">
                2019-06-14
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/Human-Attributes/" itemprop="url" rel="index">
                    <span itemprop="name">Human Attributes</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  
                </span>
              

              

              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h4 id="Links"><a href="#Links" class="headerlink" title="Links"></a>Links</h4><p><a href="https://craigie1996.github.io/2018/05/11/Pedestrian-Attribute-Recognition-调研笔记/" target="_blank" rel="noopener">RAP, PETA, PA-100K</a></p>
<p><a href="https://www.cnblogs.com/wangxiaocvpr/p/10162679.html" target="_blank" rel="noopener">Most dataset and papers links</a></p>
<p><a href="https://blog.csdn.net/Code_Mart/article/details/87721803" target="_blank" rel="noopener">Most dataset</a></p>
<h4 id="Simple-introduction"><a href="#Simple-introduction" class="headerlink" title="Simple introduction"></a>Simple introduction</h4><ul>
<li><p><a href="https://exhibits.stanford.edu/data/catalog/tb980qz1002" target="_blank" rel="noopener">Clothing Attributes Dataset</a>: cloth style(7 categories), ensurely used. accuracy (about 55%) </p>
</li>
<li><p><a href="http://mmlab.ie.cuhk.edu.hk/projects/PETA.html" target="_blank" rel="noopener">PETA Dataset</a>: low-resolution, multi-class(age 4 categories), download. accuracy(16,31,46,&gt;61: 83.8, 78.8,76.4,89.0),19,000 images, about 0.82</p>
</li>
<li><p><a href="https://jurie.users.greyc.fr/datasets/hat.html" target="_blank" rel="noopener">Database of Human Attributes (HAT)</a>: high-resolution, age(multi-classes), having sent email</p>
</li>
<li><p><a href="https://arxiv.org/pdf/1603.07054.pdf" target="_blank" rel="noopener">RAP Dataset</a>: not high-resolution, 3-multi-classes(age 3 categories), waiting to send email.</p>
</li>
<li><p>PA-100K Dataset: binary</p>
</li>
<li><p>WIDER Attribute Dataset: multi-people</p>
</li>
<li><p>Parse27k Dataset: squence, oritation(multi-class), not so much related</p>
</li>
<li><p>CRP Dataset: squence, not human centre</p>
</li>
<li><p>Berkeley-Attributes of People: binary</p>
</li>
<li><p>Deepfashion dataset: cloth related, 289,222 - 50 classes cloth categories: 82%</p>
</li>
</ul>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://www.yanhong.website/2019/06/10/U-Net/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Hongyan">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hongyan's Notes">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/06/10/U-Net/" itemprop="url">Variations of U-Net</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-06-10T14:56:57+08:00">
                2019-06-10
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/Generative-Network/" itemprop="url" rel="index">
                    <span itemprop="name">Generative Network</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  
                </span>
              

              

              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <p>refer to <a href="https://zhuanlan.zhihu.com/p/57530767" target="_blank" rel="noopener">Unet blog</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
      

  

  
  
  

  <article class="post post-type-normal" itemscope="" itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://www.yanhong.website/2019/06/05/Interpolation-in-Latent-Space/">

    <span hidden itemprop="author" itemscope="" itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Hongyan">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope="" itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Hongyan's Notes">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
                
                <a class="post-title-link" href="/2019/06/05/Interpolation-in-Latent-Space/" itemprop="url">Interpolation in Latent Space</a></h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2019-06-05T14:13:03+08:00">
                2019-06-05
              </time>
            

            

            
          </span>

          
            <span class="post-category">
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">In</span>
              
              
                <span itemprop="about" itemscope="" itemtype="http://schema.org/Thing">
                  <a href="/categories/Generative-Model/" itemprop="url" rel="index">
                    <span itemprop="name">Generative Model</span>
                  </a>
                </span>

                
                
              
            </span>
          

          
            
          

          
          

          

          
            <div class="post-wordcount">
              
                
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">Words count in article&#58;</span>
                
                <span title="Words count in article">
                  
                </span>
              

              

              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        
          
            <h3 id="Paper-Reading"><a href="#Paper-Reading" class="headerlink" title="Paper Reading"></a>Paper Reading</h3><p><a href="http://openaccess.thecvf.com/content_ECCV_2018/papers/Hsin-Ying_Lee_Diverse_Image-to-Image_Translation_ECCV_2018_paper.pdf" target="_blank" rel="noopener">Diverse Image-to-Image Translation via Disentangled Representations</a></p>
<ul>
<li>novalty</li>
</ul>
<p>diverse translation between two collections of images without aligned training pairs</p>
<p><a href="https://arxiv.org/pdf/1511.06434.pdf" target="_blank" rel="noopener">UNSUPERVISED REPRESENTATION LEARNING WITH DEEP CONVOLUTIONAL<br>GENERATIVE ADVERSARIAL NETWORKS</a></p>
<p><a href="https://arxiv.org/pdf/1711.05415.pdf" target="_blank" rel="noopener">DNA-GAN: LEARNING DISENTANGLED REPRESEN- TATIONS FROM MULTI-ATTRIBUTE IMAGES</a></p>

          
        
      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      

      

      

      
      
        <div class="post-eof"></div>
      
    </footer>
  </div>
  
  
  
  </article>


    
  </section>

  
  <nav class="pagination">
    <a class="extend prev" rel="prev" href="/page/2/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><a class="page-number" href="/page/2/">2</a><span class="page-number current">3</span><a class="page-number" href="/page/4/">4</a><span class="space">&hellip;</span><a class="page-number" href="/page/6/">6</a><a class="extend next" rel="next" href="/page/4/"><i class="fa fa-angle-right"></i></a>
  </nav>



          </div>
          


          

        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      

      <section class="site-overview-wrap sidebar-panel sidebar-panel-active">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Hongyan</p>
              <p class="site-description motion-element" itemprop="description">New Rhythm</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/">
              
                  <span class="site-state-item-count">55</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-categories">
                <a href="/categories/index.html">
                  <span class="site-state-item-count">21</span>
                  <span class="site-state-item-name">categories</span>
                </a>
              </div>
            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">35</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          
            <div class="feed-link motion-element">
              <a href="/atom.xml" rel="alternate">
                <i class="fa fa-rss"></i>
                RSS
              </a>
            </div>
          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/hy-zpg" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="mailto:yanhong.sjtu@gmail.com" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          

          

        </div>
      </section>

      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; 2018 &mdash; <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Hongyan</span>

  
</div>









        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script>



  

  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === '') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config("");
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
  


  

  

</body>
</html>
