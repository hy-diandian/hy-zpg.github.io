{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"source/CNAME","path":"CNAME","modified":1,"renderable":0}],"Cache":[{"_id":"source/CNAME","hash":"3dea51f70503b94bd4c04b70abfeb1a80f5f21fe","modified":1554704455948},{"_id":"source/_posts/Critical-Points-in-Multitask-0.md","hash":"527449436e16b37e33450e5c5b5f2c1ac1943b44","modified":1554704455948},{"_id":"source/_posts/Cross-stitch-network.md","hash":"835c20d7be180a1b685131e307dbd01684be65a7","modified":1554704455948},{"_id":"source/_posts/Cross_entropy_loss.md","hash":"934c0710fa455545b113dba68be48ae38e3556ea","modified":1554704455948},{"_id":"source/_posts/Density-Distribution.md","hash":"2a923e4dfd6546f9a7eaf88e164029af007f48c1","modified":1554704455948},{"_id":"source/_posts/Few-shot-Image-generation.md","hash":"4ce879e1fd1b60bd8c6edda37deea0bbeb3607fe","modified":1554705260779},{"_id":"source/_posts/GAN.md","hash":"eaa55e87f1f4663a456b7d83a777b8b58f45a342","modified":1554705085153},{"_id":"source/_posts/GMM.md","hash":"95af34d64ce3097b06ebd9efefd2d7f21a5a49ac","modified":1554704455948},{"_id":"source/_posts/Heterogeneous-Multitask.md","hash":"a8df6d1f3c55a771bfcfebafcae7aed2c1b67241","modified":1554704455948},{"_id":"source/_posts/Manifold-Learning.md","hash":"eecdac207771d283aaea710de3357e507676880c","modified":1554704455948},{"_id":"source/_posts/Numpy learning.md","hash":"77ccaf62a6359bf07decf3bb1894337883c6d848","modified":1554704455948},{"_id":"source/_posts/Parameters-Selection-for-Pseudo.md","hash":"b8fc1ac8d3ea565e2c5241873661956609c382cb","modified":1554704455948},{"_id":"source/_posts/Pseudo-purity&distribution-distance.md","hash":"aff2d0be0878c44d82a0c6ff1ea5e0c767225b98","modified":1554704455948},{"_id":"source/_posts/Research-Point-Multitask.md","hash":"44555d1bc4e939b98013dfe843cfbe8d4fd23d75","modified":1554704455948},{"_id":"source/_posts/Semi-Heteroneous-Multitask-Baseline.md","hash":"6b8fe198a0a7d692b3bc7510dc9226f9ec377657","modified":1554704455948},{"_id":"source/_posts/Semi-MTL-Related.md","hash":"2a4adffa3b275cfcf0395338459b0c31e7733bbb","modified":1554704455948},{"_id":"source/_posts/numpy-learning.md","hash":"77ccaf62a6359bf07decf3bb1894337883c6d848","modified":1554704455948},{"_id":"source/categories/index.md","hash":"2e2d01352952efd4bceb3d0d0a02817886c4bf80","modified":1554704455948},{"_id":"source/_posts/Why-How-Pseudo.md","hash":"c399395f7aa2af7b37cf4cf3c3cdcfe2650f92e6","modified":1554704455948},{"_id":"source/about/index.md","hash":"fb2e01d0d880651ff20f4d27b89adc21c8e297bd","modified":1554704455948},{"_id":"source/guestbook/index.md","hash":"137d73f402bb5b46050b1b7bc287423aa1e5dd26","modified":1554704455948},{"_id":"source/tags/index.md","hash":"094aeac04a8812ed812a17df698a7eca95b85a9b","modified":1554704455948},{"_id":"public/baidu_urls.txt","hash":"3bd1b4e25a47975c5fa69e6aec7f466a5697509e","modified":1554705319093},{"_id":"public/atom.xml","hash":"84f439aab7f0419fc35b44d5c317b93a39cb0975","modified":1554705319093},{"_id":"public/search.xml","hash":"76b3d9b483baf212e9e7646ac28dbc18259210f7","modified":1554705319093},{"_id":"public/sitemap.xml","hash":"4c0670a73f71e4d69032dc9cf44e0cf5d26b3f14","modified":1554705319093},{"_id":"public/baidusitemap.xml","hash":"583b3334120c673fa807c2e965f2b0c18ac5e155","modified":1554705319093},{"_id":"public/categories/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1554705319095},{"_id":"public/about/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1554705319095},{"_id":"public/guestbook/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1554705319095},{"_id":"public/tags/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1554705319095},{"_id":"public/2019/04/08/GAN/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1554705319095},{"_id":"public/2019/04/04/Few-shot-Image-generation/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1554705319096},{"_id":"public/2019/03/18/Manifold-Learning/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1554705319096},{"_id":"public/2019/03/09/Semi-MTL-Related/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1554705319096},{"_id":"public/2019/02/28/Semi-Heteroneous-Multitask-Baseline/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1554705319096},{"_id":"public/2019/02/28/Research-Point-Multitask/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1554705319096},{"_id":"public/2019/02/28/Critical-Points-in-Multitask-0/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1554705319096},{"_id":"public/2019/02/27/Parameters-Selection-for-Pseudo/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1554705319096},{"_id":"public/2019/02/27/Cross-stitch-network/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1554705319096},{"_id":"public/2019/02/26/Heterogeneous-Multitask/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1554705319096},{"_id":"public/2019/02/22/Why-How-Pseudo/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1554705319096},{"_id":"public/2019/02/21/Density-Distribution/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1554705319096},{"_id":"public/2019/02/17/Pseudo-purity&distribution-distance/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1554705319096},{"_id":"public/2019/01/16/Cross_entropy_loss/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1554705319096},{"_id":"public/2019/01/15/GMM/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1554705319096},{"_id":"public/2019/01/14/Numpy learning/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1554705319096},{"_id":"public/2019/01/14/numpy-learning/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1554705319096},{"_id":"public/archives/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1554705319096},{"_id":"public/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1554705319096},{"_id":"public/page/2/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1554705319096},{"_id":"public/categories/Deep-learning/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1554705319096},{"_id":"public/categories/Theory/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1554705319096},{"_id":"public/categories/Meta-learning/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1554705319096},{"_id":"public/categories/Codes/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1554705319096},{"_id":"public/tags/multitask/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1554705319097},{"_id":"public/tags/tensorflow/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1554705319097},{"_id":"public/tags/pesudo-labels/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1554705319097},{"_id":"public/tags/few-shot-learning/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1554705319097},{"_id":"public/tags/pseudo-labels/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1554705319097},{"_id":"public/tags/feature-regularization/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1554705319097},{"_id":"public/tags/numpy/index.html","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1554705319097},{"_id":"public/CNAME","hash":"3dea51f70503b94bd4c04b70abfeb1a80f5f21fe","modified":1554705319098}],"Category":[{"name":"Deep learning","_id":"cju7zelmj0004qrm7idghmneu"},{"name":"Theory","_id":"cju7zelmu000kqrm7kksln246"},{"name":"Meta-learning","_id":"cju7zelmw000sqrm7cq93tgv9"},{"name":"Codes","_id":"cju7zelmz0018qrm7fgwr02l6"}],"Data":[],"Page":[{"title":"categories","date":"2019-02-27T01:49:19.000Z","type":"categories","_content":"","source":"categories/index.md","raw":"---\ntitle: categories\ndate: 2019-02-27 09:49:19\ntype: \"categories\"\n---\n","updated":"2019-04-08T06:20:55.948Z","path":"categories/index.html","comments":1,"layout":"page","_id":"cju7zelmh0001qrm7tkbnshpy","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"Curriculum Vitae","date":"2019-02-16T08:52:06.000Z","_content":"","source":"about/index.md","raw":"---\ntitle: Curriculum Vitae\ndate: 2019-02-16 16:52:06\n---\n","updated":"2019-04-08T06:20:55.948Z","path":"about/index.html","comments":1,"layout":"page","_id":"cju7zelmi0003qrm7doymc8zk","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"guestbook","date":"2019-02-16T08:54:10.000Z","_content":"","source":"guestbook/index.md","raw":"---\ntitle: guestbook\ndate: 2019-02-16 16:54:10\n---\n","updated":"2019-04-08T06:20:55.948Z","path":"guestbook/index.html","comments":1,"layout":"page","_id":"cju7zeln3001vqrm71upcp718","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"Tags","date":"2019-02-16T08:52:23.000Z","type":"tags","layout":"tags","_content":"","source":"tags/index.md","raw":"---\ntitle: Tags\ndate: 2019-02-16 16:52:23\ntype: 'tags'\nlayout: 'tags'\n---\n","updated":"2019-04-08T06:20:55.948Z","path":"tags/index.html","comments":1,"_id":"cju7zeln4001wqrm7k02888hw","content":"","site":{"data":{}},"excerpt":"","more":""}],"Post":[{"title":"Critical-Points-in-Multitask","date":"2019-02-28T03:16:26.000Z","_content":"\n## Several tips for heterogeneous multitask learning\n* core problem - heterogeneity structrues in tasks[age and gender], source[documents and images], feature[generated from model for classification or regression tasks], samples[one labeled with age while another annotated with gender]\n\n1. network with suitabel initialization and learning rate\n2. construct feature relationship in network, offering trainable parameters, refer to [cross-stitch network]\n3. feature selection, sparsity and factorization, which means that the specific branch layers to ontain task-specific fearures in a common feature space.\n\n## Research directions\n* feature relationship from the level of network.\n* feature processing from the level fo feature space, such as selection, sparsity and facorization.\n","source":"_posts/Critical-Points-in-Multitask-0.md","raw":"---\ntitle: Critical-Points-in-Multitask\ndate: 2019-02-28 11:16:26\ntags: multitask\ncategories: Deep learning\n---\n\n## Several tips for heterogeneous multitask learning\n* core problem - heterogeneity structrues in tasks[age and gender], source[documents and images], feature[generated from model for classification or regression tasks], samples[one labeled with age while another annotated with gender]\n\n1. network with suitabel initialization and learning rate\n2. construct feature relationship in network, offering trainable parameters, refer to [cross-stitch network]\n3. feature selection, sparsity and factorization, which means that the specific branch layers to ontain task-specific fearures in a common feature space.\n\n## Research directions\n* feature relationship from the level of network.\n* feature processing from the level fo feature space, such as selection, sparsity and facorization.\n","slug":"Critical-Points-in-Multitask-0","published":1,"updated":"2019-04-08T06:20:55.948Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cju7zelme0000qrm747ezmxjg","content":"<h2 id=\"Several-tips-for-heterogeneous-multitask-learning\"><a href=\"#Several-tips-for-heterogeneous-multitask-learning\" class=\"headerlink\" title=\"Several tips for heterogeneous multitask learning\"></a>Several tips for heterogeneous multitask learning</h2><ul>\n<li>core problem - heterogeneity structrues in tasks[age and gender], source[documents and images], feature[generated from model for classification or regression tasks], samples[one labeled with age while another annotated with gender]</li>\n</ul>\n<ol>\n<li>network with suitabel initialization and learning rate</li>\n<li>construct feature relationship in network, offering trainable parameters, refer to [cross-stitch network]</li>\n<li>feature selection, sparsity and factorization, which means that the specific branch layers to ontain task-specific fearures in a common feature space.</li>\n</ol>\n<h2 id=\"Research-directions\"><a href=\"#Research-directions\" class=\"headerlink\" title=\"Research directions\"></a>Research directions</h2><ul>\n<li>feature relationship from the level of network.</li>\n<li>feature processing from the level fo feature space, such as selection, sparsity and facorization.</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"Several-tips-for-heterogeneous-multitask-learning\"><a href=\"#Several-tips-for-heterogeneous-multitask-learning\" class=\"headerlink\" title=\"Several tips for heterogeneous multitask learning\"></a>Several tips for heterogeneous multitask learning</h2><ul>\n<li>core problem - heterogeneity structrues in tasks[age and gender], source[documents and images], feature[generated from model for classification or regression tasks], samples[one labeled with age while another annotated with gender]</li>\n</ul>\n<ol>\n<li>network with suitabel initialization and learning rate</li>\n<li>construct feature relationship in network, offering trainable parameters, refer to [cross-stitch network]</li>\n<li>feature selection, sparsity and factorization, which means that the specific branch layers to ontain task-specific fearures in a common feature space.</li>\n</ol>\n<h2 id=\"Research-directions\"><a href=\"#Research-directions\" class=\"headerlink\" title=\"Research directions\"></a>Research directions</h2><ul>\n<li>feature relationship from the level of network.</li>\n<li>feature processing from the level fo feature space, such as selection, sparsity and facorization.</li>\n</ul>\n"},{"title":"Cross-stitch-network","date":"2019-02-27T06:03:23.000Z","_content":"\n## cross-stitch-network\n> reference CVPR 2016[Cross-stitch Networks for Multi-task Learning](https://arxiv.org/pdf/1604.03539.pdf) [tensorflow-code](https://github.com/helloyide/Cross-stitch-Networks-for-Multi-task-Learning/blob/master/gender_age_multi_task_learning.py)\n\n* problem: existing multi-task approaches rely on enumerating multiple net- work architectures specific to the tasks at hand, that do not generalize.\n* method: proposing a new sharing unit: “cross-stitch” unit. These units combine the activations from multiple networks.\n\n\n## self-defined cross-stitch layer in keras with tensorflow as backbone\n``` bash\nclass Cross_stitch(Layer):\n\t# basic parameter setting\n    def __init__(self,input_shape_1,input_shape_2, **kwargs):\n        super(Cross_stitch, self).__init__(**kwargs)\n        self.input_shape_1 = input_shape_1\n        self.input_shape_2 = input_shape_2\n    # apply trainable parameters in network, similar to convolutional layer \n    # shape is important, you must to calculate specific size based on the shape of input and output\n    # in cross-stitch network: [xa,xb]*[papameter]=[xa',xb'], the detail refer to the paper\n    def build(self, input_shape):\n        shape = self.input_shape_1 + self.input_shape_2\n        self.cross_stitch = self.add_weight(\n            shape=(shape,shape),\n            initializer=tf.initializers.identity(),\n            name='cross_stitch')\n        self.built = True\n    # conduct implement of the detailed algorithm calculation\n    # inputs represent the output of upper layer, such as x=Dense(parameter)(inputs)\n    def call(self,inputs):\n        inputss = tf.concat((inputs[0], inputs[1]), axis=1)\n        output = tf.matmul(inputss, self.cross_stitch)\n        output1 = tf.reshape(output[:,:self.input_shape_1],shape=[-1,self.input_shape_1])\n        output2 = tf.reshape(output[:,self.input_shape_2:],shape=[-1,self.input_shape_2])\n        return [output1, output2]\n    def get_config(self):\n        config = {'input_shape_1': self.input_shape_1,'input_shape_2': self.input_shape_2}\n        base_config = super(Cross_stitch, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n```","source":"_posts/Cross-stitch-network.md","raw":"---\ntitle: Cross-stitch-network\ndate: 2019-02-27 14:03:23\ntags: multitask\ncategories: Deep learning\n---\n\n## cross-stitch-network\n> reference CVPR 2016[Cross-stitch Networks for Multi-task Learning](https://arxiv.org/pdf/1604.03539.pdf) [tensorflow-code](https://github.com/helloyide/Cross-stitch-Networks-for-Multi-task-Learning/blob/master/gender_age_multi_task_learning.py)\n\n* problem: existing multi-task approaches rely on enumerating multiple net- work architectures specific to the tasks at hand, that do not generalize.\n* method: proposing a new sharing unit: “cross-stitch” unit. These units combine the activations from multiple networks.\n\n\n## self-defined cross-stitch layer in keras with tensorflow as backbone\n``` bash\nclass Cross_stitch(Layer):\n\t# basic parameter setting\n    def __init__(self,input_shape_1,input_shape_2, **kwargs):\n        super(Cross_stitch, self).__init__(**kwargs)\n        self.input_shape_1 = input_shape_1\n        self.input_shape_2 = input_shape_2\n    # apply trainable parameters in network, similar to convolutional layer \n    # shape is important, you must to calculate specific size based on the shape of input and output\n    # in cross-stitch network: [xa,xb]*[papameter]=[xa',xb'], the detail refer to the paper\n    def build(self, input_shape):\n        shape = self.input_shape_1 + self.input_shape_2\n        self.cross_stitch = self.add_weight(\n            shape=(shape,shape),\n            initializer=tf.initializers.identity(),\n            name='cross_stitch')\n        self.built = True\n    # conduct implement of the detailed algorithm calculation\n    # inputs represent the output of upper layer, such as x=Dense(parameter)(inputs)\n    def call(self,inputs):\n        inputss = tf.concat((inputs[0], inputs[1]), axis=1)\n        output = tf.matmul(inputss, self.cross_stitch)\n        output1 = tf.reshape(output[:,:self.input_shape_1],shape=[-1,self.input_shape_1])\n        output2 = tf.reshape(output[:,self.input_shape_2:],shape=[-1,self.input_shape_2])\n        return [output1, output2]\n    def get_config(self):\n        config = {'input_shape_1': self.input_shape_1,'input_shape_2': self.input_shape_2}\n        base_config = super(Cross_stitch, self).get_config()\n        return dict(list(base_config.items()) + list(config.items()))\n```","slug":"Cross-stitch-network","published":1,"updated":"2019-04-08T06:20:55.948Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cju7zelmh0002qrm7ksvv3je2","content":"<h2 id=\"cross-stitch-network\"><a href=\"#cross-stitch-network\" class=\"headerlink\" title=\"cross-stitch-network\"></a>cross-stitch-network</h2><blockquote>\n<p>reference CVPR 2016<a href=\"https://arxiv.org/pdf/1604.03539.pdf\" target=\"_blank\" rel=\"noopener\">Cross-stitch Networks for Multi-task Learning</a> <a href=\"https://github.com/helloyide/Cross-stitch-Networks-for-Multi-task-Learning/blob/master/gender_age_multi_task_learning.py\" target=\"_blank\" rel=\"noopener\">tensorflow-code</a></p>\n</blockquote>\n<ul>\n<li>problem: existing multi-task approaches rely on enumerating multiple net- work architectures specific to the tasks at hand, that do not generalize.</li>\n<li>method: proposing a new sharing unit: “cross-stitch” unit. These units combine the activations from multiple networks.</li>\n</ul>\n<h2 id=\"self-defined-cross-stitch-layer-in-keras-with-tensorflow-as-backbone\"><a href=\"#self-defined-cross-stitch-layer-in-keras-with-tensorflow-as-backbone\" class=\"headerlink\" title=\"self-defined cross-stitch layer in keras with tensorflow as backbone\"></a>self-defined cross-stitch layer in keras with tensorflow as backbone</h2><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">class Cross_stitch(Layer):</span><br><span class=\"line\">\t<span class=\"comment\"># basic parameter setting</span></span><br><span class=\"line\">    def __init__(self,input_shape_1,input_shape_2, **kwargs):</span><br><span class=\"line\">        super(Cross_stitch, self).__init__(**kwargs)</span><br><span class=\"line\">        self.input_shape_1 = input_shape_1</span><br><span class=\"line\">        self.input_shape_2 = input_shape_2</span><br><span class=\"line\">    <span class=\"comment\"># apply trainable parameters in network, similar to convolutional layer </span></span><br><span class=\"line\">    <span class=\"comment\"># shape is important, you must to calculate specific size based on the shape of input and output</span></span><br><span class=\"line\">    <span class=\"comment\"># in cross-stitch network: [xa,xb]*[papameter]=[xa',xb'], the detail refer to the paper</span></span><br><span class=\"line\">    def build(self, input_shape):</span><br><span class=\"line\">        shape = self.input_shape_1 + self.input_shape_2</span><br><span class=\"line\">        self.cross_stitch = self.add_weight(</span><br><span class=\"line\">            shape=(shape,shape),</span><br><span class=\"line\">            initializer=tf.initializers.identity(),</span><br><span class=\"line\">            name=<span class=\"string\">'cross_stitch'</span>)</span><br><span class=\"line\">        self.built = True</span><br><span class=\"line\">    <span class=\"comment\"># conduct implement of the detailed algorithm calculation</span></span><br><span class=\"line\">    <span class=\"comment\"># inputs represent the output of upper layer, such as x=Dense(parameter)(inputs)</span></span><br><span class=\"line\">    def call(self,inputs):</span><br><span class=\"line\">        inputss = tf.concat((inputs[0], inputs[1]), axis=1)</span><br><span class=\"line\">        output = tf.matmul(inputss, self.cross_stitch)</span><br><span class=\"line\">        output1 = tf.reshape(output[:,:self.input_shape_1],shape=[-1,self.input_shape_1])</span><br><span class=\"line\">        output2 = tf.reshape(output[:,self.input_shape_2:],shape=[-1,self.input_shape_2])</span><br><span class=\"line\">        <span class=\"built_in\">return</span> [output1, output2]</span><br><span class=\"line\">    def get_config(self):</span><br><span class=\"line\">        config = &#123;<span class=\"string\">'input_shape_1'</span>: self.input_shape_1,<span class=\"string\">'input_shape_2'</span>: self.input_shape_2&#125;</span><br><span class=\"line\">        base_config = super(Cross_stitch, self).get_config()</span><br><span class=\"line\">        <span class=\"built_in\">return</span> dict(list(base_config.items()) + list(config.items()))</span><br></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"","more":"<h2 id=\"cross-stitch-network\"><a href=\"#cross-stitch-network\" class=\"headerlink\" title=\"cross-stitch-network\"></a>cross-stitch-network</h2><blockquote>\n<p>reference CVPR 2016<a href=\"https://arxiv.org/pdf/1604.03539.pdf\" target=\"_blank\" rel=\"noopener\">Cross-stitch Networks for Multi-task Learning</a> <a href=\"https://github.com/helloyide/Cross-stitch-Networks-for-Multi-task-Learning/blob/master/gender_age_multi_task_learning.py\" target=\"_blank\" rel=\"noopener\">tensorflow-code</a></p>\n</blockquote>\n<ul>\n<li>problem: existing multi-task approaches rely on enumerating multiple net- work architectures specific to the tasks at hand, that do not generalize.</li>\n<li>method: proposing a new sharing unit: “cross-stitch” unit. These units combine the activations from multiple networks.</li>\n</ul>\n<h2 id=\"self-defined-cross-stitch-layer-in-keras-with-tensorflow-as-backbone\"><a href=\"#self-defined-cross-stitch-layer-in-keras-with-tensorflow-as-backbone\" class=\"headerlink\" title=\"self-defined cross-stitch layer in keras with tensorflow as backbone\"></a>self-defined cross-stitch layer in keras with tensorflow as backbone</h2><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">class Cross_stitch(Layer):</span><br><span class=\"line\">\t<span class=\"comment\"># basic parameter setting</span></span><br><span class=\"line\">    def __init__(self,input_shape_1,input_shape_2, **kwargs):</span><br><span class=\"line\">        super(Cross_stitch, self).__init__(**kwargs)</span><br><span class=\"line\">        self.input_shape_1 = input_shape_1</span><br><span class=\"line\">        self.input_shape_2 = input_shape_2</span><br><span class=\"line\">    <span class=\"comment\"># apply trainable parameters in network, similar to convolutional layer </span></span><br><span class=\"line\">    <span class=\"comment\"># shape is important, you must to calculate specific size based on the shape of input and output</span></span><br><span class=\"line\">    <span class=\"comment\"># in cross-stitch network: [xa,xb]*[papameter]=[xa',xb'], the detail refer to the paper</span></span><br><span class=\"line\">    def build(self, input_shape):</span><br><span class=\"line\">        shape = self.input_shape_1 + self.input_shape_2</span><br><span class=\"line\">        self.cross_stitch = self.add_weight(</span><br><span class=\"line\">            shape=(shape,shape),</span><br><span class=\"line\">            initializer=tf.initializers.identity(),</span><br><span class=\"line\">            name=<span class=\"string\">'cross_stitch'</span>)</span><br><span class=\"line\">        self.built = True</span><br><span class=\"line\">    <span class=\"comment\"># conduct implement of the detailed algorithm calculation</span></span><br><span class=\"line\">    <span class=\"comment\"># inputs represent the output of upper layer, such as x=Dense(parameter)(inputs)</span></span><br><span class=\"line\">    def call(self,inputs):</span><br><span class=\"line\">        inputss = tf.concat((inputs[0], inputs[1]), axis=1)</span><br><span class=\"line\">        output = tf.matmul(inputss, self.cross_stitch)</span><br><span class=\"line\">        output1 = tf.reshape(output[:,:self.input_shape_1],shape=[-1,self.input_shape_1])</span><br><span class=\"line\">        output2 = tf.reshape(output[:,self.input_shape_2:],shape=[-1,self.input_shape_2])</span><br><span class=\"line\">        <span class=\"built_in\">return</span> [output1, output2]</span><br><span class=\"line\">    def get_config(self):</span><br><span class=\"line\">        config = &#123;<span class=\"string\">'input_shape_1'</span>: self.input_shape_1,<span class=\"string\">'input_shape_2'</span>: self.input_shape_2&#125;</span><br><span class=\"line\">        base_config = super(Cross_stitch, self).get_config()</span><br><span class=\"line\">        <span class=\"built_in\">return</span> dict(list(base_config.items()) + list(config.items()))</span><br></pre></td></tr></table></figure>"},{"title":"Cross_entropy_loss","date":"2019-01-16T02:37:13.000Z","_content":"\n## Cross entropy loss calculation in different circumstances\n\n* Cross_entropy_loss in tensorflow\n``` bash\ndef softmax_cross_entropy_with_logits(\n    _sentinel=None,  # pylint: disable=invalid-name\n    labels=None,\n    logits=None,\n    dim=-1,\n    name=None):\n  _ensure_xent_args(\"softmax_cross_entropy_with_logits\", _sentinel, labels,\n                    logits)\n  with ops.name_scope(name, \"softmax_cross_entropy_with_logits_sg\",\n                      [logits, labels]) as name:\n    labels = array_ops.stop_gradient(labels, name=\"labels_stop_gradient\")\n  return softmax_cross_entropy_with_logits_v2(\n      labels=labels, logits=logits, dim=dim, name=name)\ndef softmax_cross_entropy_with_logits_v2(\n    _sentinel=None,  # pylint: disable=invalid-name\n    labels=None,\n    logits=None,\n    dim=-1,\n    name=None):\n  _ensure_xent_args(\"softmax_cross_entropy_with_logits\", _sentinel, labels,\n                    logits)\n  with ops.name_scope(name, \"softmax_cross_entropy_with_logits\",\n                      [logits, labels]) as name:\n    logits = ops.convert_to_tensor(logits, name=\"logits\")\n    labels = ops.convert_to_tensor(labels, name=\"labels\")\n    convert_to_float32 = (\n        logits.dtype == dtypes.float16 or logits.dtype == dtypes.bfloat16)\n    precise_logits = math_ops.cast(\n        logits, dtypes.float32) if convert_to_float32 else logits\n    # labels and logits must be of the same type\n    labels = math_ops.cast(labels, precise_logits.dtype)\n    input_rank = array_ops.rank(precise_logits)\n    shape = logits.get_shape()\n    if dim is not -1:\n      def _move_dim_to_end(tensor, dim_index, rank):\n        return array_ops.transpose(\n            tensor,\n            array_ops.concat([\n                math_ops.range(dim_index),\n                math_ops.range(dim_index + 1, rank), [dim_index]\n            ], 0))\n      precise_logits = _move_dim_to_end(precise_logits, dim, input_rank)\n      labels = _move_dim_to_end(labels, dim, input_rank)\n    input_shape = array_ops.shape(precise_logits)\n    precise_logits = _flatten_outer_dims(precise_logits)\n    labels = _flatten_outer_dims(labels)\n    cost, unused_backprop = gen_nn_ops.softmax_cross_entropy_with_logits(\n        precise_logits, labels, name=name)\n    output_shape = array_ops.slice(input_shape, [0],\n                                   [math_ops.subtract(input_rank, 1)])\n    cost = array_ops.reshape(cost, output_shape)\n    if not context.executing_eagerly(\n    ) and shape is not None and shape.dims is not None:\n      shape = shape.as_list()\n      del shape[dim]\n      cost.set_shape(shape)\n    if convert_to_float32:\n      return math_ops.cast(cost, logits.dtype)\n    else:\n      return cost\n```\n\n* Cross_entropy_loss in Keras with backbone of tensorflow\n``` bash\ntf.nn.softmax_cross_entropy_with_logits(labels=target,logits=output)\n```\n\n## The reason why the value of loss become inf\n* log(x) when x -> 0\n* learning rate is too high\n* some parameters of Nel appear inf\n* input data appear inf\n* the parameters of model no longer updated \n\n\n## Cross_entropy_loss with missing labels\n\n* leveraging fixed zero array or ones array as ground truth and generating mask in loss function\n``` bash\ndef mask_cross_entropy_loss(y_true,y_pred):\n\tmask=K.all(K.equal(y_true,0),axis=-1)\n\tmask=1-K.cast(mask,K.floatx())\n\tloss = K.categorical_crossentropy(y_true,y_pred)*mask\n\treturn (K.sum(loss)/K.sum(mask)\n``` \n\n* corresponding accuracy with mask\n``` bash\ndef mask_cross_entropy_acc(y_true,y_pred):\n\tmask=K.all(K.equal(y_true,0),axis=-1)\n\tmask=1-K.cast(mask,K.floatx())\n\tacc = K.cast(K.equal(K.argmax(y_true,axis=-1),K.argmax(y_pred,axis=-1)),K.floatx()))*mask\n\treturn (K.sum(acc)/K.sum(mask)\n``` \n","source":"_posts/Cross_entropy_loss.md","raw":"---\ntitle: Cross_entropy_loss\ndate: 2019-01-16 10:37:13\ntags: tensorflow\ncategories: Deep learning\n---\n\n## Cross entropy loss calculation in different circumstances\n\n* Cross_entropy_loss in tensorflow\n``` bash\ndef softmax_cross_entropy_with_logits(\n    _sentinel=None,  # pylint: disable=invalid-name\n    labels=None,\n    logits=None,\n    dim=-1,\n    name=None):\n  _ensure_xent_args(\"softmax_cross_entropy_with_logits\", _sentinel, labels,\n                    logits)\n  with ops.name_scope(name, \"softmax_cross_entropy_with_logits_sg\",\n                      [logits, labels]) as name:\n    labels = array_ops.stop_gradient(labels, name=\"labels_stop_gradient\")\n  return softmax_cross_entropy_with_logits_v2(\n      labels=labels, logits=logits, dim=dim, name=name)\ndef softmax_cross_entropy_with_logits_v2(\n    _sentinel=None,  # pylint: disable=invalid-name\n    labels=None,\n    logits=None,\n    dim=-1,\n    name=None):\n  _ensure_xent_args(\"softmax_cross_entropy_with_logits\", _sentinel, labels,\n                    logits)\n  with ops.name_scope(name, \"softmax_cross_entropy_with_logits\",\n                      [logits, labels]) as name:\n    logits = ops.convert_to_tensor(logits, name=\"logits\")\n    labels = ops.convert_to_tensor(labels, name=\"labels\")\n    convert_to_float32 = (\n        logits.dtype == dtypes.float16 or logits.dtype == dtypes.bfloat16)\n    precise_logits = math_ops.cast(\n        logits, dtypes.float32) if convert_to_float32 else logits\n    # labels and logits must be of the same type\n    labels = math_ops.cast(labels, precise_logits.dtype)\n    input_rank = array_ops.rank(precise_logits)\n    shape = logits.get_shape()\n    if dim is not -1:\n      def _move_dim_to_end(tensor, dim_index, rank):\n        return array_ops.transpose(\n            tensor,\n            array_ops.concat([\n                math_ops.range(dim_index),\n                math_ops.range(dim_index + 1, rank), [dim_index]\n            ], 0))\n      precise_logits = _move_dim_to_end(precise_logits, dim, input_rank)\n      labels = _move_dim_to_end(labels, dim, input_rank)\n    input_shape = array_ops.shape(precise_logits)\n    precise_logits = _flatten_outer_dims(precise_logits)\n    labels = _flatten_outer_dims(labels)\n    cost, unused_backprop = gen_nn_ops.softmax_cross_entropy_with_logits(\n        precise_logits, labels, name=name)\n    output_shape = array_ops.slice(input_shape, [0],\n                                   [math_ops.subtract(input_rank, 1)])\n    cost = array_ops.reshape(cost, output_shape)\n    if not context.executing_eagerly(\n    ) and shape is not None and shape.dims is not None:\n      shape = shape.as_list()\n      del shape[dim]\n      cost.set_shape(shape)\n    if convert_to_float32:\n      return math_ops.cast(cost, logits.dtype)\n    else:\n      return cost\n```\n\n* Cross_entropy_loss in Keras with backbone of tensorflow\n``` bash\ntf.nn.softmax_cross_entropy_with_logits(labels=target,logits=output)\n```\n\n## The reason why the value of loss become inf\n* log(x) when x -> 0\n* learning rate is too high\n* some parameters of Nel appear inf\n* input data appear inf\n* the parameters of model no longer updated \n\n\n## Cross_entropy_loss with missing labels\n\n* leveraging fixed zero array or ones array as ground truth and generating mask in loss function\n``` bash\ndef mask_cross_entropy_loss(y_true,y_pred):\n\tmask=K.all(K.equal(y_true,0),axis=-1)\n\tmask=1-K.cast(mask,K.floatx())\n\tloss = K.categorical_crossentropy(y_true,y_pred)*mask\n\treturn (K.sum(loss)/K.sum(mask)\n``` \n\n* corresponding accuracy with mask\n``` bash\ndef mask_cross_entropy_acc(y_true,y_pred):\n\tmask=K.all(K.equal(y_true,0),axis=-1)\n\tmask=1-K.cast(mask,K.floatx())\n\tacc = K.cast(K.equal(K.argmax(y_true,axis=-1),K.argmax(y_pred,axis=-1)),K.floatx()))*mask\n\treturn (K.sum(acc)/K.sum(mask)\n``` \n","slug":"Cross_entropy_loss","published":1,"updated":"2019-04-08T06:20:55.948Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cju7zelmm0006qrm75psake5a","content":"<h2 id=\"Cross-entropy-loss-calculation-in-different-circumstances\"><a href=\"#Cross-entropy-loss-calculation-in-different-circumstances\" class=\"headerlink\" title=\"Cross entropy loss calculation in different circumstances\"></a>Cross entropy loss calculation in different circumstances</h2><ul>\n<li><p>Cross_entropy_loss in tensorflow</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">def softmax_cross_entropy_with_logits(</span><br><span class=\"line\">    _sentinel=None,  <span class=\"comment\"># pylint: disable=invalid-name</span></span><br><span class=\"line\">    labels=None,</span><br><span class=\"line\">    logits=None,</span><br><span class=\"line\">    dim=-1,</span><br><span class=\"line\">    name=None):</span><br><span class=\"line\">  _ensure_xent_args(<span class=\"string\">\"softmax_cross_entropy_with_logits\"</span>, _sentinel, labels,</span><br><span class=\"line\">                    logits)</span><br><span class=\"line\">  with ops.name_scope(name, <span class=\"string\">\"softmax_cross_entropy_with_logits_sg\"</span>,</span><br><span class=\"line\">                      [logits, labels]) as name:</span><br><span class=\"line\">    labels = array_ops.stop_gradient(labels, name=<span class=\"string\">\"labels_stop_gradient\"</span>)</span><br><span class=\"line\">  <span class=\"built_in\">return</span> softmax_cross_entropy_with_logits_v2(</span><br><span class=\"line\">      labels=labels, logits=logits, dim=dim, name=name)</span><br><span class=\"line\">def softmax_cross_entropy_with_logits_v2(</span><br><span class=\"line\">    _sentinel=None,  <span class=\"comment\"># pylint: disable=invalid-name</span></span><br><span class=\"line\">    labels=None,</span><br><span class=\"line\">    logits=None,</span><br><span class=\"line\">    dim=-1,</span><br><span class=\"line\">    name=None):</span><br><span class=\"line\">  _ensure_xent_args(<span class=\"string\">\"softmax_cross_entropy_with_logits\"</span>, _sentinel, labels,</span><br><span class=\"line\">                    logits)</span><br><span class=\"line\">  with ops.name_scope(name, <span class=\"string\">\"softmax_cross_entropy_with_logits\"</span>,</span><br><span class=\"line\">                      [logits, labels]) as name:</span><br><span class=\"line\">    logits = ops.convert_to_tensor(logits, name=<span class=\"string\">\"logits\"</span>)</span><br><span class=\"line\">    labels = ops.convert_to_tensor(labels, name=<span class=\"string\">\"labels\"</span>)</span><br><span class=\"line\">    convert_to_float32 = (</span><br><span class=\"line\">        logits.dtype == dtypes.float16 or logits.dtype == dtypes.bfloat16)</span><br><span class=\"line\">    precise_logits = math_ops.cast(</span><br><span class=\"line\">        logits, dtypes.float32) <span class=\"keyword\">if</span> convert_to_float32 <span class=\"keyword\">else</span> logits</span><br><span class=\"line\">    <span class=\"comment\"># labels and logits must be of the same type</span></span><br><span class=\"line\">    labels = math_ops.cast(labels, precise_logits.dtype)</span><br><span class=\"line\">    input_rank = array_ops.rank(precise_logits)</span><br><span class=\"line\">    shape = logits.get_shape()</span><br><span class=\"line\">    <span class=\"keyword\">if</span> dim is not -1:</span><br><span class=\"line\">      def _move_dim_to_end(tensor, dim_index, rank):</span><br><span class=\"line\">        <span class=\"built_in\">return</span> array_ops.transpose(</span><br><span class=\"line\">            tensor,</span><br><span class=\"line\">            array_ops.concat([</span><br><span class=\"line\">                math_ops.range(dim_index),</span><br><span class=\"line\">                math_ops.range(dim_index + 1, rank), [dim_index]</span><br><span class=\"line\">            ], 0))</span><br><span class=\"line\">      precise_logits = _move_dim_to_end(precise_logits, dim, input_rank)</span><br><span class=\"line\">      labels = _move_dim_to_end(labels, dim, input_rank)</span><br><span class=\"line\">    input_shape = array_ops.shape(precise_logits)</span><br><span class=\"line\">    precise_logits = _flatten_outer_dims(precise_logits)</span><br><span class=\"line\">    labels = _flatten_outer_dims(labels)</span><br><span class=\"line\">    cost, unused_backprop = gen_nn_ops.softmax_cross_entropy_with_logits(</span><br><span class=\"line\">        precise_logits, labels, name=name)</span><br><span class=\"line\">    output_shape = array_ops.slice(input_shape, [0],</span><br><span class=\"line\">                                   [math_ops.subtract(input_rank, 1)])</span><br><span class=\"line\">    cost = array_ops.reshape(cost, output_shape)</span><br><span class=\"line\">    <span class=\"keyword\">if</span> not context.executing_eagerly(</span><br><span class=\"line\">    ) and shape is not None and shape.dims is not None:</span><br><span class=\"line\">      shape = shape.as_list()</span><br><span class=\"line\">      del shape[dim]</span><br><span class=\"line\">      cost.set_shape(shape)</span><br><span class=\"line\">    <span class=\"keyword\">if</span> convert_to_float32:</span><br><span class=\"line\">      <span class=\"built_in\">return</span> math_ops.cast(cost, logits.dtype)</span><br><span class=\"line\">    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">      <span class=\"built_in\">return</span> cost</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>Cross_entropy_loss in Keras with backbone of tensorflow</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">tf.nn.softmax_cross_entropy_with_logits(labels=target,logits=output)</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<h2 id=\"The-reason-why-the-value-of-loss-become-inf\"><a href=\"#The-reason-why-the-value-of-loss-become-inf\" class=\"headerlink\" title=\"The reason why the value of loss become inf\"></a>The reason why the value of loss become inf</h2><ul>\n<li>log(x) when x -&gt; 0</li>\n<li>learning rate is too high</li>\n<li>some parameters of Nel appear inf</li>\n<li>input data appear inf</li>\n<li>the parameters of model no longer updated </li>\n</ul>\n<h2 id=\"Cross-entropy-loss-with-missing-labels\"><a href=\"#Cross-entropy-loss-with-missing-labels\" class=\"headerlink\" title=\"Cross_entropy_loss with missing labels\"></a>Cross_entropy_loss with missing labels</h2><ul>\n<li><p>leveraging fixed zero array or ones array as ground truth and generating mask in loss function</p>\n<pre><code class=\"lang-bash\">def mask_cross_entropy_loss(y_true,y_pred):\n  mask=K.all(K.equal(y_true,0),axis=-1)\n  mask=1-K.cast(mask,K.floatx())\n  loss = K.categorical_crossentropy(y_true,y_pred)*mask\n  return (K.sum(loss)/K.sum(mask)\n</code></pre>\n</li>\n<li><p>corresponding accuracy with mask</p>\n<pre><code class=\"lang-bash\">def mask_cross_entropy_acc(y_true,y_pred):\n  mask=K.all(K.equal(y_true,0),axis=-1)\n  mask=1-K.cast(mask,K.floatx())\n  acc = K.cast(K.equal(K.argmax(y_true,axis=-1),K.argmax(y_pred,axis=-1)),K.floatx()))*mask\n  return (K.sum(acc)/K.sum(mask)\n</code></pre>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"Cross-entropy-loss-calculation-in-different-circumstances\"><a href=\"#Cross-entropy-loss-calculation-in-different-circumstances\" class=\"headerlink\" title=\"Cross entropy loss calculation in different circumstances\"></a>Cross entropy loss calculation in different circumstances</h2><ul>\n<li><p>Cross_entropy_loss in tensorflow</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">def softmax_cross_entropy_with_logits(</span><br><span class=\"line\">    _sentinel=None,  <span class=\"comment\"># pylint: disable=invalid-name</span></span><br><span class=\"line\">    labels=None,</span><br><span class=\"line\">    logits=None,</span><br><span class=\"line\">    dim=-1,</span><br><span class=\"line\">    name=None):</span><br><span class=\"line\">  _ensure_xent_args(<span class=\"string\">\"softmax_cross_entropy_with_logits\"</span>, _sentinel, labels,</span><br><span class=\"line\">                    logits)</span><br><span class=\"line\">  with ops.name_scope(name, <span class=\"string\">\"softmax_cross_entropy_with_logits_sg\"</span>,</span><br><span class=\"line\">                      [logits, labels]) as name:</span><br><span class=\"line\">    labels = array_ops.stop_gradient(labels, name=<span class=\"string\">\"labels_stop_gradient\"</span>)</span><br><span class=\"line\">  <span class=\"built_in\">return</span> softmax_cross_entropy_with_logits_v2(</span><br><span class=\"line\">      labels=labels, logits=logits, dim=dim, name=name)</span><br><span class=\"line\">def softmax_cross_entropy_with_logits_v2(</span><br><span class=\"line\">    _sentinel=None,  <span class=\"comment\"># pylint: disable=invalid-name</span></span><br><span class=\"line\">    labels=None,</span><br><span class=\"line\">    logits=None,</span><br><span class=\"line\">    dim=-1,</span><br><span class=\"line\">    name=None):</span><br><span class=\"line\">  _ensure_xent_args(<span class=\"string\">\"softmax_cross_entropy_with_logits\"</span>, _sentinel, labels,</span><br><span class=\"line\">                    logits)</span><br><span class=\"line\">  with ops.name_scope(name, <span class=\"string\">\"softmax_cross_entropy_with_logits\"</span>,</span><br><span class=\"line\">                      [logits, labels]) as name:</span><br><span class=\"line\">    logits = ops.convert_to_tensor(logits, name=<span class=\"string\">\"logits\"</span>)</span><br><span class=\"line\">    labels = ops.convert_to_tensor(labels, name=<span class=\"string\">\"labels\"</span>)</span><br><span class=\"line\">    convert_to_float32 = (</span><br><span class=\"line\">        logits.dtype == dtypes.float16 or logits.dtype == dtypes.bfloat16)</span><br><span class=\"line\">    precise_logits = math_ops.cast(</span><br><span class=\"line\">        logits, dtypes.float32) <span class=\"keyword\">if</span> convert_to_float32 <span class=\"keyword\">else</span> logits</span><br><span class=\"line\">    <span class=\"comment\"># labels and logits must be of the same type</span></span><br><span class=\"line\">    labels = math_ops.cast(labels, precise_logits.dtype)</span><br><span class=\"line\">    input_rank = array_ops.rank(precise_logits)</span><br><span class=\"line\">    shape = logits.get_shape()</span><br><span class=\"line\">    <span class=\"keyword\">if</span> dim is not -1:</span><br><span class=\"line\">      def _move_dim_to_end(tensor, dim_index, rank):</span><br><span class=\"line\">        <span class=\"built_in\">return</span> array_ops.transpose(</span><br><span class=\"line\">            tensor,</span><br><span class=\"line\">            array_ops.concat([</span><br><span class=\"line\">                math_ops.range(dim_index),</span><br><span class=\"line\">                math_ops.range(dim_index + 1, rank), [dim_index]</span><br><span class=\"line\">            ], 0))</span><br><span class=\"line\">      precise_logits = _move_dim_to_end(precise_logits, dim, input_rank)</span><br><span class=\"line\">      labels = _move_dim_to_end(labels, dim, input_rank)</span><br><span class=\"line\">    input_shape = array_ops.shape(precise_logits)</span><br><span class=\"line\">    precise_logits = _flatten_outer_dims(precise_logits)</span><br><span class=\"line\">    labels = _flatten_outer_dims(labels)</span><br><span class=\"line\">    cost, unused_backprop = gen_nn_ops.softmax_cross_entropy_with_logits(</span><br><span class=\"line\">        precise_logits, labels, name=name)</span><br><span class=\"line\">    output_shape = array_ops.slice(input_shape, [0],</span><br><span class=\"line\">                                   [math_ops.subtract(input_rank, 1)])</span><br><span class=\"line\">    cost = array_ops.reshape(cost, output_shape)</span><br><span class=\"line\">    <span class=\"keyword\">if</span> not context.executing_eagerly(</span><br><span class=\"line\">    ) and shape is not None and shape.dims is not None:</span><br><span class=\"line\">      shape = shape.as_list()</span><br><span class=\"line\">      del shape[dim]</span><br><span class=\"line\">      cost.set_shape(shape)</span><br><span class=\"line\">    <span class=\"keyword\">if</span> convert_to_float32:</span><br><span class=\"line\">      <span class=\"built_in\">return</span> math_ops.cast(cost, logits.dtype)</span><br><span class=\"line\">    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">      <span class=\"built_in\">return</span> cost</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>Cross_entropy_loss in Keras with backbone of tensorflow</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">tf.nn.softmax_cross_entropy_with_logits(labels=target,logits=output)</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<h2 id=\"The-reason-why-the-value-of-loss-become-inf\"><a href=\"#The-reason-why-the-value-of-loss-become-inf\" class=\"headerlink\" title=\"The reason why the value of loss become inf\"></a>The reason why the value of loss become inf</h2><ul>\n<li>log(x) when x -&gt; 0</li>\n<li>learning rate is too high</li>\n<li>some parameters of Nel appear inf</li>\n<li>input data appear inf</li>\n<li>the parameters of model no longer updated </li>\n</ul>\n<h2 id=\"Cross-entropy-loss-with-missing-labels\"><a href=\"#Cross-entropy-loss-with-missing-labels\" class=\"headerlink\" title=\"Cross_entropy_loss with missing labels\"></a>Cross_entropy_loss with missing labels</h2><ul>\n<li><p>leveraging fixed zero array or ones array as ground truth and generating mask in loss function</p>\n<pre><code class=\"lang-bash\">def mask_cross_entropy_loss(y_true,y_pred):\n  mask=K.all(K.equal(y_true,0),axis=-1)\n  mask=1-K.cast(mask,K.floatx())\n  loss = K.categorical_crossentropy(y_true,y_pred)*mask\n  return (K.sum(loss)/K.sum(mask)\n</code></pre>\n</li>\n<li><p>corresponding accuracy with mask</p>\n<pre><code class=\"lang-bash\">def mask_cross_entropy_acc(y_true,y_pred):\n  mask=K.all(K.equal(y_true,0),axis=-1)\n  mask=1-K.cast(mask,K.floatx())\n  acc = K.cast(K.equal(K.argmax(y_true,axis=-1),K.argmax(y_pred,axis=-1)),K.floatx()))*mask\n  return (K.sum(acc)/K.sum(mask)\n</code></pre>\n</li>\n</ul>\n"},{"title":"Density & Distribution","date":"2019-02-21T07:46:01.000Z","_content":"\n## Purity based density & distribution distance based GMM \n\n### Purity based density\n>reference：ECCV 2018 [CurriculumNet: Weakly Supervised Learning from Large-Scale Web Images](http://openaccess.thecvf.com/content_ECCV_2018/papers/Sheng_Guo_CurriculumNet_Learning_from_ECCV_2018_paper.pdf)\n\n>original reference： Science 2004 [Clustering by fast search and find of density peaks](http://sites.psu.edu/mcnl/files/2017/03/9-2dhti48.pdf)\n\n\n#### Creativity\n* leveraging data distribution density in feature space to evaluate the complexity of the data\nours -- evaluating the purity of pseudo label data by data density in feature space\n* noisy data can be regared as regularied method to improve the model generalization\nours -- pesudo labels can improve the model generalization \n\n#### Technical detail\nDensity based clustering algorithm\n* generating features\n* calculating Euclidean distance D_ij\n* calculating local density of each image\n* calculating distance of each image: maximun local distance is regarded as cluster centre, image with smaller distance between its distance and cluster centre represents that its label have high confidence \n\n\n### Distribution distance based GMM \n#### Clustring based GMM\n##### GMM with EM\n*  original definition\n\\begin{aligned}\np(x) & = \\sum_{k=1}^K p(k)p(x|k) = \\sum_{k=1}^K \\pi_k \\mathcal{N}(x|\\mu_k, \\Sigma_k)\n\\end{aligned}\n\\pi_k  represent the possibility of sample belong to kth category\n\n* new definition for coding\n\\begin{aligned}\n\\sum_{k} z_k = 1\n\\end{aligned}\n\n##### Related code\n* [sklearn.mixture.GaussianMixture](https://scikit-learn.org/stable/modules/generated/sklearn.mixture.GaussianMixture.html)\n\n#### Data distribution distance EMD\n> reference： [ Large Scale Fine-Grained Categorization and Domain-Specific Transfer Learning](http://openaccess.thecvf.com/content_cvpr_2018/papers/Cui_Large_Scale_Fine-Grained_CVPR_2018_paper.pdf)\n> original reference： [The Earth Mover's Distance as a Metric for Image Retrieval](http://robotics.stanford.edu/~rubner/papers/rubnerIjcv00.pdf)\n\n*  EDM definition: Signature matching can be naturally cast as a transportation problem by de fining one signature as the supplier and the other as the consumer, and by setting the cost for a supplier-consumer pair to equal the ground distance between an element in the fi rst signature and an element in the second\n\n*  EMD data signature:\n\\begin{aligned}\ns= (feature,weights)\n\\end{aligned}\n\n* related code\n* [general EMD](https://github.com/chalmersgit/EMD) [expaination](http://homepages.inf.ed.ac.uk/rbf/CVonline/LOCAL_COPIES/RUBNER/emd.htm)\n* [pyemd-1D data](https://pypi.org/project/pyemd/)\n* [scipy.atats.wasserstein_distance](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.wasserstein_distance.html)\n\n\n\n \n \n\n\n\n\n\n\n","source":"_posts/Density-Distribution.md","raw":"---\ntitle: Density & Distribution\ndate: 2019-02-21 15:46:01\ntags: pesudo labels\ncategories: Theory\n---\n\n## Purity based density & distribution distance based GMM \n\n### Purity based density\n>reference：ECCV 2018 [CurriculumNet: Weakly Supervised Learning from Large-Scale Web Images](http://openaccess.thecvf.com/content_ECCV_2018/papers/Sheng_Guo_CurriculumNet_Learning_from_ECCV_2018_paper.pdf)\n\n>original reference： Science 2004 [Clustering by fast search and find of density peaks](http://sites.psu.edu/mcnl/files/2017/03/9-2dhti48.pdf)\n\n\n#### Creativity\n* leveraging data distribution density in feature space to evaluate the complexity of the data\nours -- evaluating the purity of pseudo label data by data density in feature space\n* noisy data can be regared as regularied method to improve the model generalization\nours -- pesudo labels can improve the model generalization \n\n#### Technical detail\nDensity based clustering algorithm\n* generating features\n* calculating Euclidean distance D_ij\n* calculating local density of each image\n* calculating distance of each image: maximun local distance is regarded as cluster centre, image with smaller distance between its distance and cluster centre represents that its label have high confidence \n\n\n### Distribution distance based GMM \n#### Clustring based GMM\n##### GMM with EM\n*  original definition\n\\begin{aligned}\np(x) & = \\sum_{k=1}^K p(k)p(x|k) = \\sum_{k=1}^K \\pi_k \\mathcal{N}(x|\\mu_k, \\Sigma_k)\n\\end{aligned}\n\\pi_k  represent the possibility of sample belong to kth category\n\n* new definition for coding\n\\begin{aligned}\n\\sum_{k} z_k = 1\n\\end{aligned}\n\n##### Related code\n* [sklearn.mixture.GaussianMixture](https://scikit-learn.org/stable/modules/generated/sklearn.mixture.GaussianMixture.html)\n\n#### Data distribution distance EMD\n> reference： [ Large Scale Fine-Grained Categorization and Domain-Specific Transfer Learning](http://openaccess.thecvf.com/content_cvpr_2018/papers/Cui_Large_Scale_Fine-Grained_CVPR_2018_paper.pdf)\n> original reference： [The Earth Mover's Distance as a Metric for Image Retrieval](http://robotics.stanford.edu/~rubner/papers/rubnerIjcv00.pdf)\n\n*  EDM definition: Signature matching can be naturally cast as a transportation problem by de fining one signature as the supplier and the other as the consumer, and by setting the cost for a supplier-consumer pair to equal the ground distance between an element in the fi rst signature and an element in the second\n\n*  EMD data signature:\n\\begin{aligned}\ns= (feature,weights)\n\\end{aligned}\n\n* related code\n* [general EMD](https://github.com/chalmersgit/EMD) [expaination](http://homepages.inf.ed.ac.uk/rbf/CVonline/LOCAL_COPIES/RUBNER/emd.htm)\n* [pyemd-1D data](https://pypi.org/project/pyemd/)\n* [scipy.atats.wasserstein_distance](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.wasserstein_distance.html)\n\n\n\n \n \n\n\n\n\n\n\n","slug":"Density-Distribution","published":1,"updated":"2019-04-08T06:20:55.948Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cju7zelmn0007qrm738ohwi38","content":"<h2 id=\"Purity-based-density-amp-distribution-distance-based-GMM\"><a href=\"#Purity-based-density-amp-distribution-distance-based-GMM\" class=\"headerlink\" title=\"Purity based density &amp; distribution distance based GMM\"></a>Purity based density &amp; distribution distance based GMM</h2><h3 id=\"Purity-based-density\"><a href=\"#Purity-based-density\" class=\"headerlink\" title=\"Purity based density\"></a>Purity based density</h3><blockquote>\n<p>reference：ECCV 2018 <a href=\"http://openaccess.thecvf.com/content_ECCV_2018/papers/Sheng_Guo_CurriculumNet_Learning_from_ECCV_2018_paper.pdf\" target=\"_blank\" rel=\"noopener\">CurriculumNet: Weakly Supervised Learning from Large-Scale Web Images</a></p>\n<p>original reference： Science 2004 <a href=\"http://sites.psu.edu/mcnl/files/2017/03/9-2dhti48.pdf\" target=\"_blank\" rel=\"noopener\">Clustering by fast search and find of density peaks</a></p>\n</blockquote>\n<h4 id=\"Creativity\"><a href=\"#Creativity\" class=\"headerlink\" title=\"Creativity\"></a>Creativity</h4><ul>\n<li>leveraging data distribution density in feature space to evaluate the complexity of the data<br>ours — evaluating the purity of pseudo label data by data density in feature space</li>\n<li>noisy data can be regared as regularied method to improve the model generalization<br>ours — pesudo labels can improve the model generalization </li>\n</ul>\n<h4 id=\"Technical-detail\"><a href=\"#Technical-detail\" class=\"headerlink\" title=\"Technical detail\"></a>Technical detail</h4><p>Density based clustering algorithm</p>\n<ul>\n<li>generating features</li>\n<li>calculating Euclidean distance D_ij</li>\n<li>calculating local density of each image</li>\n<li>calculating distance of each image: maximun local distance is regarded as cluster centre, image with smaller distance between its distance and cluster centre represents that its label have high confidence </li>\n</ul>\n<h3 id=\"Distribution-distance-based-GMM\"><a href=\"#Distribution-distance-based-GMM\" class=\"headerlink\" title=\"Distribution distance based GMM\"></a>Distribution distance based GMM</h3><h4 id=\"Clustring-based-GMM\"><a href=\"#Clustring-based-GMM\" class=\"headerlink\" title=\"Clustring based GMM\"></a>Clustring based GMM</h4><h5 id=\"GMM-with-EM\"><a href=\"#GMM-with-EM\" class=\"headerlink\" title=\"GMM with EM\"></a>GMM with EM</h5><ul>\n<li><p>original definition<br>\\begin{aligned}<br>p(x) &amp; = \\sum<em>{k=1}^K p(k)p(x|k) = \\sum</em>{k=1}^K \\pi_k \\mathcal{N}(x|\\mu_k, \\Sigma_k)<br>\\end{aligned}<br>\\pi_k  represent the possibility of sample belong to kth category</p>\n</li>\n<li><p>new definition for coding<br>\\begin{aligned}<br>\\sum_{k} z_k = 1<br>\\end{aligned}</p>\n</li>\n</ul>\n<h5 id=\"Related-code\"><a href=\"#Related-code\" class=\"headerlink\" title=\"Related code\"></a>Related code</h5><ul>\n<li><a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.mixture.GaussianMixture.html\" target=\"_blank\" rel=\"noopener\">sklearn.mixture.GaussianMixture</a></li>\n</ul>\n<h4 id=\"Data-distribution-distance-EMD\"><a href=\"#Data-distribution-distance-EMD\" class=\"headerlink\" title=\"Data distribution distance EMD\"></a>Data distribution distance EMD</h4><blockquote>\n<p>reference： <a href=\"http://openaccess.thecvf.com/content_cvpr_2018/papers/Cui_Large_Scale_Fine-Grained_CVPR_2018_paper.pdf\" target=\"_blank\" rel=\"noopener\"> Large Scale Fine-Grained Categorization and Domain-Specific Transfer Learning</a><br>original reference： <a href=\"http://robotics.stanford.edu/~rubner/papers/rubnerIjcv00.pdf\" target=\"_blank\" rel=\"noopener\">The Earth Mover’s Distance as a Metric for Image Retrieval</a></p>\n</blockquote>\n<ul>\n<li><p>EDM definition: Signature matching can be naturally cast as a transportation problem by de fining one signature as the supplier and the other as the consumer, and by setting the cost for a supplier-consumer pair to equal the ground distance between an element in the fi rst signature and an element in the second</p>\n</li>\n<li><p>EMD data signature:<br>\\begin{aligned}<br>s= (feature,weights)<br>\\end{aligned}</p>\n</li>\n<li><p>related code</p>\n</li>\n<li><a href=\"https://github.com/chalmersgit/EMD\" target=\"_blank\" rel=\"noopener\">general EMD</a> <a href=\"http://homepages.inf.ed.ac.uk/rbf/CVonline/LOCAL_COPIES/RUBNER/emd.htm\" target=\"_blank\" rel=\"noopener\">expaination</a></li>\n<li><a href=\"https://pypi.org/project/pyemd/\" target=\"_blank\" rel=\"noopener\">pyemd-1D data</a></li>\n<li><a href=\"https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.wasserstein_distance.html\" target=\"_blank\" rel=\"noopener\">scipy.atats.wasserstein_distance</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"Purity-based-density-amp-distribution-distance-based-GMM\"><a href=\"#Purity-based-density-amp-distribution-distance-based-GMM\" class=\"headerlink\" title=\"Purity based density &amp; distribution distance based GMM\"></a>Purity based density &amp; distribution distance based GMM</h2><h3 id=\"Purity-based-density\"><a href=\"#Purity-based-density\" class=\"headerlink\" title=\"Purity based density\"></a>Purity based density</h3><blockquote>\n<p>reference：ECCV 2018 <a href=\"http://openaccess.thecvf.com/content_ECCV_2018/papers/Sheng_Guo_CurriculumNet_Learning_from_ECCV_2018_paper.pdf\" target=\"_blank\" rel=\"noopener\">CurriculumNet: Weakly Supervised Learning from Large-Scale Web Images</a></p>\n<p>original reference： Science 2004 <a href=\"http://sites.psu.edu/mcnl/files/2017/03/9-2dhti48.pdf\" target=\"_blank\" rel=\"noopener\">Clustering by fast search and find of density peaks</a></p>\n</blockquote>\n<h4 id=\"Creativity\"><a href=\"#Creativity\" class=\"headerlink\" title=\"Creativity\"></a>Creativity</h4><ul>\n<li>leveraging data distribution density in feature space to evaluate the complexity of the data<br>ours — evaluating the purity of pseudo label data by data density in feature space</li>\n<li>noisy data can be regared as regularied method to improve the model generalization<br>ours — pesudo labels can improve the model generalization </li>\n</ul>\n<h4 id=\"Technical-detail\"><a href=\"#Technical-detail\" class=\"headerlink\" title=\"Technical detail\"></a>Technical detail</h4><p>Density based clustering algorithm</p>\n<ul>\n<li>generating features</li>\n<li>calculating Euclidean distance D_ij</li>\n<li>calculating local density of each image</li>\n<li>calculating distance of each image: maximun local distance is regarded as cluster centre, image with smaller distance between its distance and cluster centre represents that its label have high confidence </li>\n</ul>\n<h3 id=\"Distribution-distance-based-GMM\"><a href=\"#Distribution-distance-based-GMM\" class=\"headerlink\" title=\"Distribution distance based GMM\"></a>Distribution distance based GMM</h3><h4 id=\"Clustring-based-GMM\"><a href=\"#Clustring-based-GMM\" class=\"headerlink\" title=\"Clustring based GMM\"></a>Clustring based GMM</h4><h5 id=\"GMM-with-EM\"><a href=\"#GMM-with-EM\" class=\"headerlink\" title=\"GMM with EM\"></a>GMM with EM</h5><ul>\n<li><p>original definition<br>\\begin{aligned}<br>p(x) &amp; = \\sum<em>{k=1}^K p(k)p(x|k) = \\sum</em>{k=1}^K \\pi_k \\mathcal{N}(x|\\mu_k, \\Sigma_k)<br>\\end{aligned}<br>\\pi_k  represent the possibility of sample belong to kth category</p>\n</li>\n<li><p>new definition for coding<br>\\begin{aligned}<br>\\sum_{k} z_k = 1<br>\\end{aligned}</p>\n</li>\n</ul>\n<h5 id=\"Related-code\"><a href=\"#Related-code\" class=\"headerlink\" title=\"Related code\"></a>Related code</h5><ul>\n<li><a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.mixture.GaussianMixture.html\" target=\"_blank\" rel=\"noopener\">sklearn.mixture.GaussianMixture</a></li>\n</ul>\n<h4 id=\"Data-distribution-distance-EMD\"><a href=\"#Data-distribution-distance-EMD\" class=\"headerlink\" title=\"Data distribution distance EMD\"></a>Data distribution distance EMD</h4><blockquote>\n<p>reference： <a href=\"http://openaccess.thecvf.com/content_cvpr_2018/papers/Cui_Large_Scale_Fine-Grained_CVPR_2018_paper.pdf\" target=\"_blank\" rel=\"noopener\"> Large Scale Fine-Grained Categorization and Domain-Specific Transfer Learning</a><br>original reference： <a href=\"http://robotics.stanford.edu/~rubner/papers/rubnerIjcv00.pdf\" target=\"_blank\" rel=\"noopener\">The Earth Mover’s Distance as a Metric for Image Retrieval</a></p>\n</blockquote>\n<ul>\n<li><p>EDM definition: Signature matching can be naturally cast as a transportation problem by de fining one signature as the supplier and the other as the consumer, and by setting the cost for a supplier-consumer pair to equal the ground distance between an element in the fi rst signature and an element in the second</p>\n</li>\n<li><p>EMD data signature:<br>\\begin{aligned}<br>s= (feature,weights)<br>\\end{aligned}</p>\n</li>\n<li><p>related code</p>\n</li>\n<li><a href=\"https://github.com/chalmersgit/EMD\" target=\"_blank\" rel=\"noopener\">general EMD</a> <a href=\"http://homepages.inf.ed.ac.uk/rbf/CVonline/LOCAL_COPIES/RUBNER/emd.htm\" target=\"_blank\" rel=\"noopener\">expaination</a></li>\n<li><a href=\"https://pypi.org/project/pyemd/\" target=\"_blank\" rel=\"noopener\">pyemd-1D data</a></li>\n<li><a href=\"https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.wasserstein_distance.html\" target=\"_blank\" rel=\"noopener\">scipy.atats.wasserstein_distance</a></li>\n</ul>\n"},{"title":"GAN","date":"2019-04-08T06:31:25.000Z","_content":"","source":"_posts/GAN.md","raw":"---\ntitle: GAN\ndate: 2019-04-08 14:31:25\ntags:\n---\n","slug":"GAN","published":1,"updated":"2019-04-08T06:31:25.153Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cju7zelmn0008qrm7xkaopkuj","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"Few-shot Image generation","date":"2019-04-04T05:44:00.000Z","_content":"\n## Meta learning\n\n### Definition\n* \"learn to learn\", intends to design models that can learn *__new__* skills or adapt to *__new__* environment *__rapidly__* with *__a few__* traing samples, like *__human learning way__*. The detail can be posted in [Meta-Learning: Learning to Learn Fast](https://lilianweng.github.io/lil-log/2018/11/30/meta-learning.html)\n\n<!-- *  Optimization aims:\n$\\theta^* = \\arg\\min_\\theta \\mathbb{E}_{\\mathcal{D}\\sim p(\\mathcal{D})} [\\mathcal{L}_\\theta(\\mathcal{D})]$ -->\n\nwhere $\\mathcal{D}=\\langle S, B\\rangle$, Support set and Batch set.\n\n* Training steps\n1. sample a subset of labels $L\\subset\\mathcal{L}$.\n2. samples a support set $S^L \\subset \\mathcal{D}$ and a training batch $B^L \\subset \\mathcal{D}$. Both of them belong to the sampled label set $L$, $y \\in L, \\forall (x, y) \\in S^L, B^L$.\n3. support set is the input of model.\n4. the update of model parameters is based on the loss in backpropagation calculated from the mini-batch $B^L$.\n\neach pair of sampled dataset $(S^L, B^L)$ is regarded as one data point, such that trained models can generalize to other datasets. Symbols in red are added for meta-learning in addition to the general supervised learning objective.\n\\begin{aligned}\n\\theta = \\arg\\max_\\theta \\color{red}{E_{L\\subset\\mathcal{L}}[} E_{\\color{red}{S^L \\subset\\mathcal{D}, }B^L \\subset\\mathcal{D}} [\\sum_{(x, y)\\in B^L} P_\\theta(x, y\\color{red}{, S^L})] \\color{red}{]}\n\\end{aligned}\n\n* Traning stages\n1. meta-learner: a optimizer $g_\\phi$ learns how to update the learner model’s parameters via the support set $S$, $\\theta' = g_\\phi(\\theta, S)$\n2. learner: A classifier $f_\\theta$ is the “learner” model, trained for operating a given task.\n<!-- final learning objective is $\\mathbb{E}_{L\\subset\\mathcal{L}}[ \\mathbb{E}_{S^L \\subset\\mathcal{D}, B^L \\subset\\mathcal{D}} [\\sum_{(\\mathbf{x}, y)\\in B^L} P_{g_\\phi(\\theta, S^L)}(y \\vert \\mathbf{x})]]$ -->\n\n\n \n\n### Common methods\n\n\n#### model-based: $f_\\theta(\\mathbf{x}, S)$\n* use *__recurrent__* network with *__internal (or external)__* memory.\n\n#### metric-based: $\\sum_{(\\mathbf{x}_i, y_i) \\in S} k_\\theta(\\mathbf{x}, \\mathbf{x}_i)y_i$\n* learn *__efficient__* distance metric.\n* similar to *__nearnest neighbors algorithm__* (KNN,k-means) and *__kernel density estimation__*.\n* the predicted possibility of labeled samples is from is a *__weighted sum of support set samples__*, and the weight is generated by a kernel function $k_\\theta$, which can measure the *__similarity__* of twp data samples:\n$$\nP_\\theta(y \\vert \\mathbf{x}, S) = \\sum_{(\\mathbf{x}_i, y_i) \\in S} k_\\theta(\\mathbf{x}, \\mathbf{x}_i)y_{i}\n$$\n* crucial keys: *__good kernel__*\n* solution: learning *__embedding vector__* of input data explicitly and use them to design *__proper kernel__* functions.\n* Siamese networks: \n    - assumption: the *__learned embedding__* can be *__generalized__* to be useful for measuring the distance between images of unknown categories.\n    - *__verification__*, images pairs.\n    - final prediction is the class of the support image with highest probability.\n* Matching networks:\n\t- $g_{\\theta}$ with $k$ classifiers for k classes, while $f_{\\theta}$ for testing images.\n\t- attention kernel depends on two embedding functions $g$ and $f$, in simple version where $f=g$. in complex version where integrating full contextual embedding (FCE), it achieves improvement on hard tasks, not for simple tasks.\n* Relation network\n    - image pairs, feature concatenation.\n    - relation modeled: mse loss function.\n* Prototypical\n    - images of each class are embedded into $M$ dimensional feature vector, each class has _prototype_ feature vector from the mean vector of the embedded support data samples in each class.\n    - squared euclidean distance.\n\n\n\n#### optimization-based: $P_{g_\\phi(\\theta, S^L)}(y \\vert \\mathbf{x})$\n* optimize the *__model parameter__* explicitly for *__fast__* learning\n","source":"_posts/Few-shot-Image-generation.md","raw":"---\ntitle: Few-shot Image generation\ndate: 2019-04-04 13:44:00\ntags: few-shot learning\ncategories: Meta-learning\n---\n\n## Meta learning\n\n### Definition\n* \"learn to learn\", intends to design models that can learn *__new__* skills or adapt to *__new__* environment *__rapidly__* with *__a few__* traing samples, like *__human learning way__*. The detail can be posted in [Meta-Learning: Learning to Learn Fast](https://lilianweng.github.io/lil-log/2018/11/30/meta-learning.html)\n\n<!-- *  Optimization aims:\n$\\theta^* = \\arg\\min_\\theta \\mathbb{E}_{\\mathcal{D}\\sim p(\\mathcal{D})} [\\mathcal{L}_\\theta(\\mathcal{D})]$ -->\n\nwhere $\\mathcal{D}=\\langle S, B\\rangle$, Support set and Batch set.\n\n* Training steps\n1. sample a subset of labels $L\\subset\\mathcal{L}$.\n2. samples a support set $S^L \\subset \\mathcal{D}$ and a training batch $B^L \\subset \\mathcal{D}$. Both of them belong to the sampled label set $L$, $y \\in L, \\forall (x, y) \\in S^L, B^L$.\n3. support set is the input of model.\n4. the update of model parameters is based on the loss in backpropagation calculated from the mini-batch $B^L$.\n\neach pair of sampled dataset $(S^L, B^L)$ is regarded as one data point, such that trained models can generalize to other datasets. Symbols in red are added for meta-learning in addition to the general supervised learning objective.\n\\begin{aligned}\n\\theta = \\arg\\max_\\theta \\color{red}{E_{L\\subset\\mathcal{L}}[} E_{\\color{red}{S^L \\subset\\mathcal{D}, }B^L \\subset\\mathcal{D}} [\\sum_{(x, y)\\in B^L} P_\\theta(x, y\\color{red}{, S^L})] \\color{red}{]}\n\\end{aligned}\n\n* Traning stages\n1. meta-learner: a optimizer $g_\\phi$ learns how to update the learner model’s parameters via the support set $S$, $\\theta' = g_\\phi(\\theta, S)$\n2. learner: A classifier $f_\\theta$ is the “learner” model, trained for operating a given task.\n<!-- final learning objective is $\\mathbb{E}_{L\\subset\\mathcal{L}}[ \\mathbb{E}_{S^L \\subset\\mathcal{D}, B^L \\subset\\mathcal{D}} [\\sum_{(\\mathbf{x}, y)\\in B^L} P_{g_\\phi(\\theta, S^L)}(y \\vert \\mathbf{x})]]$ -->\n\n\n \n\n### Common methods\n\n\n#### model-based: $f_\\theta(\\mathbf{x}, S)$\n* use *__recurrent__* network with *__internal (or external)__* memory.\n\n#### metric-based: $\\sum_{(\\mathbf{x}_i, y_i) \\in S} k_\\theta(\\mathbf{x}, \\mathbf{x}_i)y_i$\n* learn *__efficient__* distance metric.\n* similar to *__nearnest neighbors algorithm__* (KNN,k-means) and *__kernel density estimation__*.\n* the predicted possibility of labeled samples is from is a *__weighted sum of support set samples__*, and the weight is generated by a kernel function $k_\\theta$, which can measure the *__similarity__* of twp data samples:\n$$\nP_\\theta(y \\vert \\mathbf{x}, S) = \\sum_{(\\mathbf{x}_i, y_i) \\in S} k_\\theta(\\mathbf{x}, \\mathbf{x}_i)y_{i}\n$$\n* crucial keys: *__good kernel__*\n* solution: learning *__embedding vector__* of input data explicitly and use them to design *__proper kernel__* functions.\n* Siamese networks: \n    - assumption: the *__learned embedding__* can be *__generalized__* to be useful for measuring the distance between images of unknown categories.\n    - *__verification__*, images pairs.\n    - final prediction is the class of the support image with highest probability.\n* Matching networks:\n\t- $g_{\\theta}$ with $k$ classifiers for k classes, while $f_{\\theta}$ for testing images.\n\t- attention kernel depends on two embedding functions $g$ and $f$, in simple version where $f=g$. in complex version where integrating full contextual embedding (FCE), it achieves improvement on hard tasks, not for simple tasks.\n* Relation network\n    - image pairs, feature concatenation.\n    - relation modeled: mse loss function.\n* Prototypical\n    - images of each class are embedded into $M$ dimensional feature vector, each class has _prototype_ feature vector from the mean vector of the embedded support data samples in each class.\n    - squared euclidean distance.\n\n\n\n#### optimization-based: $P_{g_\\phi(\\theta, S^L)}(y \\vert \\mathbf{x})$\n* optimize the *__model parameter__* explicitly for *__fast__* learning\n","slug":"Few-shot-Image-generation","published":1,"updated":"2019-04-08T06:34:20.779Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cju7zelmp000cqrm7jdcnp41s","content":"<h2 id=\"Meta-learning\"><a href=\"#Meta-learning\" class=\"headerlink\" title=\"Meta learning\"></a>Meta learning</h2><h3 id=\"Definition\"><a href=\"#Definition\" class=\"headerlink\" title=\"Definition\"></a>Definition</h3><ul>\n<li>“learn to learn”, intends to design models that can learn <em><strong>new</strong></em> skills or adapt to <em><strong>new</strong></em> environment <em><strong>rapidly</strong></em> with <em><strong>a few</strong></em> traing samples, like <em><strong>human learning way</strong></em>. The detail can be posted in <a href=\"https://lilianweng.github.io/lil-log/2018/11/30/meta-learning.html\" target=\"_blank\" rel=\"noopener\">Meta-Learning: Learning to Learn Fast</a></li>\n</ul>\n<!-- *  Optimization aims:\n$\\theta^* = \\arg\\min_\\theta \\mathbb{E}_{\\mathcal{D}\\sim p(\\mathcal{D})} [\\mathcal{L}_\\theta(\\mathcal{D})]$ -->\n<p>where $\\mathcal{D}=\\langle S, B\\rangle$, Support set and Batch set.</p>\n<ul>\n<li>Training steps</li>\n</ul>\n<ol>\n<li>sample a subset of labels $L\\subset\\mathcal{L}$.</li>\n<li>samples a support set $S^L \\subset \\mathcal{D}$ and a training batch $B^L \\subset \\mathcal{D}$. Both of them belong to the sampled label set $L$, $y \\in L, \\forall (x, y) \\in S^L, B^L$.</li>\n<li>support set is the input of model.</li>\n<li>the update of model parameters is based on the loss in backpropagation calculated from the mini-batch $B^L$.</li>\n</ol>\n<p>each pair of sampled dataset $(S^L, B^L)$ is regarded as one data point, such that trained models can generalize to other datasets. Symbols in red are added for meta-learning in addition to the general supervised learning objective.<br>\\begin{aligned}<br>\\theta = \\arg\\max<em>\\theta \\color{red}{E</em>{L\\subset\\mathcal{L}}[} E<em>{\\color{red}{S^L \\subset\\mathcal{D}, }B^L \\subset\\mathcal{D}} [\\sum</em>{(x, y)\\in B^L} P_\\theta(x, y\\color{red}{, S^L})] \\color{red}{]}<br>\\end{aligned}</p>\n<ul>\n<li>Traning stages</li>\n</ul>\n<ol>\n<li>meta-learner: a optimizer $g<em>\\phi$ learns how to update the learner model’s parameters via the support set $S$, $\\theta’ = g</em>\\phi(\\theta, S)$</li>\n<li>learner: A classifier $f_\\theta$ is the “learner” model, trained for operating a given task.<!-- final learning objective is $\\mathbb{E}_{L\\subset\\mathcal{L}}[ \\mathbb{E}_{S^L \\subset\\mathcal{D}, B^L \\subset\\mathcal{D}} [\\sum_{(\\mathbf{x}, y)\\in B^L} P_{g_\\phi(\\theta, S^L)}(y \\vert \\mathbf{x})]]$ -->\n</li>\n</ol>\n<h3 id=\"Common-methods\"><a href=\"#Common-methods\" class=\"headerlink\" title=\"Common methods\"></a>Common methods</h3><h4 id=\"model-based-f-theta-mathbf-x-S\"><a href=\"#model-based-f-theta-mathbf-x-S\" class=\"headerlink\" title=\"model-based: $f_\\theta(\\mathbf{x}, S)$\"></a>model-based: $f_\\theta(\\mathbf{x}, S)$</h4><ul>\n<li>use <em><strong>recurrent</strong></em> network with <em><strong>internal (or external)</strong></em> memory.</li>\n</ul>\n<h4 id=\"metric-based-sum-mathbf-x-i-y-i-in-S-k-theta-mathbf-x-mathbf-x-i-y-i\"><a href=\"#metric-based-sum-mathbf-x-i-y-i-in-S-k-theta-mathbf-x-mathbf-x-i-y-i\" class=\"headerlink\" title=\"metric-based: $\\sum{(\\mathbf{x}_i, y_i) \\in S} k\\theta(\\mathbf{x}, \\mathbf{x}_i)y_i$\"></a>metric-based: $\\sum<em>{(\\mathbf{x}_i, y_i) \\in S} k</em>\\theta(\\mathbf{x}, \\mathbf{x}_i)y_i$</h4><ul>\n<li>learn <em><strong>efficient</strong></em> distance metric.</li>\n<li>similar to <em><strong>nearnest neighbors algorithm</strong></em> (KNN,k-means) and <em><strong>kernel density estimation</strong></em>.</li>\n<li>the predicted possibility of labeled samples is from is a <em><strong>weighted sum of support set samples</strong></em>, and the weight is generated by a kernel function $k<em>\\theta$, which can measure the *<em>_similarity</em></em>* of twp data samples:<script type=\"math/tex; mode=display\">\nP_\\theta(y \\vert \\mathbf{x}, S) = \\sum_{(\\mathbf{x}_i, y_i) \\in S} k_\\theta(\\mathbf{x}, \\mathbf{x}_i)y_{i}</script></li>\n<li>crucial keys: <em><strong>good kernel</strong></em></li>\n<li>solution: learning <em><strong>embedding vector</strong></em> of input data explicitly and use them to design <em><strong>proper kernel</strong></em> functions.</li>\n<li>Siamese networks: <ul>\n<li>assumption: the <em><strong>learned embedding</strong></em> can be <em><strong>generalized</strong></em> to be useful for measuring the distance between images of unknown categories.</li>\n<li><em><strong>verification</strong></em>, images pairs.</li>\n<li>final prediction is the class of the support image with highest probability.</li>\n</ul>\n</li>\n<li>Matching networks:<ul>\n<li>$g<em>{\\theta}$ with $k$ classifiers for k classes, while $f</em>{\\theta}$ for testing images.</li>\n<li>attention kernel depends on two embedding functions $g$ and $f$, in simple version where $f=g$. in complex version where integrating full contextual embedding (FCE), it achieves improvement on hard tasks, not for simple tasks.</li>\n</ul>\n</li>\n<li>Relation network<ul>\n<li>image pairs, feature concatenation.</li>\n<li>relation modeled: mse loss function.</li>\n</ul>\n</li>\n<li>Prototypical<ul>\n<li>images of each class are embedded into $M$ dimensional feature vector, each class has <em>prototype</em> feature vector from the mean vector of the embedded support data samples in each class.</li>\n<li>squared euclidean distance.</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"optimization-based-P-g-phi-theta-S-L-y-vert-mathbf-x\"><a href=\"#optimization-based-P-g-phi-theta-S-L-y-vert-mathbf-x\" class=\"headerlink\" title=\"optimization-based: $P{g\\phi(\\theta, S^L)}(y \\vert \\mathbf{x})$\"></a>optimization-based: $P<em>{g</em>\\phi(\\theta, S^L)}(y \\vert \\mathbf{x})$</h4><ul>\n<li>optimize the <em><strong>model parameter</strong></em> explicitly for <em><strong>fast</strong></em> learning</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"Meta-learning\"><a href=\"#Meta-learning\" class=\"headerlink\" title=\"Meta learning\"></a>Meta learning</h2><h3 id=\"Definition\"><a href=\"#Definition\" class=\"headerlink\" title=\"Definition\"></a>Definition</h3><ul>\n<li>“learn to learn”, intends to design models that can learn <em><strong>new</strong></em> skills or adapt to <em><strong>new</strong></em> environment <em><strong>rapidly</strong></em> with <em><strong>a few</strong></em> traing samples, like <em><strong>human learning way</strong></em>. The detail can be posted in <a href=\"https://lilianweng.github.io/lil-log/2018/11/30/meta-learning.html\" target=\"_blank\" rel=\"noopener\">Meta-Learning: Learning to Learn Fast</a></li>\n</ul>\n<!-- *  Optimization aims:\n$\\theta^* = \\arg\\min_\\theta \\mathbb{E}_{\\mathcal{D}\\sim p(\\mathcal{D})} [\\mathcal{L}_\\theta(\\mathcal{D})]$ -->\n<p>where $\\mathcal{D}=\\langle S, B\\rangle$, Support set and Batch set.</p>\n<ul>\n<li>Training steps</li>\n</ul>\n<ol>\n<li>sample a subset of labels $L\\subset\\mathcal{L}$.</li>\n<li>samples a support set $S^L \\subset \\mathcal{D}$ and a training batch $B^L \\subset \\mathcal{D}$. Both of them belong to the sampled label set $L$, $y \\in L, \\forall (x, y) \\in S^L, B^L$.</li>\n<li>support set is the input of model.</li>\n<li>the update of model parameters is based on the loss in backpropagation calculated from the mini-batch $B^L$.</li>\n</ol>\n<p>each pair of sampled dataset $(S^L, B^L)$ is regarded as one data point, such that trained models can generalize to other datasets. Symbols in red are added for meta-learning in addition to the general supervised learning objective.<br>\\begin{aligned}<br>\\theta = \\arg\\max<em>\\theta \\color{red}{E</em>{L\\subset\\mathcal{L}}[} E<em>{\\color{red}{S^L \\subset\\mathcal{D}, }B^L \\subset\\mathcal{D}} [\\sum</em>{(x, y)\\in B^L} P_\\theta(x, y\\color{red}{, S^L})] \\color{red}{]}<br>\\end{aligned}</p>\n<ul>\n<li>Traning stages</li>\n</ul>\n<ol>\n<li>meta-learner: a optimizer $g<em>\\phi$ learns how to update the learner model’s parameters via the support set $S$, $\\theta’ = g</em>\\phi(\\theta, S)$</li>\n<li>learner: A classifier $f_\\theta$ is the “learner” model, trained for operating a given task.<!-- final learning objective is $\\mathbb{E}_{L\\subset\\mathcal{L}}[ \\mathbb{E}_{S^L \\subset\\mathcal{D}, B^L \\subset\\mathcal{D}} [\\sum_{(\\mathbf{x}, y)\\in B^L} P_{g_\\phi(\\theta, S^L)}(y \\vert \\mathbf{x})]]$ -->\n</li>\n</ol>\n<h3 id=\"Common-methods\"><a href=\"#Common-methods\" class=\"headerlink\" title=\"Common methods\"></a>Common methods</h3><h4 id=\"model-based-f-theta-mathbf-x-S\"><a href=\"#model-based-f-theta-mathbf-x-S\" class=\"headerlink\" title=\"model-based: $f_\\theta(\\mathbf{x}, S)$\"></a>model-based: $f_\\theta(\\mathbf{x}, S)$</h4><ul>\n<li>use <em><strong>recurrent</strong></em> network with <em><strong>internal (or external)</strong></em> memory.</li>\n</ul>\n<h4 id=\"metric-based-sum-mathbf-x-i-y-i-in-S-k-theta-mathbf-x-mathbf-x-i-y-i\"><a href=\"#metric-based-sum-mathbf-x-i-y-i-in-S-k-theta-mathbf-x-mathbf-x-i-y-i\" class=\"headerlink\" title=\"metric-based: $\\sum{(\\mathbf{x}_i, y_i) \\in S} k\\theta(\\mathbf{x}, \\mathbf{x}_i)y_i$\"></a>metric-based: $\\sum<em>{(\\mathbf{x}_i, y_i) \\in S} k</em>\\theta(\\mathbf{x}, \\mathbf{x}_i)y_i$</h4><ul>\n<li>learn <em><strong>efficient</strong></em> distance metric.</li>\n<li>similar to <em><strong>nearnest neighbors algorithm</strong></em> (KNN,k-means) and <em><strong>kernel density estimation</strong></em>.</li>\n<li>the predicted possibility of labeled samples is from is a <em><strong>weighted sum of support set samples</strong></em>, and the weight is generated by a kernel function $k<em>\\theta$, which can measure the *<em>_similarity</em></em>* of twp data samples:<script type=\"math/tex; mode=display\">\nP_\\theta(y \\vert \\mathbf{x}, S) = \\sum_{(\\mathbf{x}_i, y_i) \\in S} k_\\theta(\\mathbf{x}, \\mathbf{x}_i)y_{i}</script></li>\n<li>crucial keys: <em><strong>good kernel</strong></em></li>\n<li>solution: learning <em><strong>embedding vector</strong></em> of input data explicitly and use them to design <em><strong>proper kernel</strong></em> functions.</li>\n<li>Siamese networks: <ul>\n<li>assumption: the <em><strong>learned embedding</strong></em> can be <em><strong>generalized</strong></em> to be useful for measuring the distance between images of unknown categories.</li>\n<li><em><strong>verification</strong></em>, images pairs.</li>\n<li>final prediction is the class of the support image with highest probability.</li>\n</ul>\n</li>\n<li>Matching networks:<ul>\n<li>$g<em>{\\theta}$ with $k$ classifiers for k classes, while $f</em>{\\theta}$ for testing images.</li>\n<li>attention kernel depends on two embedding functions $g$ and $f$, in simple version where $f=g$. in complex version where integrating full contextual embedding (FCE), it achieves improvement on hard tasks, not for simple tasks.</li>\n</ul>\n</li>\n<li>Relation network<ul>\n<li>image pairs, feature concatenation.</li>\n<li>relation modeled: mse loss function.</li>\n</ul>\n</li>\n<li>Prototypical<ul>\n<li>images of each class are embedded into $M$ dimensional feature vector, each class has <em>prototype</em> feature vector from the mean vector of the embedded support data samples in each class.</li>\n<li>squared euclidean distance.</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"optimization-based-P-g-phi-theta-S-L-y-vert-mathbf-x\"><a href=\"#optimization-based-P-g-phi-theta-S-L-y-vert-mathbf-x\" class=\"headerlink\" title=\"optimization-based: $P{g\\phi(\\theta, S^L)}(y \\vert \\mathbf{x})$\"></a>optimization-based: $P<em>{g</em>\\phi(\\theta, S^L)}(y \\vert \\mathbf{x})$</h4><ul>\n<li>optimize the <em><strong>model parameter</strong></em> explicitly for <em><strong>fast</strong></em> learning</li>\n</ul>\n"},{"title":"MMD and Density","date":"2019-01-15T02:31:01.000Z","_content":"\n\n## Relation between MMD and density for pseudo data selection\n\ncombination of MMD and density: my understanding is that we can obtain MMD, density, prior weights from GMM, when GMM can be calculated from ground-trurh label of \n\n* MMD: first-order information\n\n* Density: second-order information, the larger variance, the sparser, the small variance, the denser \n\n### GMM\n\n* Gaussian Mixed Model: A Gaussian mixture model is a probabilistic model that assumes all the data points are generated from a mixture of a finite number of Gaussian distributions with unknown parameters. One can think of mixture models as generalizing k-means clustering to incorporate information about the covariance structure of the data as well as the centers of the latent Gaussians.\n\n\n* Differentce between k-means and GMM: k-means notes that each point is assigned to different clusters, while GMM can calculate the probabiliy of each point belong to each clusters.\n\n* Import parameters of GMM: K Gaussion models, also K clusters, \\pi, \\mu, \\Sigma\n\\begin{aligned}\np(x) & = \\sum_{k=1}^K p(k)p(x|k) = \\sum_{k=1}^K \\pi_k \\mathcal{N}(x|\\mu_k, \\Sigma_k)\n\\end{aligned}\n\n","source":"_posts/GMM.md","raw":"---\ntitle: MMD and Density\ndate: 2019-01-15 10:31:01\ntags: pseudo labels\ncategories: Theory\n---\n\n\n## Relation between MMD and density for pseudo data selection\n\ncombination of MMD and density: my understanding is that we can obtain MMD, density, prior weights from GMM, when GMM can be calculated from ground-trurh label of \n\n* MMD: first-order information\n\n* Density: second-order information, the larger variance, the sparser, the small variance, the denser \n\n### GMM\n\n* Gaussian Mixed Model: A Gaussian mixture model is a probabilistic model that assumes all the data points are generated from a mixture of a finite number of Gaussian distributions with unknown parameters. One can think of mixture models as generalizing k-means clustering to incorporate information about the covariance structure of the data as well as the centers of the latent Gaussians.\n\n\n* Differentce between k-means and GMM: k-means notes that each point is assigned to different clusters, while GMM can calculate the probabiliy of each point belong to each clusters.\n\n* Import parameters of GMM: K Gaussion models, also K clusters, \\pi, \\mu, \\Sigma\n\\begin{aligned}\np(x) & = \\sum_{k=1}^K p(k)p(x|k) = \\sum_{k=1}^K \\pi_k \\mathcal{N}(x|\\mu_k, \\Sigma_k)\n\\end{aligned}\n\n","slug":"GMM","published":1,"updated":"2019-04-08T06:20:55.948Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cju7zelmq000dqrm7080fbv99","content":"<h2 id=\"Relation-between-MMD-and-density-for-pseudo-data-selection\"><a href=\"#Relation-between-MMD-and-density-for-pseudo-data-selection\" class=\"headerlink\" title=\"Relation between MMD and density for pseudo data selection\"></a>Relation between MMD and density for pseudo data selection</h2><p>combination of MMD and density: my understanding is that we can obtain MMD, density, prior weights from GMM, when GMM can be calculated from ground-trurh label of </p>\n<ul>\n<li><p>MMD: first-order information</p>\n</li>\n<li><p>Density: second-order information, the larger variance, the sparser, the small variance, the denser </p>\n</li>\n</ul>\n<h3 id=\"GMM\"><a href=\"#GMM\" class=\"headerlink\" title=\"GMM\"></a>GMM</h3><ul>\n<li>Gaussian Mixed Model: A Gaussian mixture model is a probabilistic model that assumes all the data points are generated from a mixture of a finite number of Gaussian distributions with unknown parameters. One can think of mixture models as generalizing k-means clustering to incorporate information about the covariance structure of the data as well as the centers of the latent Gaussians.</li>\n</ul>\n<ul>\n<li><p>Differentce between k-means and GMM: k-means notes that each point is assigned to different clusters, while GMM can calculate the probabiliy of each point belong to each clusters.</p>\n</li>\n<li><p>Import parameters of GMM: K Gaussion models, also K clusters, \\pi, \\mu, \\Sigma<br>\\begin{aligned}<br>p(x) &amp; = \\sum<em>{k=1}^K p(k)p(x|k) = \\sum</em>{k=1}^K \\pi_k \\mathcal{N}(x|\\mu_k, \\Sigma_k)<br>\\end{aligned}</p>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"Relation-between-MMD-and-density-for-pseudo-data-selection\"><a href=\"#Relation-between-MMD-and-density-for-pseudo-data-selection\" class=\"headerlink\" title=\"Relation between MMD and density for pseudo data selection\"></a>Relation between MMD and density for pseudo data selection</h2><p>combination of MMD and density: my understanding is that we can obtain MMD, density, prior weights from GMM, when GMM can be calculated from ground-trurh label of </p>\n<ul>\n<li><p>MMD: first-order information</p>\n</li>\n<li><p>Density: second-order information, the larger variance, the sparser, the small variance, the denser </p>\n</li>\n</ul>\n<h3 id=\"GMM\"><a href=\"#GMM\" class=\"headerlink\" title=\"GMM\"></a>GMM</h3><ul>\n<li>Gaussian Mixed Model: A Gaussian mixture model is a probabilistic model that assumes all the data points are generated from a mixture of a finite number of Gaussian distributions with unknown parameters. One can think of mixture models as generalizing k-means clustering to incorporate information about the covariance structure of the data as well as the centers of the latent Gaussians.</li>\n</ul>\n<ul>\n<li><p>Differentce between k-means and GMM: k-means notes that each point is assigned to different clusters, while GMM can calculate the probabiliy of each point belong to each clusters.</p>\n</li>\n<li><p>Import parameters of GMM: K Gaussion models, also K clusters, \\pi, \\mu, \\Sigma<br>\\begin{aligned}<br>p(x) &amp; = \\sum<em>{k=1}^K p(k)p(x|k) = \\sum</em>{k=1}^K \\pi_k \\mathcal{N}(x|\\mu_k, \\Sigma_k)<br>\\end{aligned}</p>\n</li>\n</ul>\n"},{"title":"Heterogeneous Multitask","date":"2019-02-26T07:46:30.000Z","_content":"\n\n# Large-scale Heterogeneous Learning in Big Data Analytics\n> reference slide [Large-scale Heterogeneous Learning in Big Data Analytics](http://cci.drexel.edu/bigdata/bigdata2014/MTL_BigData_14.pdf)\n\n* multi-task learning\n'Multitask learning is an inductive transfer mechanism for improving generalization performance [Caruana, Machine Learning’97]'\n* multi-label learning:\n* multi-view learning:\n\n## Heterogeneous outputs related to each other with the same set of inputs\n> reference-1 [Heterogeneous Multitask Learning with Joint Sparsity Constraints](http://www.cs.cmu.edu/~sssykim/papers/yang_kim_xing_nips09.pdf)\n  \n  1. probelm: dealing with homogeneous tasks, such as purely regression (continue) or classification (discrete) task, from a common set of high-dimensional feature space. \n  2. method: modeling the joint sparsity as L1/L∞ or L1/L2 norm of the model parameters, achieving joint sparse feature selection.\n  3. datasets: discovering genetic markers that influence multiple correlated traits jointly, datasets with different clinical traits including continuous and discrete labels.\n\n## Heterogeneous inputs from multiple domains\n> reference-2 [Heterogeneous Multitask Metric Learning\nAcross Multiple Domains](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8058002&tag=1) [Exploiting High-Order Information in Heterogeneous Multi-Task Feature Learning](https://www.semanticscholar.org/paper/Exploiting-High-Order-Information-in-Heterogeneous-Luo-Tao/1bf6d4b31fa26aa9e0c2b759e6bee9ec718dcae7)\n\n* 'Multitask metric learning (MTML), which can be regarded as a special case of transfer metric learning (TML) by performing transfer across all related domains.'\n* 'Heterogeneous transfer learning approaches can be adopted to remedy this drawback by deriving a metric from the learned transformation across different domains'\n  1. probelm: inputs from heterogeneous domain can be solved by deriving a metric from the learned transformation from two domains, but pratical aims is to deal with multiple domain by learning the metric from all domains.\n  2. method: metrics -> transformation -> subspace -> maximize high-order ovariance among the predictive structures of these domains, because high-order statistics (correlation information), which can only be exploited by simultaneously examining all domains, thus obtaining more reliable feature transformations and metrics.\n  3. datasets: Document Categorization, Scene Classification and Image Annotation\n\n## Heterogeneous features for different task\n> reference-3 [Semantic Feature Learning for Heterogeneous\nMultitask Classification via Non-Negative\nMatrix Factorization](http://www.intsci.ac.cn/users/fzzhuang/papers/TOC2017.pdf)\n  \n  1. problem: different tasks have heterogenous feature in real world.\n  2. method: leveraging a non-negative matrix factorization-based multitask method (MTNMF) to learn a common semantic feature space underlying different heterogeneous feature spaces of each task. it is similar to reference-1, feature selection vs feature factorization.\n  3. datasets: 20Newsgroups&ImageNet (image and document), Email Spam Detection (15 persons), Sentiment Classification (books;  dvd; electronics; kitchen)\n\n","source":"_posts/Heterogeneous-Multitask.md","raw":"---\ntitle: Heterogeneous Multitask\ndate: 2019-02-26 15:46:30\ntags: multitask\ncategories: Deep learning\n---\n\n\n# Large-scale Heterogeneous Learning in Big Data Analytics\n> reference slide [Large-scale Heterogeneous Learning in Big Data Analytics](http://cci.drexel.edu/bigdata/bigdata2014/MTL_BigData_14.pdf)\n\n* multi-task learning\n'Multitask learning is an inductive transfer mechanism for improving generalization performance [Caruana, Machine Learning’97]'\n* multi-label learning:\n* multi-view learning:\n\n## Heterogeneous outputs related to each other with the same set of inputs\n> reference-1 [Heterogeneous Multitask Learning with Joint Sparsity Constraints](http://www.cs.cmu.edu/~sssykim/papers/yang_kim_xing_nips09.pdf)\n  \n  1. probelm: dealing with homogeneous tasks, such as purely regression (continue) or classification (discrete) task, from a common set of high-dimensional feature space. \n  2. method: modeling the joint sparsity as L1/L∞ or L1/L2 norm of the model parameters, achieving joint sparse feature selection.\n  3. datasets: discovering genetic markers that influence multiple correlated traits jointly, datasets with different clinical traits including continuous and discrete labels.\n\n## Heterogeneous inputs from multiple domains\n> reference-2 [Heterogeneous Multitask Metric Learning\nAcross Multiple Domains](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8058002&tag=1) [Exploiting High-Order Information in Heterogeneous Multi-Task Feature Learning](https://www.semanticscholar.org/paper/Exploiting-High-Order-Information-in-Heterogeneous-Luo-Tao/1bf6d4b31fa26aa9e0c2b759e6bee9ec718dcae7)\n\n* 'Multitask metric learning (MTML), which can be regarded as a special case of transfer metric learning (TML) by performing transfer across all related domains.'\n* 'Heterogeneous transfer learning approaches can be adopted to remedy this drawback by deriving a metric from the learned transformation across different domains'\n  1. probelm: inputs from heterogeneous domain can be solved by deriving a metric from the learned transformation from two domains, but pratical aims is to deal with multiple domain by learning the metric from all domains.\n  2. method: metrics -> transformation -> subspace -> maximize high-order ovariance among the predictive structures of these domains, because high-order statistics (correlation information), which can only be exploited by simultaneously examining all domains, thus obtaining more reliable feature transformations and metrics.\n  3. datasets: Document Categorization, Scene Classification and Image Annotation\n\n## Heterogeneous features for different task\n> reference-3 [Semantic Feature Learning for Heterogeneous\nMultitask Classification via Non-Negative\nMatrix Factorization](http://www.intsci.ac.cn/users/fzzhuang/papers/TOC2017.pdf)\n  \n  1. problem: different tasks have heterogenous feature in real world.\n  2. method: leveraging a non-negative matrix factorization-based multitask method (MTNMF) to learn a common semantic feature space underlying different heterogeneous feature spaces of each task. it is similar to reference-1, feature selection vs feature factorization.\n  3. datasets: 20Newsgroups&ImageNet (image and document), Email Spam Detection (15 persons), Sentiment Classification (books;  dvd; electronics; kitchen)\n\n","slug":"Heterogeneous-Multitask","published":1,"updated":"2019-04-08T06:20:55.948Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cju7zelmr000iqrm7uqg228ml","content":"<h1 id=\"Large-scale-Heterogeneous-Learning-in-Big-Data-Analytics\"><a href=\"#Large-scale-Heterogeneous-Learning-in-Big-Data-Analytics\" class=\"headerlink\" title=\"Large-scale Heterogeneous Learning in Big Data Analytics\"></a>Large-scale Heterogeneous Learning in Big Data Analytics</h1><blockquote>\n<p>reference slide <a href=\"http://cci.drexel.edu/bigdata/bigdata2014/MTL_BigData_14.pdf\" target=\"_blank\" rel=\"noopener\">Large-scale Heterogeneous Learning in Big Data Analytics</a></p>\n</blockquote>\n<ul>\n<li>multi-task learning<br>‘Multitask learning is an inductive transfer mechanism for improving generalization performance [Caruana, Machine Learning’97]’</li>\n<li>multi-label learning:</li>\n<li>multi-view learning:</li>\n</ul>\n<h2 id=\"Heterogeneous-outputs-related-to-each-other-with-the-same-set-of-inputs\"><a href=\"#Heterogeneous-outputs-related-to-each-other-with-the-same-set-of-inputs\" class=\"headerlink\" title=\"Heterogeneous outputs related to each other with the same set of inputs\"></a>Heterogeneous outputs related to each other with the same set of inputs</h2><blockquote>\n<p>reference-1 <a href=\"http://www.cs.cmu.edu/~sssykim/papers/yang_kim_xing_nips09.pdf\" target=\"_blank\" rel=\"noopener\">Heterogeneous Multitask Learning with Joint Sparsity Constraints</a></p>\n</blockquote>\n<ol>\n<li>probelm: dealing with homogeneous tasks, such as purely regression (continue) or classification (discrete) task, from a common set of high-dimensional feature space. </li>\n<li>method: modeling the joint sparsity as L1/L∞ or L1/L2 norm of the model parameters, achieving joint sparse feature selection.</li>\n<li>datasets: discovering genetic markers that influence multiple correlated traits jointly, datasets with different clinical traits including continuous and discrete labels.</li>\n</ol>\n<h2 id=\"Heterogeneous-inputs-from-multiple-domains\"><a href=\"#Heterogeneous-inputs-from-multiple-domains\" class=\"headerlink\" title=\"Heterogeneous inputs from multiple domains\"></a>Heterogeneous inputs from multiple domains</h2><blockquote>\n<p>reference-2 <a href=\"https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=8058002&amp;tag=1\" target=\"_blank\" rel=\"noopener\">Heterogeneous Multitask Metric Learning<br>Across Multiple Domains</a> <a href=\"https://www.semanticscholar.org/paper/Exploiting-High-Order-Information-in-Heterogeneous-Luo-Tao/1bf6d4b31fa26aa9e0c2b759e6bee9ec718dcae7\" target=\"_blank\" rel=\"noopener\">Exploiting High-Order Information in Heterogeneous Multi-Task Feature Learning</a></p>\n</blockquote>\n<ul>\n<li>‘Multitask metric learning (MTML), which can be regarded as a special case of transfer metric learning (TML) by performing transfer across all related domains.’</li>\n<li>‘Heterogeneous transfer learning approaches can be adopted to remedy this drawback by deriving a metric from the learned transformation across different domains’<ol>\n<li>probelm: inputs from heterogeneous domain can be solved by deriving a metric from the learned transformation from two domains, but pratical aims is to deal with multiple domain by learning the metric from all domains.</li>\n<li>method: metrics -&gt; transformation -&gt; subspace -&gt; maximize high-order ovariance among the predictive structures of these domains, because high-order statistics (correlation information), which can only be exploited by simultaneously examining all domains, thus obtaining more reliable feature transformations and metrics.</li>\n<li>datasets: Document Categorization, Scene Classification and Image Annotation</li>\n</ol>\n</li>\n</ul>\n<h2 id=\"Heterogeneous-features-for-different-task\"><a href=\"#Heterogeneous-features-for-different-task\" class=\"headerlink\" title=\"Heterogeneous features for different task\"></a>Heterogeneous features for different task</h2><blockquote>\n<p>reference-3 <a href=\"http://www.intsci.ac.cn/users/fzzhuang/papers/TOC2017.pdf\" target=\"_blank\" rel=\"noopener\">Semantic Feature Learning for Heterogeneous<br>Multitask Classification via Non-Negative<br>Matrix Factorization</a></p>\n</blockquote>\n<ol>\n<li>problem: different tasks have heterogenous feature in real world.</li>\n<li>method: leveraging a non-negative matrix factorization-based multitask method (MTNMF) to learn a common semantic feature space underlying different heterogeneous feature spaces of each task. it is similar to reference-1, feature selection vs feature factorization.</li>\n<li>datasets: 20Newsgroups&amp;ImageNet (image and document), Email Spam Detection (15 persons), Sentiment Classification (books;  dvd; electronics; kitchen)</li>\n</ol>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"Large-scale-Heterogeneous-Learning-in-Big-Data-Analytics\"><a href=\"#Large-scale-Heterogeneous-Learning-in-Big-Data-Analytics\" class=\"headerlink\" title=\"Large-scale Heterogeneous Learning in Big Data Analytics\"></a>Large-scale Heterogeneous Learning in Big Data Analytics</h1><blockquote>\n<p>reference slide <a href=\"http://cci.drexel.edu/bigdata/bigdata2014/MTL_BigData_14.pdf\" target=\"_blank\" rel=\"noopener\">Large-scale Heterogeneous Learning in Big Data Analytics</a></p>\n</blockquote>\n<ul>\n<li>multi-task learning<br>‘Multitask learning is an inductive transfer mechanism for improving generalization performance [Caruana, Machine Learning’97]’</li>\n<li>multi-label learning:</li>\n<li>multi-view learning:</li>\n</ul>\n<h2 id=\"Heterogeneous-outputs-related-to-each-other-with-the-same-set-of-inputs\"><a href=\"#Heterogeneous-outputs-related-to-each-other-with-the-same-set-of-inputs\" class=\"headerlink\" title=\"Heterogeneous outputs related to each other with the same set of inputs\"></a>Heterogeneous outputs related to each other with the same set of inputs</h2><blockquote>\n<p>reference-1 <a href=\"http://www.cs.cmu.edu/~sssykim/papers/yang_kim_xing_nips09.pdf\" target=\"_blank\" rel=\"noopener\">Heterogeneous Multitask Learning with Joint Sparsity Constraints</a></p>\n</blockquote>\n<ol>\n<li>probelm: dealing with homogeneous tasks, such as purely regression (continue) or classification (discrete) task, from a common set of high-dimensional feature space. </li>\n<li>method: modeling the joint sparsity as L1/L∞ or L1/L2 norm of the model parameters, achieving joint sparse feature selection.</li>\n<li>datasets: discovering genetic markers that influence multiple correlated traits jointly, datasets with different clinical traits including continuous and discrete labels.</li>\n</ol>\n<h2 id=\"Heterogeneous-inputs-from-multiple-domains\"><a href=\"#Heterogeneous-inputs-from-multiple-domains\" class=\"headerlink\" title=\"Heterogeneous inputs from multiple domains\"></a>Heterogeneous inputs from multiple domains</h2><blockquote>\n<p>reference-2 <a href=\"https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=8058002&amp;tag=1\" target=\"_blank\" rel=\"noopener\">Heterogeneous Multitask Metric Learning<br>Across Multiple Domains</a> <a href=\"https://www.semanticscholar.org/paper/Exploiting-High-Order-Information-in-Heterogeneous-Luo-Tao/1bf6d4b31fa26aa9e0c2b759e6bee9ec718dcae7\" target=\"_blank\" rel=\"noopener\">Exploiting High-Order Information in Heterogeneous Multi-Task Feature Learning</a></p>\n</blockquote>\n<ul>\n<li>‘Multitask metric learning (MTML), which can be regarded as a special case of transfer metric learning (TML) by performing transfer across all related domains.’</li>\n<li>‘Heterogeneous transfer learning approaches can be adopted to remedy this drawback by deriving a metric from the learned transformation across different domains’<ol>\n<li>probelm: inputs from heterogeneous domain can be solved by deriving a metric from the learned transformation from two domains, but pratical aims is to deal with multiple domain by learning the metric from all domains.</li>\n<li>method: metrics -&gt; transformation -&gt; subspace -&gt; maximize high-order ovariance among the predictive structures of these domains, because high-order statistics (correlation information), which can only be exploited by simultaneously examining all domains, thus obtaining more reliable feature transformations and metrics.</li>\n<li>datasets: Document Categorization, Scene Classification and Image Annotation</li>\n</ol>\n</li>\n</ul>\n<h2 id=\"Heterogeneous-features-for-different-task\"><a href=\"#Heterogeneous-features-for-different-task\" class=\"headerlink\" title=\"Heterogeneous features for different task\"></a>Heterogeneous features for different task</h2><blockquote>\n<p>reference-3 <a href=\"http://www.intsci.ac.cn/users/fzzhuang/papers/TOC2017.pdf\" target=\"_blank\" rel=\"noopener\">Semantic Feature Learning for Heterogeneous<br>Multitask Classification via Non-Negative<br>Matrix Factorization</a></p>\n</blockquote>\n<ol>\n<li>problem: different tasks have heterogenous feature in real world.</li>\n<li>method: leveraging a non-negative matrix factorization-based multitask method (MTNMF) to learn a common semantic feature space underlying different heterogeneous feature spaces of each task. it is similar to reference-1, feature selection vs feature factorization.</li>\n<li>datasets: 20Newsgroups&amp;ImageNet (image and document), Email Spam Detection (15 persons), Sentiment Classification (books;  dvd; electronics; kitchen)</li>\n</ol>\n"},{"title":"Manifold Learning","date":"2019-03-18T08:24:56.000Z","_content":"\n## Manifold Leanring for Semi-supervised Learning\n* the model trained with labeled samples and unlabeled samples\n* introducing manifold learning to learn the geometry of marginal distribution >reference first paper[Manifold Regularization: A Geometric Framework for Learning from Labeled and Unlabeled Examples](http://www.jmlr.org/papers/volume7/belkin06a/belkin06a.pdf) \n  * explanation in Chinese(https://zhuanlan.zhihu.com/p/33006509)\n  * aim: data-depend regularization to exploit geometry of the marginal distribution\n\n### Manifold learning\n* non-linear dimensionality reduction method to obtain intrinsic feature >reference PAMI\n\n### Semi-supervised Learning with Manifold Learning\n* reason: leveraging a few of training samples to train model always fail to reflect the dataset distribution, which means that the trained model only adapt to the supervised label without learning the intrinsic feature. Introducing manifold learning to combine labeled samples and unlabeled samples can exploit the geometr of marginal distribution.\n\n### Semi-supervised Multi-task Learning with Manifold Learning\n\n\n>reference [Semisupervised feature analysis by mining correlations among multiple tasks]{https://arxiv.org/pdf/1411.6232.pdf}\n  \n  * aim: feature selection in semi-supervised MTL\n  * method: sparce coefficients learnt \n           \\begin{aligned}\n\t\t   p(x) & = \\min_{w_t} \\sum_(l=1}^t (loss(w_l) + \\alpha ||w_l||_{1,2} + \\gamma ||w||_{\\*})\n\t\t   \\end{aligned}\n\n\t\t   including $l_{1,2}$ norm and Laplacian norm:\n\n\t\t   \\begin{aligned}\n\t\t   \\gamma ||w|| = \\min_{w,b}\\sum_{l=1}{t}Tr(w^Tx_lL_lx_l^Tw)\n\t\t   \\end{aligned}\n\n\n\n>reference [Semi-supervised multitask learning]{http://papers.nips.cc/paper/3198-semi-supervised-multitask-learning.pdf}\n\n>reference [Semi-supervised multi-task learning with task regularizations]{http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.194.1854&rep=rep1&type=pdf}\n\n>reference [Semi-supervised multitask learning for scene recognition]{https://www.researchgate.net/profile/Lichao_Mou/publication/268880603_Semi-Supervised_Multitask_Learning_for_Scene_Recognition/links/567a67f608ae7fea2e9a08f1.pdf}\n\n","source":"_posts/Manifold-Learning.md","raw":"---\ntitle: Manifold Learning\ndate: 2019-03-18 16:24:56\ntags: feature regularization\ncategories: Deep learning\n---\n\n## Manifold Leanring for Semi-supervised Learning\n* the model trained with labeled samples and unlabeled samples\n* introducing manifold learning to learn the geometry of marginal distribution >reference first paper[Manifold Regularization: A Geometric Framework for Learning from Labeled and Unlabeled Examples](http://www.jmlr.org/papers/volume7/belkin06a/belkin06a.pdf) \n  * explanation in Chinese(https://zhuanlan.zhihu.com/p/33006509)\n  * aim: data-depend regularization to exploit geometry of the marginal distribution\n\n### Manifold learning\n* non-linear dimensionality reduction method to obtain intrinsic feature >reference PAMI\n\n### Semi-supervised Learning with Manifold Learning\n* reason: leveraging a few of training samples to train model always fail to reflect the dataset distribution, which means that the trained model only adapt to the supervised label without learning the intrinsic feature. Introducing manifold learning to combine labeled samples and unlabeled samples can exploit the geometr of marginal distribution.\n\n### Semi-supervised Multi-task Learning with Manifold Learning\n\n\n>reference [Semisupervised feature analysis by mining correlations among multiple tasks]{https://arxiv.org/pdf/1411.6232.pdf}\n  \n  * aim: feature selection in semi-supervised MTL\n  * method: sparce coefficients learnt \n           \\begin{aligned}\n\t\t   p(x) & = \\min_{w_t} \\sum_(l=1}^t (loss(w_l) + \\alpha ||w_l||_{1,2} + \\gamma ||w||_{\\*})\n\t\t   \\end{aligned}\n\n\t\t   including $l_{1,2}$ norm and Laplacian norm:\n\n\t\t   \\begin{aligned}\n\t\t   \\gamma ||w|| = \\min_{w,b}\\sum_{l=1}{t}Tr(w^Tx_lL_lx_l^Tw)\n\t\t   \\end{aligned}\n\n\n\n>reference [Semi-supervised multitask learning]{http://papers.nips.cc/paper/3198-semi-supervised-multitask-learning.pdf}\n\n>reference [Semi-supervised multi-task learning with task regularizations]{http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.194.1854&rep=rep1&type=pdf}\n\n>reference [Semi-supervised multitask learning for scene recognition]{https://www.researchgate.net/profile/Lichao_Mou/publication/268880603_Semi-Supervised_Multitask_Learning_for_Scene_Recognition/links/567a67f608ae7fea2e9a08f1.pdf}\n\n","slug":"Manifold-Learning","published":1,"updated":"2019-04-08T06:20:55.948Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cju7zelmt000jqrm78iuwh6gd","content":"<h2 id=\"Manifold-Leanring-for-Semi-supervised-Learning\"><a href=\"#Manifold-Leanring-for-Semi-supervised-Learning\" class=\"headerlink\" title=\"Manifold Leanring for Semi-supervised Learning\"></a>Manifold Leanring for Semi-supervised Learning</h2><ul>\n<li>the model trained with labeled samples and unlabeled samples</li>\n<li>introducing manifold learning to learn the geometry of marginal distribution &gt;reference first paper<a href=\"http://www.jmlr.org/papers/volume7/belkin06a/belkin06a.pdf\" target=\"_blank\" rel=\"noopener\">Manifold Regularization: A Geometric Framework for Learning from Labeled and Unlabeled Examples</a> <ul>\n<li>explanation in Chinese(<a href=\"https://zhuanlan.zhihu.com/p/33006509\" target=\"_blank\" rel=\"noopener\">https://zhuanlan.zhihu.com/p/33006509</a>)</li>\n<li>aim: data-depend regularization to exploit geometry of the marginal distribution</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"Manifold-learning\"><a href=\"#Manifold-learning\" class=\"headerlink\" title=\"Manifold learning\"></a>Manifold learning</h3><ul>\n<li>non-linear dimensionality reduction method to obtain intrinsic feature &gt;reference PAMI</li>\n</ul>\n<h3 id=\"Semi-supervised-Learning-with-Manifold-Learning\"><a href=\"#Semi-supervised-Learning-with-Manifold-Learning\" class=\"headerlink\" title=\"Semi-supervised Learning with Manifold Learning\"></a>Semi-supervised Learning with Manifold Learning</h3><ul>\n<li>reason: leveraging a few of training samples to train model always fail to reflect the dataset distribution, which means that the trained model only adapt to the supervised label without learning the intrinsic feature. Introducing manifold learning to combine labeled samples and unlabeled samples can exploit the geometr of marginal distribution.</li>\n</ul>\n<h3 id=\"Semi-supervised-Multi-task-Learning-with-Manifold-Learning\"><a href=\"#Semi-supervised-Multi-task-Learning-with-Manifold-Learning\" class=\"headerlink\" title=\"Semi-supervised Multi-task Learning with Manifold Learning\"></a>Semi-supervised Multi-task Learning with Manifold Learning</h3><blockquote>\n<p>reference [Semisupervised feature analysis by mining correlations among multiple tasks]{<a href=\"https://arxiv.org/pdf/1411.6232.pdf}\" target=\"_blank\" rel=\"noopener\">https://arxiv.org/pdf/1411.6232.pdf}</a></p>\n</blockquote>\n<ul>\n<li>aim: feature selection in semi-supervised MTL</li>\n<li><p>method: sparce coefficients learnt </p>\n<pre><code>   \\begin{aligned}\n   p(x) &amp; = \\min_{w_t} \\sum_(l=1}^t (loss(w_l) + \\alpha ||w_l||_{1,2} + \\gamma ||w||_{\\*})\n   \\end{aligned}\n\n   including $l_{1,2}$ norm and Laplacian norm:\n\n   \\begin{aligned}\n   \\gamma ||w|| = \\min_{w,b}\\sum_{l=1}{t}Tr(w^Tx_lL_lx_l^Tw)\n   \\end{aligned}\n</code></pre></li>\n</ul>\n<blockquote>\n<p>reference [Semi-supervised multitask learning]{<a href=\"http://papers.nips.cc/paper/3198-semi-supervised-multitask-learning.pdf}\" target=\"_blank\" rel=\"noopener\">http://papers.nips.cc/paper/3198-semi-supervised-multitask-learning.pdf}</a></p>\n<p>reference [Semi-supervised multi-task learning with task regularizations]{<a href=\"http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.194.1854&amp;rep=rep1&amp;type=pdf}\" target=\"_blank\" rel=\"noopener\">http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.194.1854&amp;rep=rep1&amp;type=pdf}</a></p>\n<p>reference [Semi-supervised multitask learning for scene recognition]{<a href=\"https://www.researchgate.net/profile/Lichao_Mou/publication/268880603_Semi-Supervised_Multitask_Learning_for_Scene_Recognition/links/567a67f608ae7fea2e9a08f1.pdf}\" target=\"_blank\" rel=\"noopener\">https://www.researchgate.net/profile/Lichao_Mou/publication/268880603_Semi-Supervised_Multitask_Learning_for_Scene_Recognition/links/567a67f608ae7fea2e9a08f1.pdf}</a></p>\n</blockquote>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"Manifold-Leanring-for-Semi-supervised-Learning\"><a href=\"#Manifold-Leanring-for-Semi-supervised-Learning\" class=\"headerlink\" title=\"Manifold Leanring for Semi-supervised Learning\"></a>Manifold Leanring for Semi-supervised Learning</h2><ul>\n<li>the model trained with labeled samples and unlabeled samples</li>\n<li>introducing manifold learning to learn the geometry of marginal distribution &gt;reference first paper<a href=\"http://www.jmlr.org/papers/volume7/belkin06a/belkin06a.pdf\" target=\"_blank\" rel=\"noopener\">Manifold Regularization: A Geometric Framework for Learning from Labeled and Unlabeled Examples</a> <ul>\n<li>explanation in Chinese(<a href=\"https://zhuanlan.zhihu.com/p/33006509\" target=\"_blank\" rel=\"noopener\">https://zhuanlan.zhihu.com/p/33006509</a>)</li>\n<li>aim: data-depend regularization to exploit geometry of the marginal distribution</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"Manifold-learning\"><a href=\"#Manifold-learning\" class=\"headerlink\" title=\"Manifold learning\"></a>Manifold learning</h3><ul>\n<li>non-linear dimensionality reduction method to obtain intrinsic feature &gt;reference PAMI</li>\n</ul>\n<h3 id=\"Semi-supervised-Learning-with-Manifold-Learning\"><a href=\"#Semi-supervised-Learning-with-Manifold-Learning\" class=\"headerlink\" title=\"Semi-supervised Learning with Manifold Learning\"></a>Semi-supervised Learning with Manifold Learning</h3><ul>\n<li>reason: leveraging a few of training samples to train model always fail to reflect the dataset distribution, which means that the trained model only adapt to the supervised label without learning the intrinsic feature. Introducing manifold learning to combine labeled samples and unlabeled samples can exploit the geometr of marginal distribution.</li>\n</ul>\n<h3 id=\"Semi-supervised-Multi-task-Learning-with-Manifold-Learning\"><a href=\"#Semi-supervised-Multi-task-Learning-with-Manifold-Learning\" class=\"headerlink\" title=\"Semi-supervised Multi-task Learning with Manifold Learning\"></a>Semi-supervised Multi-task Learning with Manifold Learning</h3><blockquote>\n<p>reference [Semisupervised feature analysis by mining correlations among multiple tasks]{<a href=\"https://arxiv.org/pdf/1411.6232.pdf}\" target=\"_blank\" rel=\"noopener\">https://arxiv.org/pdf/1411.6232.pdf}</a></p>\n</blockquote>\n<ul>\n<li>aim: feature selection in semi-supervised MTL</li>\n<li><p>method: sparce coefficients learnt </p>\n<pre><code>   \\begin{aligned}\n   p(x) &amp; = \\min_{w_t} \\sum_(l=1}^t (loss(w_l) + \\alpha ||w_l||_{1,2} + \\gamma ||w||_{\\*})\n   \\end{aligned}\n\n   including $l_{1,2}$ norm and Laplacian norm:\n\n   \\begin{aligned}\n   \\gamma ||w|| = \\min_{w,b}\\sum_{l=1}{t}Tr(w^Tx_lL_lx_l^Tw)\n   \\end{aligned}\n</code></pre></li>\n</ul>\n<blockquote>\n<p>reference [Semi-supervised multitask learning]{<a href=\"http://papers.nips.cc/paper/3198-semi-supervised-multitask-learning.pdf}\" target=\"_blank\" rel=\"noopener\">http://papers.nips.cc/paper/3198-semi-supervised-multitask-learning.pdf}</a></p>\n<p>reference [Semi-supervised multi-task learning with task regularizations]{<a href=\"http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.194.1854&amp;rep=rep1&amp;type=pdf}\" target=\"_blank\" rel=\"noopener\">http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.194.1854&amp;rep=rep1&amp;type=pdf}</a></p>\n<p>reference [Semi-supervised multitask learning for scene recognition]{<a href=\"https://www.researchgate.net/profile/Lichao_Mou/publication/268880603_Semi-Supervised_Multitask_Learning_for_Scene_Recognition/links/567a67f608ae7fea2e9a08f1.pdf}\" target=\"_blank\" rel=\"noopener\">https://www.researchgate.net/profile/Lichao_Mou/publication/268880603_Semi-Supervised_Multitask_Learning_for_Scene_Recognition/links/567a67f608ae7fea2e9a08f1.pdf}</a></p>\n</blockquote>\n"},{"title":"Numpy learning","date":"2019-01-14T14:25:55.000Z","_content":"\nOne-hot labels preprocessing\n\n* Weighting samples with confidence score\n``` bash\nindex = np.ragmax(predicted_result,axis=1)\narg = np_utils.to_categorical(index,classes)\nweighted_one_hot=predicted_result*arg\n```\n\n* Selection && weighting samples with confidence score\n``` bash\nweighted_selected_one_hot=np.where(predicted_result>k,predicted_result,0)\n```\n\n* Extending vector into matrix\n``` bash\nxx = [np.full(classes,value) for value in x]\n```\n\n\n","source":"_posts/Numpy learning.md","raw":"---\ntitle: Numpy learning\ndate: 2019-01-14 22:25:55\ntags: numpy\ncategories: Codes\n---\n\nOne-hot labels preprocessing\n\n* Weighting samples with confidence score\n``` bash\nindex = np.ragmax(predicted_result,axis=1)\narg = np_utils.to_categorical(index,classes)\nweighted_one_hot=predicted_result*arg\n```\n\n* Selection && weighting samples with confidence score\n``` bash\nweighted_selected_one_hot=np.where(predicted_result>k,predicted_result,0)\n```\n\n* Extending vector into matrix\n``` bash\nxx = [np.full(classes,value) for value in x]\n```\n\n\n","slug":"Numpy learning","published":1,"updated":"2019-04-08T06:20:55.948Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cju7zelmu000oqrm7nig10sdg","content":"<p>One-hot labels preprocessing</p>\n<ul>\n<li><p>Weighting samples with confidence score</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">index = np.ragmax(predicted_result,axis=1)</span><br><span class=\"line\">arg = np_utils.to_categorical(index,classes)</span><br><span class=\"line\">weighted_one_hot=predicted_result*arg</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>Selection &amp;&amp; weighting samples with confidence score</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">weighted_selected_one_hot=np.where(predicted_result&gt;k,predicted_result,0)</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>Extending vector into matrix</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">xx = [np.full(classes,value) <span class=\"keyword\">for</span> value <span class=\"keyword\">in</span> x]</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<p>One-hot labels preprocessing</p>\n<ul>\n<li><p>Weighting samples with confidence score</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">index = np.ragmax(predicted_result,axis=1)</span><br><span class=\"line\">arg = np_utils.to_categorical(index,classes)</span><br><span class=\"line\">weighted_one_hot=predicted_result*arg</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>Selection &amp;&amp; weighting samples with confidence score</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">weighted_selected_one_hot=np.where(predicted_result&gt;k,predicted_result,0)</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>Extending vector into matrix</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">xx = [np.full(classes,value) <span class=\"keyword\">for</span> value <span class=\"keyword\">in</span> x]</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n"},{"title":"Parameters-Selection-for-Pseudo","date":"2019-02-27T07:52:24.000Z","_content":"\n## temperature in distilled knowledge\n> reference-1 [Distilling the Knowledge in a Neural Network](https://arxiv.org/pdf/1503.02531.pdf)\n \naim: distilling the knowledge in an ensemble of models into a single model\ntemperature: the higher the temperature T, the softer the probability distribution over classes. 'For the distillation we tried temperatures of [1, 2, 5, 10] and used a relative weight of 0.5 on the cross-entropy for the hard targets, where bold font indicates the best value'\n\n> reference-2 from reference-1 [Learning without Forgetting](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8107520)\n\naim: useing only new task data to train the network while preserving the original capabilities\ntemperature: T=2, grid search method\n\n## density threshold in local feature density\n## distribution distance is transfered into weights","source":"_posts/Parameters-Selection-for-Pseudo.md","raw":"---\ntitle: Parameters-Selection-for-Pseudo\ndate: 2019-02-27 15:52:24\ntags: pesudo labels\ncategories: Deep learning\n---\n\n## temperature in distilled knowledge\n> reference-1 [Distilling the Knowledge in a Neural Network](https://arxiv.org/pdf/1503.02531.pdf)\n \naim: distilling the knowledge in an ensemble of models into a single model\ntemperature: the higher the temperature T, the softer the probability distribution over classes. 'For the distillation we tried temperatures of [1, 2, 5, 10] and used a relative weight of 0.5 on the cross-entropy for the hard targets, where bold font indicates the best value'\n\n> reference-2 from reference-1 [Learning without Forgetting](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8107520)\n\naim: useing only new task data to train the network while preserving the original capabilities\ntemperature: T=2, grid search method\n\n## density threshold in local feature density\n## distribution distance is transfered into weights","slug":"Parameters-Selection-for-Pseudo","published":1,"updated":"2019-04-08T06:20:55.948Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cju7zelmv000qqrm7wgk9wkoo","content":"<h2 id=\"temperature-in-distilled-knowledge\"><a href=\"#temperature-in-distilled-knowledge\" class=\"headerlink\" title=\"temperature in distilled knowledge\"></a>temperature in distilled knowledge</h2><blockquote>\n<p>reference-1 <a href=\"https://arxiv.org/pdf/1503.02531.pdf\" target=\"_blank\" rel=\"noopener\">Distilling the Knowledge in a Neural Network</a></p>\n</blockquote>\n<p>aim: distilling the knowledge in an ensemble of models into a single model<br>temperature: the higher the temperature T, the softer the probability distribution over classes. ‘For the distillation we tried temperatures of [1, 2, 5, 10] and used a relative weight of 0.5 on the cross-entropy for the hard targets, where bold font indicates the best value’</p>\n<blockquote>\n<p>reference-2 from reference-1 <a href=\"https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=8107520\" target=\"_blank\" rel=\"noopener\">Learning without Forgetting</a></p>\n</blockquote>\n<p>aim: useing only new task data to train the network while preserving the original capabilities<br>temperature: T=2, grid search method</p>\n<h2 id=\"density-threshold-in-local-feature-density\"><a href=\"#density-threshold-in-local-feature-density\" class=\"headerlink\" title=\"density threshold in local feature density\"></a>density threshold in local feature density</h2><h2 id=\"distribution-distance-is-transfered-into-weights\"><a href=\"#distribution-distance-is-transfered-into-weights\" class=\"headerlink\" title=\"distribution distance is transfered into weights\"></a>distribution distance is transfered into weights</h2>","site":{"data":{}},"excerpt":"","more":"<h2 id=\"temperature-in-distilled-knowledge\"><a href=\"#temperature-in-distilled-knowledge\" class=\"headerlink\" title=\"temperature in distilled knowledge\"></a>temperature in distilled knowledge</h2><blockquote>\n<p>reference-1 <a href=\"https://arxiv.org/pdf/1503.02531.pdf\" target=\"_blank\" rel=\"noopener\">Distilling the Knowledge in a Neural Network</a></p>\n</blockquote>\n<p>aim: distilling the knowledge in an ensemble of models into a single model<br>temperature: the higher the temperature T, the softer the probability distribution over classes. ‘For the distillation we tried temperatures of [1, 2, 5, 10] and used a relative weight of 0.5 on the cross-entropy for the hard targets, where bold font indicates the best value’</p>\n<blockquote>\n<p>reference-2 from reference-1 <a href=\"https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=8107520\" target=\"_blank\" rel=\"noopener\">Learning without Forgetting</a></p>\n</blockquote>\n<p>aim: useing only new task data to train the network while preserving the original capabilities<br>temperature: T=2, grid search method</p>\n<h2 id=\"density-threshold-in-local-feature-density\"><a href=\"#density-threshold-in-local-feature-density\" class=\"headerlink\" title=\"density threshold in local feature density\"></a>density threshold in local feature density</h2><h2 id=\"distribution-distance-is-transfered-into-weights\"><a href=\"#distribution-distance-is-transfered-into-weights\" class=\"headerlink\" title=\"distribution distance is transfered into weights\"></a>distribution distance is transfered into weights</h2>"},{"title":"Pseudo Purity && Dataset Distribution Distance","date":"2019-02-17T10:07:47.000Z","_content":"\n## Purity and distribution distance based density \n### Data density\n\n>reference  ECCV 2018 [ CurriculumNet: Weakly Supervised Learning from Large-Scale Web Images](http://openaccess.thecvf.com/content_ECCV_2018/papers/Sheng_Guo_CurriculumNet_Learning_from_ECCV_2018_paper.pdf)\n\n#### creativity\n1. leveraging data distribution density in feature space to evaluate the complexity of the data\n    ours -- evaluating the purity of pseudo label data by data density in feature space\n2. noisy data can be regared as regularied method to improve the model generalization\n    ours -- pesudo labels can improve the model generalization \n    \n#### technical detail\n1. density based clustering algorithm\n     * generating features\n     * calculating Euclidean distance D_ij\n       * calculating local density of each image\n       * calculating distance of each image: maximun local distance is regarded as cluster centre, image with smaller distance between its distance and cluster centre represents that its label have high confidence \n\n### Data distribution distance EMD\n> reference IJCV 2000 [The Earth Mover's Distance as a Metric for Image Retrieval](http://robotics.stanford.edu/~rubner/papers/rubnerIjcv00.pdf)\n\n#### definition\n1. EDM: Signature matching can be naturally cast as a transportation problem by de fining one signature as the supplier and the other as the consumer, and by setting the cost for a supplier-consumer pair to equal the ground distance between an element in the fi rst signature and an element in the second\n2. signature: \n\\begin{aligned}\ns= (feature,weights)\n\\end{aligned}\n\n\n\n## Purity and distribution distance based gmm\n\n### GMM with EM\n*  original definition\n\\begin{aligned}\np(x) & = \\sum_{k=1}^K p(k)p(x|k) = \\sum_{k=1}^K \\pi_k \\mathcal{N}(x|\\mu_k, \\Sigma_k)\n\\end{aligned}\n\n\\pi_k  represent the possibility of sample belong to kth category\n\n* new definition for coding\n\\begin{aligned}\n \\sum_{k} z_k = 1\n\\end{aligned}\n\n\n\n","source":"_posts/Pseudo-purity&distribution-distance.md","raw":"---\ntitle: Pseudo Purity && Dataset Distribution Distance\ndate: 2019-02-17 18:07:47\ntags: pesudo labels\ncategories: Theory\n---\n\n## Purity and distribution distance based density \n### Data density\n\n>reference  ECCV 2018 [ CurriculumNet: Weakly Supervised Learning from Large-Scale Web Images](http://openaccess.thecvf.com/content_ECCV_2018/papers/Sheng_Guo_CurriculumNet_Learning_from_ECCV_2018_paper.pdf)\n\n#### creativity\n1. leveraging data distribution density in feature space to evaluate the complexity of the data\n    ours -- evaluating the purity of pseudo label data by data density in feature space\n2. noisy data can be regared as regularied method to improve the model generalization\n    ours -- pesudo labels can improve the model generalization \n    \n#### technical detail\n1. density based clustering algorithm\n     * generating features\n     * calculating Euclidean distance D_ij\n       * calculating local density of each image\n       * calculating distance of each image: maximun local distance is regarded as cluster centre, image with smaller distance between its distance and cluster centre represents that its label have high confidence \n\n### Data distribution distance EMD\n> reference IJCV 2000 [The Earth Mover's Distance as a Metric for Image Retrieval](http://robotics.stanford.edu/~rubner/papers/rubnerIjcv00.pdf)\n\n#### definition\n1. EDM: Signature matching can be naturally cast as a transportation problem by de fining one signature as the supplier and the other as the consumer, and by setting the cost for a supplier-consumer pair to equal the ground distance between an element in the fi rst signature and an element in the second\n2. signature: \n\\begin{aligned}\ns= (feature,weights)\n\\end{aligned}\n\n\n\n## Purity and distribution distance based gmm\n\n### GMM with EM\n*  original definition\n\\begin{aligned}\np(x) & = \\sum_{k=1}^K p(k)p(x|k) = \\sum_{k=1}^K \\pi_k \\mathcal{N}(x|\\mu_k, \\Sigma_k)\n\\end{aligned}\n\n\\pi_k  represent the possibility of sample belong to kth category\n\n* new definition for coding\n\\begin{aligned}\n \\sum_{k} z_k = 1\n\\end{aligned}\n\n\n\n","slug":"Pseudo-purity&distribution-distance","published":1,"updated":"2019-04-08T06:20:55.948Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cju7zelmw000uqrm76vqy8y6j","content":"<h2 id=\"Purity-and-distribution-distance-based-density\"><a href=\"#Purity-and-distribution-distance-based-density\" class=\"headerlink\" title=\"Purity and distribution distance based density\"></a>Purity and distribution distance based density</h2><h3 id=\"Data-density\"><a href=\"#Data-density\" class=\"headerlink\" title=\"Data density\"></a>Data density</h3><blockquote>\n<p>reference  ECCV 2018 <a href=\"http://openaccess.thecvf.com/content_ECCV_2018/papers/Sheng_Guo_CurriculumNet_Learning_from_ECCV_2018_paper.pdf\" target=\"_blank\" rel=\"noopener\"> CurriculumNet: Weakly Supervised Learning from Large-Scale Web Images</a></p>\n</blockquote>\n<h4 id=\"creativity\"><a href=\"#creativity\" class=\"headerlink\" title=\"creativity\"></a>creativity</h4><ol>\n<li>leveraging data distribution density in feature space to evaluate the complexity of the data<br> ours — evaluating the purity of pseudo label data by data density in feature space</li>\n<li>noisy data can be regared as regularied method to improve the model generalization<br> ours — pesudo labels can improve the model generalization </li>\n</ol>\n<h4 id=\"technical-detail\"><a href=\"#technical-detail\" class=\"headerlink\" title=\"technical detail\"></a>technical detail</h4><ol>\n<li>density based clustering algorithm<ul>\n<li>generating features</li>\n<li>calculating Euclidean distance D_ij<ul>\n<li>calculating local density of each image</li>\n<li>calculating distance of each image: maximun local distance is regarded as cluster centre, image with smaller distance between its distance and cluster centre represents that its label have high confidence </li>\n</ul>\n</li>\n</ul>\n</li>\n</ol>\n<h3 id=\"Data-distribution-distance-EMD\"><a href=\"#Data-distribution-distance-EMD\" class=\"headerlink\" title=\"Data distribution distance EMD\"></a>Data distribution distance EMD</h3><blockquote>\n<p>reference IJCV 2000 <a href=\"http://robotics.stanford.edu/~rubner/papers/rubnerIjcv00.pdf\" target=\"_blank\" rel=\"noopener\">The Earth Mover’s Distance as a Metric for Image Retrieval</a></p>\n</blockquote>\n<h4 id=\"definition\"><a href=\"#definition\" class=\"headerlink\" title=\"definition\"></a>definition</h4><ol>\n<li>EDM: Signature matching can be naturally cast as a transportation problem by de fining one signature as the supplier and the other as the consumer, and by setting the cost for a supplier-consumer pair to equal the ground distance between an element in the fi rst signature and an element in the second</li>\n<li>signature:<br>\\begin{aligned}<br>s= (feature,weights)<br>\\end{aligned}</li>\n</ol>\n<h2 id=\"Purity-and-distribution-distance-based-gmm\"><a href=\"#Purity-and-distribution-distance-based-gmm\" class=\"headerlink\" title=\"Purity and distribution distance based gmm\"></a>Purity and distribution distance based gmm</h2><h3 id=\"GMM-with-EM\"><a href=\"#GMM-with-EM\" class=\"headerlink\" title=\"GMM with EM\"></a>GMM with EM</h3><ul>\n<li>original definition<br>\\begin{aligned}<br>p(x) &amp; = \\sum<em>{k=1}^K p(k)p(x|k) = \\sum</em>{k=1}^K \\pi_k \\mathcal{N}(x|\\mu_k, \\Sigma_k)<br>\\end{aligned}</li>\n</ul>\n<p>\\pi_k  represent the possibility of sample belong to kth category</p>\n<ul>\n<li>new definition for coding<br>\\begin{aligned}<br>\\sum_{k} z_k = 1<br>\\end{aligned}</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"Purity-and-distribution-distance-based-density\"><a href=\"#Purity-and-distribution-distance-based-density\" class=\"headerlink\" title=\"Purity and distribution distance based density\"></a>Purity and distribution distance based density</h2><h3 id=\"Data-density\"><a href=\"#Data-density\" class=\"headerlink\" title=\"Data density\"></a>Data density</h3><blockquote>\n<p>reference  ECCV 2018 <a href=\"http://openaccess.thecvf.com/content_ECCV_2018/papers/Sheng_Guo_CurriculumNet_Learning_from_ECCV_2018_paper.pdf\" target=\"_blank\" rel=\"noopener\"> CurriculumNet: Weakly Supervised Learning from Large-Scale Web Images</a></p>\n</blockquote>\n<h4 id=\"creativity\"><a href=\"#creativity\" class=\"headerlink\" title=\"creativity\"></a>creativity</h4><ol>\n<li>leveraging data distribution density in feature space to evaluate the complexity of the data<br> ours — evaluating the purity of pseudo label data by data density in feature space</li>\n<li>noisy data can be regared as regularied method to improve the model generalization<br> ours — pesudo labels can improve the model generalization </li>\n</ol>\n<h4 id=\"technical-detail\"><a href=\"#technical-detail\" class=\"headerlink\" title=\"technical detail\"></a>technical detail</h4><ol>\n<li>density based clustering algorithm<ul>\n<li>generating features</li>\n<li>calculating Euclidean distance D_ij<ul>\n<li>calculating local density of each image</li>\n<li>calculating distance of each image: maximun local distance is regarded as cluster centre, image with smaller distance between its distance and cluster centre represents that its label have high confidence </li>\n</ul>\n</li>\n</ul>\n</li>\n</ol>\n<h3 id=\"Data-distribution-distance-EMD\"><a href=\"#Data-distribution-distance-EMD\" class=\"headerlink\" title=\"Data distribution distance EMD\"></a>Data distribution distance EMD</h3><blockquote>\n<p>reference IJCV 2000 <a href=\"http://robotics.stanford.edu/~rubner/papers/rubnerIjcv00.pdf\" target=\"_blank\" rel=\"noopener\">The Earth Mover’s Distance as a Metric for Image Retrieval</a></p>\n</blockquote>\n<h4 id=\"definition\"><a href=\"#definition\" class=\"headerlink\" title=\"definition\"></a>definition</h4><ol>\n<li>EDM: Signature matching can be naturally cast as a transportation problem by de fining one signature as the supplier and the other as the consumer, and by setting the cost for a supplier-consumer pair to equal the ground distance between an element in the fi rst signature and an element in the second</li>\n<li>signature:<br>\\begin{aligned}<br>s= (feature,weights)<br>\\end{aligned}</li>\n</ol>\n<h2 id=\"Purity-and-distribution-distance-based-gmm\"><a href=\"#Purity-and-distribution-distance-based-gmm\" class=\"headerlink\" title=\"Purity and distribution distance based gmm\"></a>Purity and distribution distance based gmm</h2><h3 id=\"GMM-with-EM\"><a href=\"#GMM-with-EM\" class=\"headerlink\" title=\"GMM with EM\"></a>GMM with EM</h3><ul>\n<li>original definition<br>\\begin{aligned}<br>p(x) &amp; = \\sum<em>{k=1}^K p(k)p(x|k) = \\sum</em>{k=1}^K \\pi_k \\mathcal{N}(x|\\mu_k, \\Sigma_k)<br>\\end{aligned}</li>\n</ul>\n<p>\\pi_k  represent the possibility of sample belong to kth category</p>\n<ul>\n<li>new definition for coding<br>\\begin{aligned}<br>\\sum_{k} z_k = 1<br>\\end{aligned}</li>\n</ul>\n"},{"title":"Research-Point-Multitask","date":"2019-02-28T03:25:45.000Z","_content":"\n## Several tips for heterogeneous multitask learning\n* core problem - heterogeneity structrues in tasks[age and gender], source[documents and images], feature[generated from model for classification or regression tasks], samples[one labeled with age while another annotated with gender]\n\n1. network with suitabel initialization and learning rate\n2. construct feature relationship in network, offering trainable parameters, refer to [cross-stitch network]\n3. feature selection, sparsity and factorization, which means that the specific branch layers to ontain task-specific fearures in a common feature space.\n\n## Research directions\n* feature relationship from the level of network.\n* feature processing from the level fo feature space, such as selection, sparsity and facorization.","source":"_posts/Research-Point-Multitask.md","raw":"---\ntitle: Research-Point-Multitask\ndate: 2019-02-28 11:25:45\ntags: multitask\ncategories: Deep learning\n---\n\n## Several tips for heterogeneous multitask learning\n* core problem - heterogeneity structrues in tasks[age and gender], source[documents and images], feature[generated from model for classification or regression tasks], samples[one labeled with age while another annotated with gender]\n\n1. network with suitabel initialization and learning rate\n2. construct feature relationship in network, offering trainable parameters, refer to [cross-stitch network]\n3. feature selection, sparsity and factorization, which means that the specific branch layers to ontain task-specific fearures in a common feature space.\n\n## Research directions\n* feature relationship from the level of network.\n* feature processing from the level fo feature space, such as selection, sparsity and facorization.","slug":"Research-Point-Multitask","published":1,"updated":"2019-04-08T06:20:55.948Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cju7zelmx000xqrm760jskuah","content":"<h2 id=\"Several-tips-for-heterogeneous-multitask-learning\"><a href=\"#Several-tips-for-heterogeneous-multitask-learning\" class=\"headerlink\" title=\"Several tips for heterogeneous multitask learning\"></a>Several tips for heterogeneous multitask learning</h2><ul>\n<li>core problem - heterogeneity structrues in tasks[age and gender], source[documents and images], feature[generated from model for classification or regression tasks], samples[one labeled with age while another annotated with gender]</li>\n</ul>\n<ol>\n<li>network with suitabel initialization and learning rate</li>\n<li>construct feature relationship in network, offering trainable parameters, refer to [cross-stitch network]</li>\n<li>feature selection, sparsity and factorization, which means that the specific branch layers to ontain task-specific fearures in a common feature space.</li>\n</ol>\n<h2 id=\"Research-directions\"><a href=\"#Research-directions\" class=\"headerlink\" title=\"Research directions\"></a>Research directions</h2><ul>\n<li>feature relationship from the level of network.</li>\n<li>feature processing from the level fo feature space, such as selection, sparsity and facorization.</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"Several-tips-for-heterogeneous-multitask-learning\"><a href=\"#Several-tips-for-heterogeneous-multitask-learning\" class=\"headerlink\" title=\"Several tips for heterogeneous multitask learning\"></a>Several tips for heterogeneous multitask learning</h2><ul>\n<li>core problem - heterogeneity structrues in tasks[age and gender], source[documents and images], feature[generated from model for classification or regression tasks], samples[one labeled with age while another annotated with gender]</li>\n</ul>\n<ol>\n<li>network with suitabel initialization and learning rate</li>\n<li>construct feature relationship in network, offering trainable parameters, refer to [cross-stitch network]</li>\n<li>feature selection, sparsity and factorization, which means that the specific branch layers to ontain task-specific fearures in a common feature space.</li>\n</ol>\n<h2 id=\"Research-directions\"><a href=\"#Research-directions\" class=\"headerlink\" title=\"Research directions\"></a>Research directions</h2><ul>\n<li>feature relationship from the level of network.</li>\n<li>feature processing from the level fo feature space, such as selection, sparsity and facorization.</li>\n</ul>\n"},{"title":"Semi-Heteroneous-Multitask-Baseline","date":"2019-02-28T07:23:11.000Z","_content":"\n## high-related\n\n>reference [Learning without Forgetting](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8107520)\n* distilled knowledge\n\n\n\n>reference [An All-In-One Convolutional Neural Network for Face Analysis](https://arxiv.org/pdf/1611.00851.pdf)\n* naive joint\n\n\n>reference [From Facial Expression Recognition to Interpersonal Relation Prediction\nZhanpeng](https://arxiv.org/pdf/1609.06426.pdf)\n* pseudo label\n\n\n\n>reference NLP [Multi-task Learning of Pairwise Sequence Classification Tasks Over Disparate Label Spaces](https://arxiv.org/pdf/1802.09913.pdf)\n'we should be able to not only model their relationship, but also to directly estimate the corresponding label of the target task based on auxiliary predictions.'\n* probelm: jointly using unlabelled data and auxiliary, annotated datasets; domain gap; missing labels\n* method: training the Label Transfer Network, minimise the squared error between the model predictions and the pseudo label\n* baseline: yes (how to calculate loss funtion [squared error] based on pseudo label)\n\n\n>reference [Seeing through the Human Reporting Bias: Visual Classifiers from Noisy Human-Centric Labels Ishan](https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Misra_Seeing_Through_the_CVPR_2016_paper.pdf)\n* confidence score\n* same apply scene\n* refer to paper writting\n\n\n\n>reference non-DL [Semi-supervised Feature Analysis by Mining Correlations among Multiple Tasks](http://de.arxiv.org/pdf/1411.6232)\n* problem: 'Since the objective function is non-smooth and difficult to solve, we propose an iterative algorithm with fast convergence.' 'These previous works, however, independently select features for each task, which fails to consider correlations among multiple related tasks.' 'Despite of their good performances, these classical algorithms are all implemented only with labeled training data.'\n* method: 'ignoring the correlations among different features ->apply the sparse coefficients to the feature vectors -> proposing multiple feature selection'\n* baseline: undetermined (hard to complete)\n\n\n> [Pseudo-task Augmentation: From Deep Multitask Learning to Intratask Sharing—and Back](https://arxiv.org/pdf/1803.04062.pdf)\n* related work conclude papers of joint training of models for multiple tasks.\n  * 'how learned structure is shared across tasks':\n     1. supervise different tasks at different depths of the shared structure []()\n     2. duplicate the shared structure into columns and define mechanisms for sharing information across columns [Multitask Learning with Low-Level Auxiliary Tasks for Encoder-Decoder Based Speech Recognition\n](https://arxiv.org/pdf/1704.01631.pdf), using intermediate representations as auxiliary supervision for low-level task recognition to improve final task performance.\n* baseline: no( pose-emotion both are high-level task, not similar to keypoint detection)\n\n\n\n\n\n## pseudo method related\n >reference CVPR 2018[Pseudo Mask Augmented Object Detection](http://openaccess.thecvf.com/content_cvpr_2018/papers/Zhao_Pseudo_Mask_Augmented_CVPR_2018_paper.pdf)\n 'proposing an effective learning approach that progressively improves the quality pseudo from a coarse initialization,the detection network parameters Θ and pseudo masks Mpseudo are alternatively optimized following a EM-like way'\n * probelm: object detection without mask annotation\n * method: pseudo mask (alternatively,initialization,pseudo mask with refinement algorithm[graphical model, because the pixel charaterization])\n * baseline: yes(uing graphical model with learned information as input to refine pseudo label)\n\n>reference [Learning from Noisy Labels with Distillation](https://arxiv.org/pdf/1703.02391.pdf)\n* interpolation between noisy label and distilled knowledge\n* baseline: yes\n\n >reference [Clustered Multi-Task Learning Via Alternating Structure Optimization\n](http://papers.nips.cc/paper/4292-clustered-multi-task-learning-via-alternating-structure-optimization.pdf)\n* 'ASO which aims to identify a shared low-dimensional predictive structure for all tasks','based on the standard assump- tion that each task can learn equally well from any other task','the clustering view of ASO has not been explored before'\n* hard to understand, pure theories.\n\n","source":"_posts/Semi-Heteroneous-Multitask-Baseline.md","raw":"---\ntitle: Semi-Heteroneous-Multitask-Baseline\ndate: 2019-02-28 15:23:11\ntags: multitask\ncategories: Deep learning\n---\n\n## high-related\n\n>reference [Learning without Forgetting](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8107520)\n* distilled knowledge\n\n\n\n>reference [An All-In-One Convolutional Neural Network for Face Analysis](https://arxiv.org/pdf/1611.00851.pdf)\n* naive joint\n\n\n>reference [From Facial Expression Recognition to Interpersonal Relation Prediction\nZhanpeng](https://arxiv.org/pdf/1609.06426.pdf)\n* pseudo label\n\n\n\n>reference NLP [Multi-task Learning of Pairwise Sequence Classification Tasks Over Disparate Label Spaces](https://arxiv.org/pdf/1802.09913.pdf)\n'we should be able to not only model their relationship, but also to directly estimate the corresponding label of the target task based on auxiliary predictions.'\n* probelm: jointly using unlabelled data and auxiliary, annotated datasets; domain gap; missing labels\n* method: training the Label Transfer Network, minimise the squared error between the model predictions and the pseudo label\n* baseline: yes (how to calculate loss funtion [squared error] based on pseudo label)\n\n\n>reference [Seeing through the Human Reporting Bias: Visual Classifiers from Noisy Human-Centric Labels Ishan](https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Misra_Seeing_Through_the_CVPR_2016_paper.pdf)\n* confidence score\n* same apply scene\n* refer to paper writting\n\n\n\n>reference non-DL [Semi-supervised Feature Analysis by Mining Correlations among Multiple Tasks](http://de.arxiv.org/pdf/1411.6232)\n* problem: 'Since the objective function is non-smooth and difficult to solve, we propose an iterative algorithm with fast convergence.' 'These previous works, however, independently select features for each task, which fails to consider correlations among multiple related tasks.' 'Despite of their good performances, these classical algorithms are all implemented only with labeled training data.'\n* method: 'ignoring the correlations among different features ->apply the sparse coefficients to the feature vectors -> proposing multiple feature selection'\n* baseline: undetermined (hard to complete)\n\n\n> [Pseudo-task Augmentation: From Deep Multitask Learning to Intratask Sharing—and Back](https://arxiv.org/pdf/1803.04062.pdf)\n* related work conclude papers of joint training of models for multiple tasks.\n  * 'how learned structure is shared across tasks':\n     1. supervise different tasks at different depths of the shared structure []()\n     2. duplicate the shared structure into columns and define mechanisms for sharing information across columns [Multitask Learning with Low-Level Auxiliary Tasks for Encoder-Decoder Based Speech Recognition\n](https://arxiv.org/pdf/1704.01631.pdf), using intermediate representations as auxiliary supervision for low-level task recognition to improve final task performance.\n* baseline: no( pose-emotion both are high-level task, not similar to keypoint detection)\n\n\n\n\n\n## pseudo method related\n >reference CVPR 2018[Pseudo Mask Augmented Object Detection](http://openaccess.thecvf.com/content_cvpr_2018/papers/Zhao_Pseudo_Mask_Augmented_CVPR_2018_paper.pdf)\n 'proposing an effective learning approach that progressively improves the quality pseudo from a coarse initialization,the detection network parameters Θ and pseudo masks Mpseudo are alternatively optimized following a EM-like way'\n * probelm: object detection without mask annotation\n * method: pseudo mask (alternatively,initialization,pseudo mask with refinement algorithm[graphical model, because the pixel charaterization])\n * baseline: yes(uing graphical model with learned information as input to refine pseudo label)\n\n>reference [Learning from Noisy Labels with Distillation](https://arxiv.org/pdf/1703.02391.pdf)\n* interpolation between noisy label and distilled knowledge\n* baseline: yes\n\n >reference [Clustered Multi-Task Learning Via Alternating Structure Optimization\n](http://papers.nips.cc/paper/4292-clustered-multi-task-learning-via-alternating-structure-optimization.pdf)\n* 'ASO which aims to identify a shared low-dimensional predictive structure for all tasks','based on the standard assump- tion that each task can learn equally well from any other task','the clustering view of ASO has not been explored before'\n* hard to understand, pure theories.\n\n","slug":"Semi-Heteroneous-Multitask-Baseline","published":1,"updated":"2019-04-08T06:20:55.948Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cju7zelmy0012qrm7lplt4zmq","content":"<h2 id=\"high-related\"><a href=\"#high-related\" class=\"headerlink\" title=\"high-related\"></a>high-related</h2><blockquote>\n<p>reference <a href=\"https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=8107520\" target=\"_blank\" rel=\"noopener\">Learning without Forgetting</a></p>\n<ul>\n<li>distilled knowledge</li>\n</ul>\n<p>reference <a href=\"https://arxiv.org/pdf/1611.00851.pdf\" target=\"_blank\" rel=\"noopener\">An All-In-One Convolutional Neural Network for Face Analysis</a></p>\n<ul>\n<li>naive joint</li>\n</ul>\n<p>reference <a href=\"https://arxiv.org/pdf/1609.06426.pdf\" target=\"_blank\" rel=\"noopener\">From Facial Expression Recognition to Interpersonal Relation Prediction<br>Zhanpeng</a></p>\n<ul>\n<li>pseudo label</li>\n</ul>\n<p>reference NLP <a href=\"https://arxiv.org/pdf/1802.09913.pdf\" target=\"_blank\" rel=\"noopener\">Multi-task Learning of Pairwise Sequence Classification Tasks Over Disparate Label Spaces</a><br>‘we should be able to not only model their relationship, but also to directly estimate the corresponding label of the target task based on auxiliary predictions.’</p>\n<ul>\n<li>probelm: jointly using unlabelled data and auxiliary, annotated datasets; domain gap; missing labels</li>\n<li>method: training the Label Transfer Network, minimise the squared error between the model predictions and the pseudo label</li>\n<li>baseline: yes (how to calculate loss funtion [squared error] based on pseudo label)</li>\n</ul>\n<p>reference <a href=\"https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Misra_Seeing_Through_the_CVPR_2016_paper.pdf\" target=\"_blank\" rel=\"noopener\">Seeing through the Human Reporting Bias: Visual Classifiers from Noisy Human-Centric Labels Ishan</a></p>\n<ul>\n<li>confidence score</li>\n<li>same apply scene</li>\n<li>refer to paper writting</li>\n</ul>\n<p>reference non-DL <a href=\"http://de.arxiv.org/pdf/1411.6232\" target=\"_blank\" rel=\"noopener\">Semi-supervised Feature Analysis by Mining Correlations among Multiple Tasks</a></p>\n<ul>\n<li>problem: ‘Since the objective function is non-smooth and difficult to solve, we propose an iterative algorithm with fast convergence.’ ‘These previous works, however, independently select features for each task, which fails to consider correlations among multiple related tasks.’ ‘Despite of their good performances, these classical algorithms are all implemented only with labeled training data.’</li>\n<li>method: ‘ignoring the correlations among different features -&gt;apply the sparse coefficients to the feature vectors -&gt; proposing multiple feature selection’</li>\n<li>baseline: undetermined (hard to complete)</li>\n</ul>\n<p><a href=\"https://arxiv.org/pdf/1803.04062.pdf\" target=\"_blank\" rel=\"noopener\">Pseudo-task Augmentation: From Deep Multitask Learning to Intratask Sharing—and Back</a></p>\n<ul>\n<li>related work conclude papers of joint training of models for multiple tasks.<ul>\n<li>‘how learned structure is shared across tasks’:<ol>\n<li>supervise different tasks at different depths of the shared structure <a href=\"\"></a></li>\n<li>duplicate the shared structure into columns and define mechanisms for sharing information across columns <a href=\"https://arxiv.org/pdf/1704.01631.pdf\" target=\"_blank\" rel=\"noopener\">Multitask Learning with Low-Level Auxiliary Tasks for Encoder-Decoder Based Speech Recognition\n</a>, using intermediate representations as auxiliary supervision for low-level task recognition to improve final task performance.</li>\n</ol>\n</li>\n</ul>\n</li>\n<li>baseline: no( pose-emotion both are high-level task, not similar to keypoint detection)</li>\n</ul>\n</blockquote>\n<h2 id=\"pseudo-method-related\"><a href=\"#pseudo-method-related\" class=\"headerlink\" title=\"pseudo method related\"></a>pseudo method related</h2><blockquote>\n<p>reference CVPR 2018<a href=\"http://openaccess.thecvf.com/content_cvpr_2018/papers/Zhao_Pseudo_Mask_Augmented_CVPR_2018_paper.pdf\" target=\"_blank\" rel=\"noopener\">Pseudo Mask Augmented Object Detection</a><br> ‘proposing an effective learning approach that progressively improves the quality pseudo from a coarse initialization,the detection network parameters Θ and pseudo masks Mpseudo are alternatively optimized following a EM-like way’</p>\n<ul>\n<li>probelm: object detection without mask annotation</li>\n<li>method: pseudo mask (alternatively,initialization,pseudo mask with refinement algorithm[graphical model, because the pixel charaterization])</li>\n<li>baseline: yes(uing graphical model with learned information as input to refine pseudo label)</li>\n</ul>\n<p>reference <a href=\"https://arxiv.org/pdf/1703.02391.pdf\" target=\"_blank\" rel=\"noopener\">Learning from Noisy Labels with Distillation</a></p>\n<ul>\n<li>interpolation between noisy label and distilled knowledge</li>\n<li>baseline: yes</li>\n</ul>\n<p>reference <a href=\"http://papers.nips.cc/paper/4292-clustered-multi-task-learning-via-alternating-structure-optimization.pdf\" target=\"_blank\" rel=\"noopener\">Clustered Multi-Task Learning Via Alternating Structure Optimization\n</a></p>\n<ul>\n<li>‘ASO which aims to identify a shared low-dimensional predictive structure for all tasks’,’based on the standard assump- tion that each task can learn equally well from any other task’,’the clustering view of ASO has not been explored before’</li>\n<li>hard to understand, pure theories.</li>\n</ul>\n</blockquote>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"high-related\"><a href=\"#high-related\" class=\"headerlink\" title=\"high-related\"></a>high-related</h2><blockquote>\n<p>reference <a href=\"https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=8107520\" target=\"_blank\" rel=\"noopener\">Learning without Forgetting</a></p>\n<ul>\n<li>distilled knowledge</li>\n</ul>\n<p>reference <a href=\"https://arxiv.org/pdf/1611.00851.pdf\" target=\"_blank\" rel=\"noopener\">An All-In-One Convolutional Neural Network for Face Analysis</a></p>\n<ul>\n<li>naive joint</li>\n</ul>\n<p>reference <a href=\"https://arxiv.org/pdf/1609.06426.pdf\" target=\"_blank\" rel=\"noopener\">From Facial Expression Recognition to Interpersonal Relation Prediction<br>Zhanpeng</a></p>\n<ul>\n<li>pseudo label</li>\n</ul>\n<p>reference NLP <a href=\"https://arxiv.org/pdf/1802.09913.pdf\" target=\"_blank\" rel=\"noopener\">Multi-task Learning of Pairwise Sequence Classification Tasks Over Disparate Label Spaces</a><br>‘we should be able to not only model their relationship, but also to directly estimate the corresponding label of the target task based on auxiliary predictions.’</p>\n<ul>\n<li>probelm: jointly using unlabelled data and auxiliary, annotated datasets; domain gap; missing labels</li>\n<li>method: training the Label Transfer Network, minimise the squared error between the model predictions and the pseudo label</li>\n<li>baseline: yes (how to calculate loss funtion [squared error] based on pseudo label)</li>\n</ul>\n<p>reference <a href=\"https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Misra_Seeing_Through_the_CVPR_2016_paper.pdf\" target=\"_blank\" rel=\"noopener\">Seeing through the Human Reporting Bias: Visual Classifiers from Noisy Human-Centric Labels Ishan</a></p>\n<ul>\n<li>confidence score</li>\n<li>same apply scene</li>\n<li>refer to paper writting</li>\n</ul>\n<p>reference non-DL <a href=\"http://de.arxiv.org/pdf/1411.6232\" target=\"_blank\" rel=\"noopener\">Semi-supervised Feature Analysis by Mining Correlations among Multiple Tasks</a></p>\n<ul>\n<li>problem: ‘Since the objective function is non-smooth and difficult to solve, we propose an iterative algorithm with fast convergence.’ ‘These previous works, however, independently select features for each task, which fails to consider correlations among multiple related tasks.’ ‘Despite of their good performances, these classical algorithms are all implemented only with labeled training data.’</li>\n<li>method: ‘ignoring the correlations among different features -&gt;apply the sparse coefficients to the feature vectors -&gt; proposing multiple feature selection’</li>\n<li>baseline: undetermined (hard to complete)</li>\n</ul>\n<p><a href=\"https://arxiv.org/pdf/1803.04062.pdf\" target=\"_blank\" rel=\"noopener\">Pseudo-task Augmentation: From Deep Multitask Learning to Intratask Sharing—and Back</a></p>\n<ul>\n<li>related work conclude papers of joint training of models for multiple tasks.<ul>\n<li>‘how learned structure is shared across tasks’:<ol>\n<li>supervise different tasks at different depths of the shared structure <a href=\"\"></a></li>\n<li>duplicate the shared structure into columns and define mechanisms for sharing information across columns <a href=\"https://arxiv.org/pdf/1704.01631.pdf\" target=\"_blank\" rel=\"noopener\">Multitask Learning with Low-Level Auxiliary Tasks for Encoder-Decoder Based Speech Recognition\n</a>, using intermediate representations as auxiliary supervision for low-level task recognition to improve final task performance.</li>\n</ol>\n</li>\n</ul>\n</li>\n<li>baseline: no( pose-emotion both are high-level task, not similar to keypoint detection)</li>\n</ul>\n</blockquote>\n<h2 id=\"pseudo-method-related\"><a href=\"#pseudo-method-related\" class=\"headerlink\" title=\"pseudo method related\"></a>pseudo method related</h2><blockquote>\n<p>reference CVPR 2018<a href=\"http://openaccess.thecvf.com/content_cvpr_2018/papers/Zhao_Pseudo_Mask_Augmented_CVPR_2018_paper.pdf\" target=\"_blank\" rel=\"noopener\">Pseudo Mask Augmented Object Detection</a><br> ‘proposing an effective learning approach that progressively improves the quality pseudo from a coarse initialization,the detection network parameters Θ and pseudo masks Mpseudo are alternatively optimized following a EM-like way’</p>\n<ul>\n<li>probelm: object detection without mask annotation</li>\n<li>method: pseudo mask (alternatively,initialization,pseudo mask with refinement algorithm[graphical model, because the pixel charaterization])</li>\n<li>baseline: yes(uing graphical model with learned information as input to refine pseudo label)</li>\n</ul>\n<p>reference <a href=\"https://arxiv.org/pdf/1703.02391.pdf\" target=\"_blank\" rel=\"noopener\">Learning from Noisy Labels with Distillation</a></p>\n<ul>\n<li>interpolation between noisy label and distilled knowledge</li>\n<li>baseline: yes</li>\n</ul>\n<p>reference <a href=\"http://papers.nips.cc/paper/4292-clustered-multi-task-learning-via-alternating-structure-optimization.pdf\" target=\"_blank\" rel=\"noopener\">Clustered Multi-Task Learning Via Alternating Structure Optimization\n</a></p>\n<ul>\n<li>‘ASO which aims to identify a shared low-dimensional predictive structure for all tasks’,’based on the standard assump- tion that each task can learn equally well from any other task’,’the clustering view of ASO has not been explored before’</li>\n<li>hard to understand, pure theories.</li>\n</ul>\n</blockquote>\n"},{"title":"Semi-MTL Related","date":"2019-03-09T06:59:07.000Z","_content":"\n## MTL\n\n### Learning Methods\n* Supervised\n* Semi-supervised\n\n### Scenarios\n* Homogeneous\n* Heterogeneous\n  * Heterogeneous Tasks (Document & Images & Audio)\n  * Hterogeneous Datsets (Each dataset with a set of labels)\n\n### Improvement Ideas\n* Network Structure\n* Feature Selection\n\n### Application\n* CV\n* NLP\n\n\nALL MTL is the combination of above mentioned.\nOur method is semi-supervised MTL with heterogeneous datasets, comparison including supervised or semi-supervised MTL with heterogeneous dataset.\n\n\n\n>reference [Semi-supervised Feature Analysis by Mining Correlations among Multiple Tasks](https://arxiv.org/pdf/1411.6232.pdf)\n\n* semi-supervised, heterogeneou datasets, feature selection.\n* scenario: CV, dataset A for tasks A[labeled and unlabeled], dataset B for tasks B[labeled and unlabeled]\n* method: manifold learning, mining feature correlation by sparse coefficients.\n* No\n\n> reference [Deep Cross Residual Learning for Multitask Visual Recognition](https://arxiv.org/pdf/1604.01335.pdf)\n\n* supervised, heterogeneou datasets, network structure.\n* scenario: CV, dataset A for tasks A[labeled], dataset B for tasks B[labeled]\n* method: enables intuitive learning across multiple related tasks using cross-connections called cross-residuals\n* Yes? Netowrk realization?\n\n\n\n> reference [A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data](http://www.jmlr.org/papers/volume6/ando05a/ando05a.pdf)\n\n* semi-supervised, heterogeneou datasets, network structure.\n* scenario: \n* method: \n* No\n\n>reference [Multi-task Learning of Pairwise Sequence Classification Tasks Over Disparate Label Spaces](https://arxiv.org/pdf/1802.09913.pdf)\n\n* supervised, heterogeneou datasets, network structure.\n* scenario: text classification, dataset A for tasks A[labeled], dataset B for tasks B[labeled]\n* method: combining multi-task learning and semi- supervised learning by inducing a joint embed- ding space between disparate label spaces and learning transfer functions between label embeddings. LTN can be used to label unlabelled and auxiliary task data by utilising the ‘distilling knowledge’ contained in auxiliary model predictions. not only model their relationship, but also to directly estimate the cor- responding label of the target task based on auxil- iary predictions\n* Yes: embedding, prediction, output, temperature=1, embedding can be realized with cross-stich network\n\n\n\n>reference [Neural Network for Heterogeneous Annotations](http://www.aclweb.org/anthology/D16-1070)\n\n* supervised, heterogeneou datasets, multi-view & stacking setting\n* scenario: NLP, dataset A for tasks A[labeled], dataset B for tasks B[labeled]\n* method: multi-view, stacking, neurual network\n* Yes: not understand\n\n\n\n","source":"_posts/Semi-MTL-Related.md","raw":"---\ntitle: Semi-MTL Related\ndate: 2019-03-09 14:59:07\ntags: multitask\ncategories: Deep learning\n---\n\n## MTL\n\n### Learning Methods\n* Supervised\n* Semi-supervised\n\n### Scenarios\n* Homogeneous\n* Heterogeneous\n  * Heterogeneous Tasks (Document & Images & Audio)\n  * Hterogeneous Datsets (Each dataset with a set of labels)\n\n### Improvement Ideas\n* Network Structure\n* Feature Selection\n\n### Application\n* CV\n* NLP\n\n\nALL MTL is the combination of above mentioned.\nOur method is semi-supervised MTL with heterogeneous datasets, comparison including supervised or semi-supervised MTL with heterogeneous dataset.\n\n\n\n>reference [Semi-supervised Feature Analysis by Mining Correlations among Multiple Tasks](https://arxiv.org/pdf/1411.6232.pdf)\n\n* semi-supervised, heterogeneou datasets, feature selection.\n* scenario: CV, dataset A for tasks A[labeled and unlabeled], dataset B for tasks B[labeled and unlabeled]\n* method: manifold learning, mining feature correlation by sparse coefficients.\n* No\n\n> reference [Deep Cross Residual Learning for Multitask Visual Recognition](https://arxiv.org/pdf/1604.01335.pdf)\n\n* supervised, heterogeneou datasets, network structure.\n* scenario: CV, dataset A for tasks A[labeled], dataset B for tasks B[labeled]\n* method: enables intuitive learning across multiple related tasks using cross-connections called cross-residuals\n* Yes? Netowrk realization?\n\n\n\n> reference [A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data](http://www.jmlr.org/papers/volume6/ando05a/ando05a.pdf)\n\n* semi-supervised, heterogeneou datasets, network structure.\n* scenario: \n* method: \n* No\n\n>reference [Multi-task Learning of Pairwise Sequence Classification Tasks Over Disparate Label Spaces](https://arxiv.org/pdf/1802.09913.pdf)\n\n* supervised, heterogeneou datasets, network structure.\n* scenario: text classification, dataset A for tasks A[labeled], dataset B for tasks B[labeled]\n* method: combining multi-task learning and semi- supervised learning by inducing a joint embed- ding space between disparate label spaces and learning transfer functions between label embeddings. LTN can be used to label unlabelled and auxiliary task data by utilising the ‘distilling knowledge’ contained in auxiliary model predictions. not only model their relationship, but also to directly estimate the cor- responding label of the target task based on auxil- iary predictions\n* Yes: embedding, prediction, output, temperature=1, embedding can be realized with cross-stich network\n\n\n\n>reference [Neural Network for Heterogeneous Annotations](http://www.aclweb.org/anthology/D16-1070)\n\n* supervised, heterogeneou datasets, multi-view & stacking setting\n* scenario: NLP, dataset A for tasks A[labeled], dataset B for tasks B[labeled]\n* method: multi-view, stacking, neurual network\n* Yes: not understand\n\n\n\n","slug":"Semi-MTL-Related","published":1,"updated":"2019-04-08T06:20:55.948Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cju7zelmz0015qrm7ufrqth9q","content":"<h2 id=\"MTL\"><a href=\"#MTL\" class=\"headerlink\" title=\"MTL\"></a>MTL</h2><h3 id=\"Learning-Methods\"><a href=\"#Learning-Methods\" class=\"headerlink\" title=\"Learning Methods\"></a>Learning Methods</h3><ul>\n<li>Supervised</li>\n<li>Semi-supervised</li>\n</ul>\n<h3 id=\"Scenarios\"><a href=\"#Scenarios\" class=\"headerlink\" title=\"Scenarios\"></a>Scenarios</h3><ul>\n<li>Homogeneous</li>\n<li>Heterogeneous<ul>\n<li>Heterogeneous Tasks (Document &amp; Images &amp; Audio)</li>\n<li>Hterogeneous Datsets (Each dataset with a set of labels)</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"Improvement-Ideas\"><a href=\"#Improvement-Ideas\" class=\"headerlink\" title=\"Improvement Ideas\"></a>Improvement Ideas</h3><ul>\n<li>Network Structure</li>\n<li>Feature Selection</li>\n</ul>\n<h3 id=\"Application\"><a href=\"#Application\" class=\"headerlink\" title=\"Application\"></a>Application</h3><ul>\n<li>CV</li>\n<li>NLP</li>\n</ul>\n<p>ALL MTL is the combination of above mentioned.<br>Our method is semi-supervised MTL with heterogeneous datasets, comparison including supervised or semi-supervised MTL with heterogeneous dataset.</p>\n<blockquote>\n<p>reference <a href=\"https://arxiv.org/pdf/1411.6232.pdf\" target=\"_blank\" rel=\"noopener\">Semi-supervised Feature Analysis by Mining Correlations among Multiple Tasks</a></p>\n</blockquote>\n<ul>\n<li>semi-supervised, heterogeneou datasets, feature selection.</li>\n<li>scenario: CV, dataset A for tasks A[labeled and unlabeled], dataset B for tasks B[labeled and unlabeled]</li>\n<li>method: manifold learning, mining feature correlation by sparse coefficients.</li>\n<li>No</li>\n</ul>\n<blockquote>\n<p>reference <a href=\"https://arxiv.org/pdf/1604.01335.pdf\" target=\"_blank\" rel=\"noopener\">Deep Cross Residual Learning for Multitask Visual Recognition</a></p>\n</blockquote>\n<ul>\n<li>supervised, heterogeneou datasets, network structure.</li>\n<li>scenario: CV, dataset A for tasks A[labeled], dataset B for tasks B[labeled]</li>\n<li>method: enables intuitive learning across multiple related tasks using cross-connections called cross-residuals</li>\n<li>Yes? Netowrk realization?</li>\n</ul>\n<blockquote>\n<p>reference <a href=\"http://www.jmlr.org/papers/volume6/ando05a/ando05a.pdf\" target=\"_blank\" rel=\"noopener\">A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data</a></p>\n</blockquote>\n<ul>\n<li>semi-supervised, heterogeneou datasets, network structure.</li>\n<li>scenario: </li>\n<li>method: </li>\n<li>No</li>\n</ul>\n<blockquote>\n<p>reference <a href=\"https://arxiv.org/pdf/1802.09913.pdf\" target=\"_blank\" rel=\"noopener\">Multi-task Learning of Pairwise Sequence Classification Tasks Over Disparate Label Spaces</a></p>\n</blockquote>\n<ul>\n<li>supervised, heterogeneou datasets, network structure.</li>\n<li>scenario: text classification, dataset A for tasks A[labeled], dataset B for tasks B[labeled]</li>\n<li>method: combining multi-task learning and semi- supervised learning by inducing a joint embed- ding space between disparate label spaces and learning transfer functions between label embeddings. LTN can be used to label unlabelled and auxiliary task data by utilising the ‘distilling knowledge’ contained in auxiliary model predictions. not only model their relationship, but also to directly estimate the cor- responding label of the target task based on auxil- iary predictions</li>\n<li>Yes: embedding, prediction, output, temperature=1, embedding can be realized with cross-stich network</li>\n</ul>\n<blockquote>\n<p>reference <a href=\"http://www.aclweb.org/anthology/D16-1070\" target=\"_blank\" rel=\"noopener\">Neural Network for Heterogeneous Annotations</a></p>\n</blockquote>\n<ul>\n<li>supervised, heterogeneou datasets, multi-view &amp; stacking setting</li>\n<li>scenario: NLP, dataset A for tasks A[labeled], dataset B for tasks B[labeled]</li>\n<li>method: multi-view, stacking, neurual network</li>\n<li>Yes: not understand</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"MTL\"><a href=\"#MTL\" class=\"headerlink\" title=\"MTL\"></a>MTL</h2><h3 id=\"Learning-Methods\"><a href=\"#Learning-Methods\" class=\"headerlink\" title=\"Learning Methods\"></a>Learning Methods</h3><ul>\n<li>Supervised</li>\n<li>Semi-supervised</li>\n</ul>\n<h3 id=\"Scenarios\"><a href=\"#Scenarios\" class=\"headerlink\" title=\"Scenarios\"></a>Scenarios</h3><ul>\n<li>Homogeneous</li>\n<li>Heterogeneous<ul>\n<li>Heterogeneous Tasks (Document &amp; Images &amp; Audio)</li>\n<li>Hterogeneous Datsets (Each dataset with a set of labels)</li>\n</ul>\n</li>\n</ul>\n<h3 id=\"Improvement-Ideas\"><a href=\"#Improvement-Ideas\" class=\"headerlink\" title=\"Improvement Ideas\"></a>Improvement Ideas</h3><ul>\n<li>Network Structure</li>\n<li>Feature Selection</li>\n</ul>\n<h3 id=\"Application\"><a href=\"#Application\" class=\"headerlink\" title=\"Application\"></a>Application</h3><ul>\n<li>CV</li>\n<li>NLP</li>\n</ul>\n<p>ALL MTL is the combination of above mentioned.<br>Our method is semi-supervised MTL with heterogeneous datasets, comparison including supervised or semi-supervised MTL with heterogeneous dataset.</p>\n<blockquote>\n<p>reference <a href=\"https://arxiv.org/pdf/1411.6232.pdf\" target=\"_blank\" rel=\"noopener\">Semi-supervised Feature Analysis by Mining Correlations among Multiple Tasks</a></p>\n</blockquote>\n<ul>\n<li>semi-supervised, heterogeneou datasets, feature selection.</li>\n<li>scenario: CV, dataset A for tasks A[labeled and unlabeled], dataset B for tasks B[labeled and unlabeled]</li>\n<li>method: manifold learning, mining feature correlation by sparse coefficients.</li>\n<li>No</li>\n</ul>\n<blockquote>\n<p>reference <a href=\"https://arxiv.org/pdf/1604.01335.pdf\" target=\"_blank\" rel=\"noopener\">Deep Cross Residual Learning for Multitask Visual Recognition</a></p>\n</blockquote>\n<ul>\n<li>supervised, heterogeneou datasets, network structure.</li>\n<li>scenario: CV, dataset A for tasks A[labeled], dataset B for tasks B[labeled]</li>\n<li>method: enables intuitive learning across multiple related tasks using cross-connections called cross-residuals</li>\n<li>Yes? Netowrk realization?</li>\n</ul>\n<blockquote>\n<p>reference <a href=\"http://www.jmlr.org/papers/volume6/ando05a/ando05a.pdf\" target=\"_blank\" rel=\"noopener\">A Framework for Learning Predictive Structures from Multiple Tasks and Unlabeled Data</a></p>\n</blockquote>\n<ul>\n<li>semi-supervised, heterogeneou datasets, network structure.</li>\n<li>scenario: </li>\n<li>method: </li>\n<li>No</li>\n</ul>\n<blockquote>\n<p>reference <a href=\"https://arxiv.org/pdf/1802.09913.pdf\" target=\"_blank\" rel=\"noopener\">Multi-task Learning of Pairwise Sequence Classification Tasks Over Disparate Label Spaces</a></p>\n</blockquote>\n<ul>\n<li>supervised, heterogeneou datasets, network structure.</li>\n<li>scenario: text classification, dataset A for tasks A[labeled], dataset B for tasks B[labeled]</li>\n<li>method: combining multi-task learning and semi- supervised learning by inducing a joint embed- ding space between disparate label spaces and learning transfer functions between label embeddings. LTN can be used to label unlabelled and auxiliary task data by utilising the ‘distilling knowledge’ contained in auxiliary model predictions. not only model their relationship, but also to directly estimate the cor- responding label of the target task based on auxil- iary predictions</li>\n<li>Yes: embedding, prediction, output, temperature=1, embedding can be realized with cross-stich network</li>\n</ul>\n<blockquote>\n<p>reference <a href=\"http://www.aclweb.org/anthology/D16-1070\" target=\"_blank\" rel=\"noopener\">Neural Network for Heterogeneous Annotations</a></p>\n</blockquote>\n<ul>\n<li>supervised, heterogeneou datasets, multi-view &amp; stacking setting</li>\n<li>scenario: NLP, dataset A for tasks A[labeled], dataset B for tasks B[labeled]</li>\n<li>method: multi-view, stacking, neurual network</li>\n<li>Yes: not understand</li>\n</ul>\n"},{"title":"Numpy learning","date":"2019-01-14T14:25:55.000Z","_content":"\nOne-hot labels preprocessing\n\n* Weighting samples with confidence score\n``` bash\nindex = np.ragmax(predicted_result,axis=1)\narg = np_utils.to_categorical(index,classes)\nweighted_one_hot=predicted_result*arg\n```\n\n* Selection && weighting samples with confidence score\n``` bash\nweighted_selected_one_hot=np.where(predicted_result>k,predicted_result,0)\n```\n\n* Extending vector into matrix\n``` bash\nxx = [np.full(classes,value) for value in x]\n```\n\n\n","source":"_posts/numpy-learning.md","raw":"---\ntitle: Numpy learning\ndate: 2019-01-14 22:25:55\ntags: numpy\ncategories: Codes\n---\n\nOne-hot labels preprocessing\n\n* Weighting samples with confidence score\n``` bash\nindex = np.ragmax(predicted_result,axis=1)\narg = np_utils.to_categorical(index,classes)\nweighted_one_hot=predicted_result*arg\n```\n\n* Selection && weighting samples with confidence score\n``` bash\nweighted_selected_one_hot=np.where(predicted_result>k,predicted_result,0)\n```\n\n* Extending vector into matrix\n``` bash\nxx = [np.full(classes,value) for value in x]\n```\n\n\n","slug":"numpy-learning","published":1,"updated":"2019-04-08T06:20:55.948Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cju7zelmz0019qrm7wg85r4es","content":"<p>One-hot labels preprocessing</p>\n<ul>\n<li><p>Weighting samples with confidence score</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">index = np.ragmax(predicted_result,axis=1)</span><br><span class=\"line\">arg = np_utils.to_categorical(index,classes)</span><br><span class=\"line\">weighted_one_hot=predicted_result*arg</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>Selection &amp;&amp; weighting samples with confidence score</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">weighted_selected_one_hot=np.where(predicted_result&gt;k,predicted_result,0)</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>Extending vector into matrix</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">xx = [np.full(classes,value) <span class=\"keyword\">for</span> value <span class=\"keyword\">in</span> x]</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<p>One-hot labels preprocessing</p>\n<ul>\n<li><p>Weighting samples with confidence score</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">index = np.ragmax(predicted_result,axis=1)</span><br><span class=\"line\">arg = np_utils.to_categorical(index,classes)</span><br><span class=\"line\">weighted_one_hot=predicted_result*arg</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>Selection &amp;&amp; weighting samples with confidence score</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">weighted_selected_one_hot=np.where(predicted_result&gt;k,predicted_result,0)</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>Extending vector into matrix</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">xx = [np.full(classes,value) <span class=\"keyword\">for</span> value <span class=\"keyword\">in</span> x]</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n"},{"title":"Why-How-Pseudo","date":"2019-02-22T02:53:37.000Z","_content":"\n\n* Pseudo labels in multi-task learning\n* Pseudo data selection with density and distribution distance\n\n## Pseudo labels\nThe reason why need to apply pseudo data into model training \n* >reference [CurriculumNet: Weakly Supervised Learning from Large-Scale Web Images](http://openaccess.thecvf.com/content_ECCV_2018/papers/Sheng_Guo_CurriculumNet_Learning_from_ECCV_2018_paper.pdf), demonstrating that training a CNN from scratch using both clean and noisy data is better than just using the clean one, on the condition that the amount of pseudo data is limited.\n* >reference [From Facial Expression Recognition to Interpersonal Relation Prediction Zhanpeng](https://arxiv.org/pdf/1609.06426.pdf), stating explaination that pseudo data can bridge the gap between heterogeneous data.\n* >reference [Seeing through the Human Reporting Bias: Visual Classifiers from Noisy Human-Centric Labels](https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Misra_Seeing_Through_the_CVPR_2016_paper.pdf), 'what's the all attributs of images' versus 'what's the labeled attributes', labeling missing attributes. The novalty may be regarded as a baseline (waiting to understand the detail).\n* data imbalance in joint training strategy, such as 20k~ pose dataset AFLW and 90k~ emotion dataset ExpW.\n\n\n## Pseudo data selection\nBecause much noisy data can effect the model performance and even disturb the model training process, leading to poor model performance, pseudo data selection can control the ratio of pseudo data in the whole datasets.\n\n### Density\n* reason: because clusters are easily detected by the local density of data points, in the pseudo data belong to same categoty have similar feature. Appling a density based clustering algorithm that measures the complexity of psuedo data using data distribution density in. each category.\n* implementation detail: measuring the purity of data with pseudo label based on its distribution density in a feature space, and rank the purity to generate pseudo weights, pseudo data with higher density is assigned larger weights, while smaller weights are assigned to low-density pseudo data.\n\n### Distribution distance\n* reason: \n * 'transfer learning is one important method in machine learning, it can relax the condition of the independent identical distribution in train dataset and test dataset, so that knowledge can be transfered from source domain to target domain','its main application includes domain adaptation and multi-domain tranferation'.\n * instance-based domain adaption: calculating the distance between source domain data and target domain data, then adjusting the weights of target domain instance so that the target data can be matched with source domain data. In detail, the smaller distance, the higher similarity.\n* implementation detail: \n   1. GMM\n     * reason:\n     * implementation: generating Gaussian Mixture models (GMM) based on A1 (data with pseuodo label) and B (data with ground truth) in each categoty. Assuming GMM has K Gaussian models, we obtain G(A1_1), ..., G(A1_K), G(B1_1), ..., G(B1_K); \n   2. EMD\n     * reason: >reference [Large Scale Fine-Grained Categorization and Domain-Specific Transfer Learning](http://openaccess.thecvf.com/content_cvpr_2018/papers/Cui_Large_Scale_Fine-Grained_CVPR_2018_paper.pdf),  which takes domain scale into account by adding a scale factor. In this paper, transfer learning can be viewed as moving a set of images from the source domain S to the target domain T. The work needed to be done by moving an image to another can be defined as their feature Euaullean distance, so the distance between two domains can be defined as the least amount of total work needed. This definition of domain similarity can be calculated by the Earth Mover’s Distance (EMD). \n       * original EMD equation\n\n\t     \\begin{aligned}\n\t\t \\sum_{i=1}^{m}\\sum_{j=1}^{n}f_{i,j}=\\min \\{\\sum_{i=1}^{m}w_{pi},\\quad \\sum_{j=1}^{n}w_{qj}\\}\n\t\t \\end{aligned}\n\n\t\t \\begin{aligned}\n\t\t EMD(P,Q)={\\frac {\\sum_{i=1}^{m}\\sum_{j=1}^{n}f_{i,j}d_{i,j}}{\\sum_{i=1}^{m}\\sum_{j=1}^{n}f_{i,j}}}\n\t     \\end{aligned}\n\n\t\t \\begin{aligned}\n\t\t P=\\{(p_{1},w_{p1}),(p_{2},w_{p2}),...,(p_{m},w_{pm})\\}\n\t\t \\end{aligned}\n\n\t\t \\begin{aligned}\n\t\t Q=\\{(q_{1},w_{q1}),(q_{2},w_{q2}),...,(q_{n},w_{qn})\\}\n\t\t \\end{aligned}\n\n\t   * reference paper EMD application\n\t\t g(s_{i}) from the mean value of image features in category i from source domain\n\t\t g(t_{i}) from the mean value of image features in category i from target domain\n\t\t \\begin{aligned}\n\t\t \\sum_{i=1}^{m}\\sum_{j=1}^{n}f_{i,j}=\\min \\{\\sum_{i=1}^{m}w_{pi},\\quad \\sum_{j=1}^{n}w_{qj}\\}\n\t\t \\end{aligned}\n\n\t\t \\begin{aligned}\n\t\t EMD(P,Q)={\\frac {\\sum_{i=1}^{m}\\sum_{j=1}^{n}f_{i,j}d_{i,j}}{\\sum_{i=1}^{m}\\sum_{j=1}^{n}f_{i,j}}}\n\t     \\end{aligned}\n\n\t\t \\begin{aligned}\n\t\t S=\\{(s_{1},w_{s1}),(s_{2},w_{s2}),...,(s_{m},w_{sm})\\}\n\t\t \\end{aligned}\n\n\t\t \\begin{aligned}\n\t\t T=\\{(t_{1},w_{t1}),(t_{2},w_{t2}),...,(t_{n},w_{tn})\\}\n\t\t \\end{aligned}\n\n\t\t \\begin{aligned}\n\t\t D=[d_{i,j}] = || g(s_{i}) − g(t_{j})|| \n\t\t \\end{aligned}\n\n\t\t \\begin{aligned}\n\t\t sim(S, T) = e−γd(S,T )\n\t\t \\end{aligned}\n\n\t   * EMD application for pseudo data selection\n\t   \t g(p) = mean value of image features in specific cluster from the same category in source domain\n\t   \t g(g_{i}) = mean value of image features in cluster i from the same category in target domain\n\t     \\begin{aligned}\n\t\t \\sum_{i=1}^{m}\\sum_{j=1}^{n}f_{i,j}=\\min \\{\\sum_{i=1}^{m}w_{pi},\\quad \\sum_{j=1}^{n}w_{qj}\\}\n\t\t \\end{aligned}\n\n\t\t \\begin{aligned}\n\t\t EMD(P,Q)={\\frac {\\sum_{i=1}^{m}\\sum_{j=1}^{n}f_{i,j}d_{i,j}}{\\sum_{i=1}^{m}\\sum_{j=1}^{n}f_{i,j}}}\n\t     \\end{aligned}\n\n\t\t \\begin{aligned}\n\t\t P=\\{(p_{1},w_{p1}),(p_{2},w_{p2}),...,(p_{m},w_{pm})\\}\n\t\t \\end{aligned}\n\n\t\t \\begin{aligned}\n\t\t G=\\{(g_{1},w_{g1}),(g_{2},w_{g2}),...,(g_{n},w_{gn})\\}\n\t\t \\end{aligned}\n\n\t\t \\begin{aligned}\n\t\t D=[d_{i,j}] = || g(p_{i}) − g(g_{j})|| \n\t\t \\end{aligned}\n\n\t\t \\begin{aligned}\n\t\t sim(S, T) = e−γd(S,T )\n\t\t \\end{aligned}\n     * implementation: calculating the distance between G(A1_i) and the whole cluster in G(B1). As for distance calculation with EMD method, we obtain P={G(A1_i)_mean,G(A1_i)_probs} and Q={[G(B1_1)_mean, ..., G(B1_K)_mean],[G(B1_1)_probs, ..., G(B1_K)_probs]}, so we can calculate distance vector D=(emd_1,emd_k), which is used for obtaining distribution weights weights_g.\n","source":"_posts/Why-How-Pseudo.md","raw":"---\ntitle: Why-How-Pseudo\ndate: 2019-02-22 10:53:37\ntags: pesudo labels\ncategories: Theory\n---\n\n\n* Pseudo labels in multi-task learning\n* Pseudo data selection with density and distribution distance\n\n## Pseudo labels\nThe reason why need to apply pseudo data into model training \n* >reference [CurriculumNet: Weakly Supervised Learning from Large-Scale Web Images](http://openaccess.thecvf.com/content_ECCV_2018/papers/Sheng_Guo_CurriculumNet_Learning_from_ECCV_2018_paper.pdf), demonstrating that training a CNN from scratch using both clean and noisy data is better than just using the clean one, on the condition that the amount of pseudo data is limited.\n* >reference [From Facial Expression Recognition to Interpersonal Relation Prediction Zhanpeng](https://arxiv.org/pdf/1609.06426.pdf), stating explaination that pseudo data can bridge the gap between heterogeneous data.\n* >reference [Seeing through the Human Reporting Bias: Visual Classifiers from Noisy Human-Centric Labels](https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Misra_Seeing_Through_the_CVPR_2016_paper.pdf), 'what's the all attributs of images' versus 'what's the labeled attributes', labeling missing attributes. The novalty may be regarded as a baseline (waiting to understand the detail).\n* data imbalance in joint training strategy, such as 20k~ pose dataset AFLW and 90k~ emotion dataset ExpW.\n\n\n## Pseudo data selection\nBecause much noisy data can effect the model performance and even disturb the model training process, leading to poor model performance, pseudo data selection can control the ratio of pseudo data in the whole datasets.\n\n### Density\n* reason: because clusters are easily detected by the local density of data points, in the pseudo data belong to same categoty have similar feature. Appling a density based clustering algorithm that measures the complexity of psuedo data using data distribution density in. each category.\n* implementation detail: measuring the purity of data with pseudo label based on its distribution density in a feature space, and rank the purity to generate pseudo weights, pseudo data with higher density is assigned larger weights, while smaller weights are assigned to low-density pseudo data.\n\n### Distribution distance\n* reason: \n * 'transfer learning is one important method in machine learning, it can relax the condition of the independent identical distribution in train dataset and test dataset, so that knowledge can be transfered from source domain to target domain','its main application includes domain adaptation and multi-domain tranferation'.\n * instance-based domain adaption: calculating the distance between source domain data and target domain data, then adjusting the weights of target domain instance so that the target data can be matched with source domain data. In detail, the smaller distance, the higher similarity.\n* implementation detail: \n   1. GMM\n     * reason:\n     * implementation: generating Gaussian Mixture models (GMM) based on A1 (data with pseuodo label) and B (data with ground truth) in each categoty. Assuming GMM has K Gaussian models, we obtain G(A1_1), ..., G(A1_K), G(B1_1), ..., G(B1_K); \n   2. EMD\n     * reason: >reference [Large Scale Fine-Grained Categorization and Domain-Specific Transfer Learning](http://openaccess.thecvf.com/content_cvpr_2018/papers/Cui_Large_Scale_Fine-Grained_CVPR_2018_paper.pdf),  which takes domain scale into account by adding a scale factor. In this paper, transfer learning can be viewed as moving a set of images from the source domain S to the target domain T. The work needed to be done by moving an image to another can be defined as their feature Euaullean distance, so the distance between two domains can be defined as the least amount of total work needed. This definition of domain similarity can be calculated by the Earth Mover’s Distance (EMD). \n       * original EMD equation\n\n\t     \\begin{aligned}\n\t\t \\sum_{i=1}^{m}\\sum_{j=1}^{n}f_{i,j}=\\min \\{\\sum_{i=1}^{m}w_{pi},\\quad \\sum_{j=1}^{n}w_{qj}\\}\n\t\t \\end{aligned}\n\n\t\t \\begin{aligned}\n\t\t EMD(P,Q)={\\frac {\\sum_{i=1}^{m}\\sum_{j=1}^{n}f_{i,j}d_{i,j}}{\\sum_{i=1}^{m}\\sum_{j=1}^{n}f_{i,j}}}\n\t     \\end{aligned}\n\n\t\t \\begin{aligned}\n\t\t P=\\{(p_{1},w_{p1}),(p_{2},w_{p2}),...,(p_{m},w_{pm})\\}\n\t\t \\end{aligned}\n\n\t\t \\begin{aligned}\n\t\t Q=\\{(q_{1},w_{q1}),(q_{2},w_{q2}),...,(q_{n},w_{qn})\\}\n\t\t \\end{aligned}\n\n\t   * reference paper EMD application\n\t\t g(s_{i}) from the mean value of image features in category i from source domain\n\t\t g(t_{i}) from the mean value of image features in category i from target domain\n\t\t \\begin{aligned}\n\t\t \\sum_{i=1}^{m}\\sum_{j=1}^{n}f_{i,j}=\\min \\{\\sum_{i=1}^{m}w_{pi},\\quad \\sum_{j=1}^{n}w_{qj}\\}\n\t\t \\end{aligned}\n\n\t\t \\begin{aligned}\n\t\t EMD(P,Q)={\\frac {\\sum_{i=1}^{m}\\sum_{j=1}^{n}f_{i,j}d_{i,j}}{\\sum_{i=1}^{m}\\sum_{j=1}^{n}f_{i,j}}}\n\t     \\end{aligned}\n\n\t\t \\begin{aligned}\n\t\t S=\\{(s_{1},w_{s1}),(s_{2},w_{s2}),...,(s_{m},w_{sm})\\}\n\t\t \\end{aligned}\n\n\t\t \\begin{aligned}\n\t\t T=\\{(t_{1},w_{t1}),(t_{2},w_{t2}),...,(t_{n},w_{tn})\\}\n\t\t \\end{aligned}\n\n\t\t \\begin{aligned}\n\t\t D=[d_{i,j}] = || g(s_{i}) − g(t_{j})|| \n\t\t \\end{aligned}\n\n\t\t \\begin{aligned}\n\t\t sim(S, T) = e−γd(S,T )\n\t\t \\end{aligned}\n\n\t   * EMD application for pseudo data selection\n\t   \t g(p) = mean value of image features in specific cluster from the same category in source domain\n\t   \t g(g_{i}) = mean value of image features in cluster i from the same category in target domain\n\t     \\begin{aligned}\n\t\t \\sum_{i=1}^{m}\\sum_{j=1}^{n}f_{i,j}=\\min \\{\\sum_{i=1}^{m}w_{pi},\\quad \\sum_{j=1}^{n}w_{qj}\\}\n\t\t \\end{aligned}\n\n\t\t \\begin{aligned}\n\t\t EMD(P,Q)={\\frac {\\sum_{i=1}^{m}\\sum_{j=1}^{n}f_{i,j}d_{i,j}}{\\sum_{i=1}^{m}\\sum_{j=1}^{n}f_{i,j}}}\n\t     \\end{aligned}\n\n\t\t \\begin{aligned}\n\t\t P=\\{(p_{1},w_{p1}),(p_{2},w_{p2}),...,(p_{m},w_{pm})\\}\n\t\t \\end{aligned}\n\n\t\t \\begin{aligned}\n\t\t G=\\{(g_{1},w_{g1}),(g_{2},w_{g2}),...,(g_{n},w_{gn})\\}\n\t\t \\end{aligned}\n\n\t\t \\begin{aligned}\n\t\t D=[d_{i,j}] = || g(p_{i}) − g(g_{j})|| \n\t\t \\end{aligned}\n\n\t\t \\begin{aligned}\n\t\t sim(S, T) = e−γd(S,T )\n\t\t \\end{aligned}\n     * implementation: calculating the distance between G(A1_i) and the whole cluster in G(B1). As for distance calculation with EMD method, we obtain P={G(A1_i)_mean,G(A1_i)_probs} and Q={[G(B1_1)_mean, ..., G(B1_K)_mean],[G(B1_1)_probs, ..., G(B1_K)_probs]}, so we can calculate distance vector D=(emd_1,emd_k), which is used for obtaining distribution weights weights_g.\n","slug":"Why-How-Pseudo","published":1,"updated":"2019-04-08T06:20:55.948Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cju7zeln0001dqrm792j0j1c7","content":"<ul>\n<li>Pseudo labels in multi-task learning</li>\n<li>Pseudo data selection with density and distribution distance</li>\n</ul>\n<h2 id=\"Pseudo-labels\"><a href=\"#Pseudo-labels\" class=\"headerlink\" title=\"Pseudo labels\"></a>Pseudo labels</h2><p>The reason why need to apply pseudo data into model training </p>\n<ul>\n<li><blockquote>\n<p>reference <a href=\"http://openaccess.thecvf.com/content_ECCV_2018/papers/Sheng_Guo_CurriculumNet_Learning_from_ECCV_2018_paper.pdf\" target=\"_blank\" rel=\"noopener\">CurriculumNet: Weakly Supervised Learning from Large-Scale Web Images</a>, demonstrating that training a CNN from scratch using both clean and noisy data is better than just using the clean one, on the condition that the amount of pseudo data is limited.</p>\n</blockquote>\n</li>\n<li><blockquote>\n<p>reference <a href=\"https://arxiv.org/pdf/1609.06426.pdf\" target=\"_blank\" rel=\"noopener\">From Facial Expression Recognition to Interpersonal Relation Prediction Zhanpeng</a>, stating explaination that pseudo data can bridge the gap between heterogeneous data.</p>\n</blockquote>\n</li>\n<li><blockquote>\n<p>reference <a href=\"https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Misra_Seeing_Through_the_CVPR_2016_paper.pdf\" target=\"_blank\" rel=\"noopener\">Seeing through the Human Reporting Bias: Visual Classifiers from Noisy Human-Centric Labels</a>, ‘what’s the all attributs of images’ versus ‘what’s the labeled attributes’, labeling missing attributes. The novalty may be regarded as a baseline (waiting to understand the detail).</p>\n</blockquote>\n</li>\n<li>data imbalance in joint training strategy, such as 20k~ pose dataset AFLW and 90k~ emotion dataset ExpW.</li>\n</ul>\n<h2 id=\"Pseudo-data-selection\"><a href=\"#Pseudo-data-selection\" class=\"headerlink\" title=\"Pseudo data selection\"></a>Pseudo data selection</h2><p>Because much noisy data can effect the model performance and even disturb the model training process, leading to poor model performance, pseudo data selection can control the ratio of pseudo data in the whole datasets.</p>\n<h3 id=\"Density\"><a href=\"#Density\" class=\"headerlink\" title=\"Density\"></a>Density</h3><ul>\n<li>reason: because clusters are easily detected by the local density of data points, in the pseudo data belong to same categoty have similar feature. Appling a density based clustering algorithm that measures the complexity of psuedo data using data distribution density in. each category.</li>\n<li>implementation detail: measuring the purity of data with pseudo label based on its distribution density in a feature space, and rank the purity to generate pseudo weights, pseudo data with higher density is assigned larger weights, while smaller weights are assigned to low-density pseudo data.</li>\n</ul>\n<h3 id=\"Distribution-distance\"><a href=\"#Distribution-distance\" class=\"headerlink\" title=\"Distribution distance\"></a>Distribution distance</h3><ul>\n<li>reason: <ul>\n<li>‘transfer learning is one important method in machine learning, it can relax the condition of the independent identical distribution in train dataset and test dataset, so that knowledge can be transfered from source domain to target domain’,’its main application includes domain adaptation and multi-domain tranferation’.</li>\n<li>instance-based domain adaption: calculating the distance between source domain data and target domain data, then adjusting the weights of target domain instance so that the target data can be matched with source domain data. In detail, the smaller distance, the higher similarity.</li>\n</ul>\n</li>\n<li><p>implementation detail: </p>\n<ol>\n<li>GMM<ul>\n<li>reason:</li>\n<li>implementation: generating Gaussian Mixture models (GMM) based on A1 (data with pseuodo label) and B (data with ground truth) in each categoty. Assuming GMM has K Gaussian models, we obtain G(A1_1), …, G(A1_K), G(B1_1), …, G(B1_K); </li>\n</ul>\n</li>\n<li><p>EMD</p>\n<ul>\n<li><p>reason: &gt;reference <a href=\"http://openaccess.thecvf.com/content_cvpr_2018/papers/Cui_Large_Scale_Fine-Grained_CVPR_2018_paper.pdf\" target=\"_blank\" rel=\"noopener\">Large Scale Fine-Grained Categorization and Domain-Specific Transfer Learning</a>,  which takes domain scale into account by adding a scale factor. In this paper, transfer learning can be viewed as moving a set of images from the source domain S to the target domain T. The work needed to be done by moving an image to another can be defined as their feature Euaullean distance, so the distance between two domains can be defined as the least amount of total work needed. This definition of domain similarity can be calculated by the Earth Mover’s Distance (EMD). </p>\n<ul>\n<li><p>original EMD equation</p>\n<p>\\begin{aligned}<br>\\sum<em>{i=1}^{m}\\sum</em>{j=1}^{n}f<em>{i,j}=\\min {\\sum</em>{i=1}^{m}w<em>{pi},\\quad \\sum</em>{j=1}^{n}w_{qj}}<br>\\end{aligned}</p>\n<p>\\begin{aligned}<br>EMD(P,Q)={\\frac {\\sum<em>{i=1}^{m}\\sum</em>{j=1}^{n}f<em>{i,j}d</em>{i,j}}{\\sum<em>{i=1}^{m}\\sum</em>{j=1}^{n}f_{i,j}}}<br>\\end{aligned}</p>\n<p>\\begin{aligned}<br>P={(p<em>{1},w</em>{p1}),(p<em>{2},w</em>{p2}),…,(p<em>{m},w</em>{pm})}<br>\\end{aligned}</p>\n<p>\\begin{aligned}<br>Q={(q<em>{1},w</em>{q1}),(q<em>{2},w</em>{q2}),…,(q<em>{n},w</em>{qn})}<br>\\end{aligned}</p>\n</li>\n<li><p>reference paper EMD application<br>g(s<em>{i}) from the mean value of image features in category i from source domain<br>g(t</em>{i}) from the mean value of image features in category i from target domain<br>\\begin{aligned}<br>\\sum<em>{i=1}^{m}\\sum</em>{j=1}^{n}f<em>{i,j}=\\min {\\sum</em>{i=1}^{m}w<em>{pi},\\quad \\sum</em>{j=1}^{n}w_{qj}}<br>\\end{aligned}</p>\n<p>\\begin{aligned}<br>EMD(P,Q)={\\frac {\\sum<em>{i=1}^{m}\\sum</em>{j=1}^{n}f<em>{i,j}d</em>{i,j}}{\\sum<em>{i=1}^{m}\\sum</em>{j=1}^{n}f_{i,j}}}<br>\\end{aligned}</p>\n<p>\\begin{aligned}<br>S={(s<em>{1},w</em>{s1}),(s<em>{2},w</em>{s2}),…,(s<em>{m},w</em>{sm})}<br>\\end{aligned}</p>\n<p>\\begin{aligned}<br>T={(t<em>{1},w</em>{t1}),(t<em>{2},w</em>{t2}),…,(t<em>{n},w</em>{tn})}<br>\\end{aligned}</p>\n<p>\\begin{aligned}<br>D=[d<em>{i,j}] = || g(s</em>{i}) − g(t_{j})||<br>\\end{aligned}</p>\n<p>\\begin{aligned}<br>sim(S, T) = e−γd(S,T )<br>\\end{aligned}</p>\n</li>\n<li><p>EMD application for pseudo data selection<br>  g(p) = mean value of image features in specific cluster from the same category in source domain<br>  g(g<em>{i}) = mean value of image features in cluster i from the same category in target domain<br>\\begin{aligned}<br>\\sum</em>{i=1}^{m}\\sum<em>{j=1}^{n}f</em>{i,j}=\\min {\\sum<em>{i=1}^{m}w</em>{pi},\\quad \\sum<em>{j=1}^{n}w</em>{qj}}<br>\\end{aligned}</p>\n<p>\\begin{aligned}<br>EMD(P,Q)={\\frac {\\sum<em>{i=1}^{m}\\sum</em>{j=1}^{n}f<em>{i,j}d</em>{i,j}}{\\sum<em>{i=1}^{m}\\sum</em>{j=1}^{n}f_{i,j}}}<br>\\end{aligned}</p>\n<p>\\begin{aligned}<br>P={(p<em>{1},w</em>{p1}),(p<em>{2},w</em>{p2}),…,(p<em>{m},w</em>{pm})}<br>\\end{aligned}</p>\n<p>\\begin{aligned}<br>G={(g<em>{1},w</em>{g1}),(g<em>{2},w</em>{g2}),…,(g<em>{n},w</em>{gn})}<br>\\end{aligned}</p>\n<p>\\begin{aligned}<br>D=[d<em>{i,j}] = || g(p</em>{i}) − g(g_{j})||<br>\\end{aligned}</p>\n<p>\\begin{aligned}<br>sim(S, T) = e−γd(S,T )<br>\\end{aligned}</p>\n</li>\n</ul>\n</li>\n<li>implementation: calculating the distance between G(A1_i) and the whole cluster in G(B1). As for distance calculation with EMD method, we obtain P={G(A1_i)_mean,G(A1_i)_probs} and Q={[G(B1_1)_mean, …, G(B1_K)_mean],[G(B1_1)_probs, …, G(B1_K)_probs]}, so we can calculate distance vector D=(emd_1,emd_k), which is used for obtaining distribution weights weights_g.</li>\n</ul>\n</li>\n</ol>\n</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<ul>\n<li>Pseudo labels in multi-task learning</li>\n<li>Pseudo data selection with density and distribution distance</li>\n</ul>\n<h2 id=\"Pseudo-labels\"><a href=\"#Pseudo-labels\" class=\"headerlink\" title=\"Pseudo labels\"></a>Pseudo labels</h2><p>The reason why need to apply pseudo data into model training </p>\n<ul>\n<li><blockquote>\n<p>reference <a href=\"http://openaccess.thecvf.com/content_ECCV_2018/papers/Sheng_Guo_CurriculumNet_Learning_from_ECCV_2018_paper.pdf\" target=\"_blank\" rel=\"noopener\">CurriculumNet: Weakly Supervised Learning from Large-Scale Web Images</a>, demonstrating that training a CNN from scratch using both clean and noisy data is better than just using the clean one, on the condition that the amount of pseudo data is limited.</p>\n</blockquote>\n</li>\n<li><blockquote>\n<p>reference <a href=\"https://arxiv.org/pdf/1609.06426.pdf\" target=\"_blank\" rel=\"noopener\">From Facial Expression Recognition to Interpersonal Relation Prediction Zhanpeng</a>, stating explaination that pseudo data can bridge the gap between heterogeneous data.</p>\n</blockquote>\n</li>\n<li><blockquote>\n<p>reference <a href=\"https://www.cv-foundation.org/openaccess/content_cvpr_2016/papers/Misra_Seeing_Through_the_CVPR_2016_paper.pdf\" target=\"_blank\" rel=\"noopener\">Seeing through the Human Reporting Bias: Visual Classifiers from Noisy Human-Centric Labels</a>, ‘what’s the all attributs of images’ versus ‘what’s the labeled attributes’, labeling missing attributes. The novalty may be regarded as a baseline (waiting to understand the detail).</p>\n</blockquote>\n</li>\n<li>data imbalance in joint training strategy, such as 20k~ pose dataset AFLW and 90k~ emotion dataset ExpW.</li>\n</ul>\n<h2 id=\"Pseudo-data-selection\"><a href=\"#Pseudo-data-selection\" class=\"headerlink\" title=\"Pseudo data selection\"></a>Pseudo data selection</h2><p>Because much noisy data can effect the model performance and even disturb the model training process, leading to poor model performance, pseudo data selection can control the ratio of pseudo data in the whole datasets.</p>\n<h3 id=\"Density\"><a href=\"#Density\" class=\"headerlink\" title=\"Density\"></a>Density</h3><ul>\n<li>reason: because clusters are easily detected by the local density of data points, in the pseudo data belong to same categoty have similar feature. Appling a density based clustering algorithm that measures the complexity of psuedo data using data distribution density in. each category.</li>\n<li>implementation detail: measuring the purity of data with pseudo label based on its distribution density in a feature space, and rank the purity to generate pseudo weights, pseudo data with higher density is assigned larger weights, while smaller weights are assigned to low-density pseudo data.</li>\n</ul>\n<h3 id=\"Distribution-distance\"><a href=\"#Distribution-distance\" class=\"headerlink\" title=\"Distribution distance\"></a>Distribution distance</h3><ul>\n<li>reason: <ul>\n<li>‘transfer learning is one important method in machine learning, it can relax the condition of the independent identical distribution in train dataset and test dataset, so that knowledge can be transfered from source domain to target domain’,’its main application includes domain adaptation and multi-domain tranferation’.</li>\n<li>instance-based domain adaption: calculating the distance between source domain data and target domain data, then adjusting the weights of target domain instance so that the target data can be matched with source domain data. In detail, the smaller distance, the higher similarity.</li>\n</ul>\n</li>\n<li><p>implementation detail: </p>\n<ol>\n<li>GMM<ul>\n<li>reason:</li>\n<li>implementation: generating Gaussian Mixture models (GMM) based on A1 (data with pseuodo label) and B (data with ground truth) in each categoty. Assuming GMM has K Gaussian models, we obtain G(A1_1), …, G(A1_K), G(B1_1), …, G(B1_K); </li>\n</ul>\n</li>\n<li><p>EMD</p>\n<ul>\n<li><p>reason: &gt;reference <a href=\"http://openaccess.thecvf.com/content_cvpr_2018/papers/Cui_Large_Scale_Fine-Grained_CVPR_2018_paper.pdf\" target=\"_blank\" rel=\"noopener\">Large Scale Fine-Grained Categorization and Domain-Specific Transfer Learning</a>,  which takes domain scale into account by adding a scale factor. In this paper, transfer learning can be viewed as moving a set of images from the source domain S to the target domain T. The work needed to be done by moving an image to another can be defined as their feature Euaullean distance, so the distance between two domains can be defined as the least amount of total work needed. This definition of domain similarity can be calculated by the Earth Mover’s Distance (EMD). </p>\n<ul>\n<li><p>original EMD equation</p>\n<p>\\begin{aligned}<br>\\sum<em>{i=1}^{m}\\sum</em>{j=1}^{n}f<em>{i,j}=\\min {\\sum</em>{i=1}^{m}w<em>{pi},\\quad \\sum</em>{j=1}^{n}w_{qj}}<br>\\end{aligned}</p>\n<p>\\begin{aligned}<br>EMD(P,Q)={\\frac {\\sum<em>{i=1}^{m}\\sum</em>{j=1}^{n}f<em>{i,j}d</em>{i,j}}{\\sum<em>{i=1}^{m}\\sum</em>{j=1}^{n}f_{i,j}}}<br>\\end{aligned}</p>\n<p>\\begin{aligned}<br>P={(p<em>{1},w</em>{p1}),(p<em>{2},w</em>{p2}),…,(p<em>{m},w</em>{pm})}<br>\\end{aligned}</p>\n<p>\\begin{aligned}<br>Q={(q<em>{1},w</em>{q1}),(q<em>{2},w</em>{q2}),…,(q<em>{n},w</em>{qn})}<br>\\end{aligned}</p>\n</li>\n<li><p>reference paper EMD application<br>g(s<em>{i}) from the mean value of image features in category i from source domain<br>g(t</em>{i}) from the mean value of image features in category i from target domain<br>\\begin{aligned}<br>\\sum<em>{i=1}^{m}\\sum</em>{j=1}^{n}f<em>{i,j}=\\min {\\sum</em>{i=1}^{m}w<em>{pi},\\quad \\sum</em>{j=1}^{n}w_{qj}}<br>\\end{aligned}</p>\n<p>\\begin{aligned}<br>EMD(P,Q)={\\frac {\\sum<em>{i=1}^{m}\\sum</em>{j=1}^{n}f<em>{i,j}d</em>{i,j}}{\\sum<em>{i=1}^{m}\\sum</em>{j=1}^{n}f_{i,j}}}<br>\\end{aligned}</p>\n<p>\\begin{aligned}<br>S={(s<em>{1},w</em>{s1}),(s<em>{2},w</em>{s2}),…,(s<em>{m},w</em>{sm})}<br>\\end{aligned}</p>\n<p>\\begin{aligned}<br>T={(t<em>{1},w</em>{t1}),(t<em>{2},w</em>{t2}),…,(t<em>{n},w</em>{tn})}<br>\\end{aligned}</p>\n<p>\\begin{aligned}<br>D=[d<em>{i,j}] = || g(s</em>{i}) − g(t_{j})||<br>\\end{aligned}</p>\n<p>\\begin{aligned}<br>sim(S, T) = e−γd(S,T )<br>\\end{aligned}</p>\n</li>\n<li><p>EMD application for pseudo data selection<br>  g(p) = mean value of image features in specific cluster from the same category in source domain<br>  g(g<em>{i}) = mean value of image features in cluster i from the same category in target domain<br>\\begin{aligned}<br>\\sum</em>{i=1}^{m}\\sum<em>{j=1}^{n}f</em>{i,j}=\\min {\\sum<em>{i=1}^{m}w</em>{pi},\\quad \\sum<em>{j=1}^{n}w</em>{qj}}<br>\\end{aligned}</p>\n<p>\\begin{aligned}<br>EMD(P,Q)={\\frac {\\sum<em>{i=1}^{m}\\sum</em>{j=1}^{n}f<em>{i,j}d</em>{i,j}}{\\sum<em>{i=1}^{m}\\sum</em>{j=1}^{n}f_{i,j}}}<br>\\end{aligned}</p>\n<p>\\begin{aligned}<br>P={(p<em>{1},w</em>{p1}),(p<em>{2},w</em>{p2}),…,(p<em>{m},w</em>{pm})}<br>\\end{aligned}</p>\n<p>\\begin{aligned}<br>G={(g<em>{1},w</em>{g1}),(g<em>{2},w</em>{g2}),…,(g<em>{n},w</em>{gn})}<br>\\end{aligned}</p>\n<p>\\begin{aligned}<br>D=[d<em>{i,j}] = || g(p</em>{i}) − g(g_{j})||<br>\\end{aligned}</p>\n<p>\\begin{aligned}<br>sim(S, T) = e−γd(S,T )<br>\\end{aligned}</p>\n</li>\n</ul>\n</li>\n<li>implementation: calculating the distance between G(A1_i) and the whole cluster in G(B1). As for distance calculation with EMD method, we obtain P={G(A1_i)_mean,G(A1_i)_probs} and Q={[G(B1_1)_mean, …, G(B1_K)_mean],[G(B1_1)_probs, …, G(B1_K)_probs]}, so we can calculate distance vector D=(emd_1,emd_k), which is used for obtaining distribution weights weights_g.</li>\n</ul>\n</li>\n</ol>\n</li>\n</ul>\n"}],"PostAsset":[],"PostCategory":[{"post_id":"cju7zelme0000qrm747ezmxjg","category_id":"cju7zelmj0004qrm7idghmneu","_id":"cju7zelmr000fqrm730q8c6bw"},{"post_id":"cju7zelmh0002qrm7ksvv3je2","category_id":"cju7zelmj0004qrm7idghmneu","_id":"cju7zelmu000lqrm7eid8yaut"},{"post_id":"cju7zelmr000iqrm7uqg228ml","category_id":"cju7zelmj0004qrm7idghmneu","_id":"cju7zelmv000rqrm7rzvx6y3m"},{"post_id":"cju7zelmm0006qrm75psake5a","category_id":"cju7zelmj0004qrm7idghmneu","_id":"cju7zelmw000vqrm77q57imcm"},{"post_id":"cju7zelmt000jqrm78iuwh6gd","category_id":"cju7zelmj0004qrm7idghmneu","_id":"cju7zelmx000yqrm72o6i60ic"},{"post_id":"cju7zelmn0007qrm738ohwi38","category_id":"cju7zelmu000kqrm7kksln246","_id":"cju7zelmy0013qrm76awbihoy"},{"post_id":"cju7zelmv000qqrm7wgk9wkoo","category_id":"cju7zelmj0004qrm7idghmneu","_id":"cju7zelmz0016qrm70kv1jd3l"},{"post_id":"cju7zelmw000uqrm76vqy8y6j","category_id":"cju7zelmu000kqrm7kksln246","_id":"cju7zeln0001aqrm7dk01kpa1"},{"post_id":"cju7zelmp000cqrm7jdcnp41s","category_id":"cju7zelmw000sqrm7cq93tgv9","_id":"cju7zeln1001eqrm7aib6t4ov"},{"post_id":"cju7zelmx000xqrm760jskuah","category_id":"cju7zelmj0004qrm7idghmneu","_id":"cju7zeln1001gqrm70ajk15jy"},{"post_id":"cju7zelmy0012qrm7lplt4zmq","category_id":"cju7zelmj0004qrm7idghmneu","_id":"cju7zeln1001jqrm7f9oaypy4"},{"post_id":"cju7zelmq000dqrm7080fbv99","category_id":"cju7zelmu000kqrm7kksln246","_id":"cju7zeln2001lqrm7pj85me5q"},{"post_id":"cju7zelmz0015qrm7ufrqth9q","category_id":"cju7zelmj0004qrm7idghmneu","_id":"cju7zeln2001oqrm7tkwu5ml4"},{"post_id":"cju7zelmz0019qrm7wg85r4es","category_id":"cju7zelmz0018qrm7fgwr02l6","_id":"cju7zeln2001qqrm7a39psatl"},{"post_id":"cju7zelmu000oqrm7nig10sdg","category_id":"cju7zelmz0018qrm7fgwr02l6","_id":"cju7zeln2001sqrm7djiyouxd"},{"post_id":"cju7zeln0001dqrm792j0j1c7","category_id":"cju7zelmu000kqrm7kksln246","_id":"cju7zeln3001uqrm74c3xlgst"}],"PostTag":[{"post_id":"cju7zelme0000qrm747ezmxjg","tag_id":"cju7zelmm0005qrm76iascl9e","_id":"cju7zelmp000bqrm7114mh109"},{"post_id":"cju7zelmh0002qrm7ksvv3je2","tag_id":"cju7zelmm0005qrm76iascl9e","_id":"cju7zelmr000hqrm7a7rayos2"},{"post_id":"cju7zelmr000iqrm7uqg228ml","tag_id":"cju7zelmm0005qrm76iascl9e","_id":"cju7zelmu000nqrm7r0jw8sxg"},{"post_id":"cju7zelmm0006qrm75psake5a","tag_id":"cju7zelmr000gqrm7mkrm6vpp","_id":"cju7zelmv000pqrm7exhfwrgg"},{"post_id":"cju7zelmn0007qrm738ohwi38","tag_id":"cju7zelmu000mqrm7tmq58oc4","_id":"cju7zelmx000wqrm7jc63kdxh"},{"post_id":"cju7zelmv000qqrm7wgk9wkoo","tag_id":"cju7zelmu000mqrm7tmq58oc4","_id":"cju7zelmx000zqrm71b3kqk4n"},{"post_id":"cju7zelmw000uqrm76vqy8y6j","tag_id":"cju7zelmu000mqrm7tmq58oc4","_id":"cju7zelmy0014qrm7jh7kz5zv"},{"post_id":"cju7zelmp000cqrm7jdcnp41s","tag_id":"cju7zelmw000tqrm7xozz42wh","_id":"cju7zelmz0017qrm7jcjetysc"},{"post_id":"cju7zelmx000xqrm760jskuah","tag_id":"cju7zelmm0005qrm76iascl9e","_id":"cju7zeln0001cqrm7sb7kmq6v"},{"post_id":"cju7zelmy0012qrm7lplt4zmq","tag_id":"cju7zelmm0005qrm76iascl9e","_id":"cju7zeln1001fqrm747e70xu2"},{"post_id":"cju7zelmz0015qrm7ufrqth9q","tag_id":"cju7zelmm0005qrm76iascl9e","_id":"cju7zeln1001iqrm7nvs340ks"},{"post_id":"cju7zelmq000dqrm7080fbv99","tag_id":"cju7zelmy0011qrm70kuvt7t0","_id":"cju7zeln2001kqrm772mtbe8s"},{"post_id":"cju7zeln0001dqrm792j0j1c7","tag_id":"cju7zelmu000mqrm7tmq58oc4","_id":"cju7zeln2001mqrm79j7mzd52"},{"post_id":"cju7zelmt000jqrm78iuwh6gd","tag_id":"cju7zeln0001bqrm762qg74ys","_id":"cju7zeln2001pqrm7b5z67avy"},{"post_id":"cju7zelmu000oqrm7nig10sdg","tag_id":"cju7zeln1001hqrm73bn83c6e","_id":"cju7zeln2001rqrm787aetoky"},{"post_id":"cju7zelmz0019qrm7wg85r4es","tag_id":"cju7zeln1001hqrm73bn83c6e","_id":"cju7zeln3001tqrm77pxexn32"}],"Tag":[{"name":"multitask","_id":"cju7zelmm0005qrm76iascl9e"},{"name":"tensorflow","_id":"cju7zelmr000gqrm7mkrm6vpp"},{"name":"pesudo labels","_id":"cju7zelmu000mqrm7tmq58oc4"},{"name":"few-shot learning","_id":"cju7zelmw000tqrm7xozz42wh"},{"name":"pseudo labels","_id":"cju7zelmy0011qrm70kuvt7t0"},{"name":"feature regularization","_id":"cju7zeln0001bqrm762qg74ys"},{"name":"numpy","_id":"cju7zeln1001hqrm73bn83c6e"}]}}