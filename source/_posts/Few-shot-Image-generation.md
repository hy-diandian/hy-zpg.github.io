---
title: Few-shot Image generation
date: 2019-04-04 13:44:00
tags: overview
categories: Meta-learning
---

## Meta learning

### Definition
* "learn to learn", intends to design models that can learn *__new__* skills or adapt to *__new__* environment *__rapidly__* with *__a few__* traing samples, like *__human learning way__*. The detail can be posted in [Meta-Learning: Learning to Learn Fast](https://lilianweng.github.io/lil-log/2018/11/30/meta-learning.html)

*  Optimization aims:
\begin{equation}
\theta^{*}=\arg \min _{\theta} \mathbb{E}_{\mathcal{D} \sim p(\mathcal{D})}\left[\mathcal{L}_{\theta}(\mathcal{D})\right]
\end{equation}

where $\mathcal{D}=\langle S, B\rangle$, Support set and Batch set.

* Training steps
1. sample a subset of labels $L\subset\mathcal{L}$.
2. samples a support set $S^L \subset \mathcal{D}$ and a training batch $B^L \subset \mathcal{D}$. Both of them belong to the sampled label set $L$, $y \in L, \forall (x, y) \in S^L, B^L$.
3. support set is the input of model.
4. the update of model parameters is based on the loss in backpropagation calculated from the mini-batch $B^L$.

each pair of sampled dataset $(S^L, B^L)$ is regarded as one data point, such that trained models can generalize to other datasets. Symbols in red are added for meta-learning in addition to the general supervised learning objective.
\begin{aligned}
\theta = \arg\max_\theta \color{red}{E_{L\subset\mathcal{L}}[} E_{\color{red}{S^L \subset\mathcal{D}, }B^L \subset\mathcal{D}} [\sum_{(x, y)\in B^L} P_\theta(x, y\color{red}{, S^L})] \color{red}{]}
\end{aligned}

* Traning stages
1. meta-learner: a optimizer $ g_\phi $ learns how to update the learner model’s parameters via the support set $S$, $\theta' = g_\phi(\theta, S)$
2. learner: A classifier $f_\theta$ is the “learner” model, trained for operating a given task.
<!-- final learning objective is $\mathbb{E}_{L\subset\mathcal{L}}[ \mathbb{E}_{S^L \subset\mathcal{D}, B^L \subset\mathcal{D}} [\sum_{(\mathbf{x}, y)\in B^L} P_{g_\phi(\theta, S^L)}(y \vert \mathbf{x})]]$ -->


 

### Common methods


#### model-based: $f_\theta(\mathbf{x}, S)$
* use *__recurrent__* network with *__internal (or external)__* memory.
* rapid parameter update achieved by *__meta-learner model__* or *__internal architecture__*.
* memory-augmented neural network for meta-learning
	* using _external memory storage_ to facilate learning process _without forgetting_ new information in future.
	* encoding new information _quicly_, so adapt to new tasks after only _a few samples_.
	* memory-augmented neural networkc: how to assign weights to attention vector. memory serves as knowledge repository, the controller learns to read and write memory rows. ttention weights generation by addressing mechanism: control-based + location-based.
	* MANN for meta-learning: the update of memory for efficient information retrievel and storage, how to read from memory and how to write into memory.
* meta network
	* architecture
	* loss gradients are used as meta information to populate models to learn fast weights.

#### metric-based:
* learn *__efficient__* distance metric.
* similar to *__nearnest neighbors algorithm__* (KNN,k-means) and *__kernel density estimation__*.
* the predicted possibility of labeled samples is from is a *__weighted sum of support set samples__*, and the weight is generated by a kernel function $k_\theta$, which can measure the *__similarity__* of twp data samples:
$$
P_\theta(y \vert \mathbf{x}, S) = \sum_{(\mathbf{x}_i, y_i) \in S} k_\theta(\mathbf{x}, \mathbf{x}_i)y_{i}
$$
* crucial points: *__good kernel__*
* solution: learning *__embedding vector__* of input data explicitly and use them to design *__proper kernel__* functions.
* Siamese networks: 
    - assumption: the _learned embedding_ can be _generalized_ to be useful for measuring the distance between images of unknown categories.
    - _verification_, images pairs.
    - final prediction is the class of the support image with highest probability.
* Matching networks:
	- $g_{\theta}$ with $k$ classifiers for k classes, while $f_{\theta}$ for testing images.
	- _attention kernel_ depends on two embedding functions $g$ and $f$, in simple version where $f=g$. in complex version where integrating full contextual embedding (FCE), it achieves improvement on hard tasks, not for simple tasks.
* Relation networks
    - image pairs, _feature concatenation_.
    - relation modeled: _mse_ loss function.
* Prototypical networks
    - images of _each class_ are embedded into $M$ dimensional feature vector, each class has _prototype_ feature vector from the mean vector of the embedded support data samples in each class.
    - _squared euclidean distance_ loss.




#### optimization-based: 
* optimize the *__model parameter__* explicitly for *__fast__* learning.
* modeling *__optimization algorithm__* exploitly.
* LSTM meta-learner
* MAML
* reptile

