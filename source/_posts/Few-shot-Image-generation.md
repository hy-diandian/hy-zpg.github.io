---
title: Few-shot Image generation
date: 2019-04-04 13:44:00
tags: few-shot learning
categories: Meta-learning
---

## Meta learning

### Definition
* "learn to learn", intends to design models that can learn *__new__* skills or adapt to *__new__* environment *__rapidly__* with *__a few__* traing samples, like *__human learning way__*. The detail can be posted in [Meta-Learning: Learning to Learn Fast](https://lilianweng.github.io/lil-log/2018/11/30/meta-learning.html)

*  Optimization aims:
\begin{aligned}
\theta^* = \arg\min\_\theta \mathbb{E}\_{\mathcal{D}\sim p(\mathcal{D})} [\mathcal{L}\_\theta(\mathcal{D})]
\end{aligned}


where $\mathcal{D}=\langle S, B\rangle$, Support set and Batch set.

* Training steps
1. sample a subset of labels $L\subset\mathcal{L}$.
2. samples a support set $S^L \subset \mathcal{D}$ and a training batch $B^L \subset \mathcal{D}$. Both of them belong to the sampled label set $L$, $y \in L, \forall (x, y) \in S^L, B^L$.
3. support set is the input of model.
4. the update of model parameters is based on the loss in backpropagation calculated from the mini-batch $B^L$.

each pair of sampled dataset $(S^L, B^L)$ is regarded as one data point, such that trained models can generalize to other datasets. Symbols in red are added for meta-learning in addition to the general supervised learning objective.
\begin{aligned}
\theta = \arg\max\_\theta \color{red}{E\_{L\subset\mathcal{L}}[} E\_{\color{red}{S^L \subset\mathcal{D}, }B^L \subset\mathcal{D}} [\sum\_{(x, y)\in B^L} P\_\theta(x, y\color{red}{, S^L})] \color{red}{]}
\end{aligned}

* Traning stages
1. meta-learner: a optimizer $g\_\phi$ learns how to update the learner model’s parameters via the support set $S$, $\theta' = g\_\phi(\theta, S)$
2. learner: A classifier $f\_\theta$ is the “learner” model, trained for operating a given task.
3. final learning objective is:
\begin{aligned}
\mathbb{E}\_{L\subset\mathcal{L}}[ \mathbb{E}\_{S^L \subset\mathcal{D}, B^L \subset\mathcal{D}} [\sum\_{(\mathbf{x}, y)\in B^L} P\_{g\_\phi(\theta, S^L)}(y \vert \mathbf{x})]]
\end{aligned}


 

### Common methods


#### model-based: $f\_\theta(\mathbf{x}, S)$
* use *__recurrent__* network with *__internal (or external)__* memory.
* rapid parameter update achieved by *__meta-learner model__* or *__internal architecture__*.
* memory-augmented neural network for meta-learning
	* using _external memory storage_ to facilate learning process _without forgetting_ new information in future.
	* encoding new information _quicly_, so adapt to new tasks after only _a few samples_.
	* memory-augmented neural networkc: how to assign weights to attention vector. memory serves as knowledge repository, the controller learns to read and write memory rows. ttention weights generation by addressing mechanism: control-based + location-based.
	* MANN for meta-learning: the update of memory for efficient information retrievel and storage, how to read from memory and how to write into memory.
* meta network
	* architecture
	* loss gradients are used as meta information to populate models to learn fast weights.


#### metric-based: $\sum\_{(\mathbf{x}\_i, y\_i) \in S} k\_\theta(\mathbf{x}, \mathbf{x}\_i)y\_i$
* learn *__efficient__* distance metric.
* similar to *__nearnest neighbors algorithm__* (KNN,k-means) and *__kernel density estimation__*.
* the predicted possibility of labeled samples is from is a *__weighted sum of support set samples__*, and the weight is generated by a kernel function $k_\theta$, which can measure the *__similarity__* of twp data samples:
\begin{aligned}
P\_\theta(y \vert \mathbf{x}, S) = \sum\_{(\mathbf{x}\_i, y\_i) \in S} k\_\theta(\mathbf{x}, \mathbf{x}\_i)y\_{i}
\end{aligned}

* crucial points: *__good kernel__*
* solution: learning *__embedding vector__* of input data explicitly and use them to design *__proper kernel__* functions.
* Siamese networks: 
    - assumption: the _learned embedding_ can be _generalized_ to be useful for measuring the distance between images of unknown categories.
    - _verification_, images pairs.
    - final prediction is the class of the support image with highest probability.
* Matching networks:
	- $g\_{\theta}$ with $k$ classifiers for k classes, while $f_{\theta}$ for testing images.
	- _attention kernel_ depends on two embedding functions $g$ and $f$, in simple version where $f=g$. in complex version where integrating full contextual embedding (FCE), it achieves improvement on hard tasks, not for simple tasks.
* Relation networks
    - image pairs, _feature concatenation_.
    - relation modeled: _mse_ loss function.
* Prototypical networks
    - images of _each class_ are embedded into $M$ dimensional feature vector, each class has _prototype_ feature vector from the mean vector of the embedded support data samples in each class.
    - _squared euclidean distance_ loss.




#### optimization-based: $P\_{g\_\phi(\theta, S^L)}(y \vert \mathbf{x})$
* optimize the *__model parameter__* explicitly for *__fast__* learning.
* modeling *__optimization algorithm__* exploitly.
* LSTM meta-learner
* MAML
* reptile

* crucial keys: *__good kernel__*
* solution: learning *__embedding vector__* of input data explicitly and use them to design *__proper kernel__* functions.
* Siamese networks: 
    - assumption: the *__learned embedding__* can be *__generalized__* to be useful for measuring the distance between images of unknown categories.
    - *__verification__*, images pairs.
    - final prediction is the class of the support image with highest probability.
* Matching networks:
	- $g\_{\theta}$ with $k$ classifiers for k classes, while $f\_{\theta}$ for testing images.
	- attention kernel depends on two embedding functions $g$ and $f$, in simple version where $f=g$. in complex version where integrating full contextual embedding (FCE), it achieves improvement on hard tasks, not for simple tasks.
* Relation network
    - image pairs, feature concatenation.
    - relation modeled: mse loss function.
* Prototypical
    - images of each class are embedded into $M$ dimensional feature vector, each class has _prototype_ feature vector from the mean vector of the embedded support data samples in each class.
    - squared euclidean distance.



#### optimization-based: $P\_{g\_\phi(\theta, S^L)}(y \vert \mathbf{x})$
* optimize the *__model parameter__* explicitly for *__fast__* learning
